{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CV2020 - 15 - YOLO Detection.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"f_ChrQTZyAZU"},"source":["![title](https://i.ibb.co/f2W87Fg/logo2020.png)\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"MQjL2XtX7uKJ"},"source":["<table  class=\"tfo-notebook-buttons\" align=\"left\"><tr><td>\n","    \n","<a href=\"https://colab.research.google.com/github/adf-telkomuniv/CV2020_Exercises/blob/main/CV2020 - 15 - YOLO Detection.ipynb\" source=\"blank\" ><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>\n","</td><td>\n","<a href=\"https://github.com/adf-telkomuniv/CV2020_Exercises/blob/main/CV2020 - 15 - YOLO Detection.ipynb\" source=\"blank\" ><img src=\"https://i.ibb.co/6NxqGSF/pinpng-com-github-logo-png-small.png\"></a>\n","    \n","</td></tr></table>"]},{"cell_type":"markdown","metadata":{"id":"8WGg98rBctSg"},"source":["\n","# Task 17 - You Only Look Once Object Detection\n","\n","You only look once (YOLO) is a state-of-the-art, real-time object detection system. The latest improvement of YOLO achieve mAP of 57.9% on COCO test-dev with an ability of processing images at 30 FPS.\n","\n","<center>\n","<img src='https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/opencv-yolo/yolo_car_chase_01_output.gif' width=500>\n","</center>\n","\n","Currently there are several version of improvements, from YOLO, YOLO9000, YOLOv2, and the latest is YOLOv3\n","\n","<center>\n","<img src='https://miro.medium.com/max/1091/1*ju1oaoIkVUkaIPAdpehlzA.png' width=500>\n","</center>\n","\n","<br>\n","\n","In this exercise, we will build a simplified version of YOLO detection system and train it using **makeshift** detection dataset\n"]},{"cell_type":"markdown","metadata":{"id":"SF71bN55cZzi"},"source":["Write down your Name and Student ID"]},{"cell_type":"code","metadata":{"id":"S5yg44U8cZzk"},"source":["## --- start your code here ----\n","\n","NIM  = ??\n","Nama = ??\n","\n","## --- end your code here ----"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6VAE_sE-Bgk1"},"source":["---\n","---\n","#[Part 0] Import Libraries "]},{"cell_type":"markdown","metadata":{"id":"WvTLgxWsfaJm"},"source":["---\n","## 1 - Import Module\n","\n","import the necessary modules"]},{"cell_type":"code","metadata":{"id":"JC_hj76sMEnF"},"source":["import numpy as np\n","import tensorflow as tf\n","from PIL import Image, ImageDraw, ImageFont\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras import backend as K\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","np.set_printoptions(precision=2,suppress=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"55xMnve6d8UW"},"source":["download font type needed to write to the image\n","\n","you can change this to another font type of your liking"]},{"cell_type":"code","metadata":{"id":"hxLm6nSHd1yo"},"source":["!wget -O 'font.ttf' 'http://webpagepublicity.com/free-fonts/x/Xerox%20Sans%20Serif%20Narrow.ttf' -q"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kVIp10traRtK"},"source":["---\n","## 2 - Turn off Eager Execution\n","\n","Since this simplified version is using old Keras backend, when using TensorFlow 2.0 we need to turn off the Eager execution\n","\n","to do that run the following cell"]},{"cell_type":"code","metadata":{"id":"5silAgzHL4D-","cellView":"both"},"source":["tf.compat.v1.disable_eager_execution()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qpeMsOz1f4te"},"source":["---\n","---\n","#[Part 1] Detection Dataset\n","\n","Now the Detection Dataset is usually quite expensive to build, and the already existing datasets are usually quite large in scale. Which is too much for our simplified exercise\n","\n","So let's generate a simplified dataset which is only images of string labels simulating the obects much like the image below\n","\n","<center>\n","<img src='https://i.ibb.co/DbqcTtV/detection-data.png'>\n","</center>\n","\n","This way we can generate a detection dataset with much cheaper process"]},{"cell_type":"markdown","metadata":{"id":"rWy1Vg7itF2j"},"source":["---\n","## 1 - Define Class and Color\n","\n","Now let's define the class and color\n","\n","First, define each object label in `cl_label` list. You can change the label or even add more class if you want.\n","\n","**But the last labes should always be `'background'`**\n","\n","<br>\n","\n","Then define what color you want the label to be drawn on the image. You can very much use black and white images, but the network will train easier if the color vary for each class\n","\n","Also define the background image color outside the `cl_color` list\n"]},{"cell_type":"markdown","metadata":{"id":"xc2RyhhXUYMU"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","change or add the labels and their corresponding color\n"]},{"cell_type":"code","metadata":{"id":"t1ziGn2jMEhB"},"source":["cl_label = ['bike',    'person',    'background']\n","cl_color = ['darkred', 'orangered', '']\n","cl_hot   = to_categorical(np.arange(len(cl_label)))\n","\n","bg_color = 'LightGray'\n","\n","classes  = list(zip(cl_label, cl_hot, cl_color))\n","nb_class = len(classes)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hdkzbR7Kg-9p"},"source":["let's see the class list"]},{"cell_type":"code","metadata":{"id":"lQpnCc_VbDlF"},"source":["print('number of class:',nb_class)\n","\n","for c in classes:\n","    print(c)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v-BuY4KUkaro"},"source":["**EXPECTED OUTPUT**:\n","\n","if you're using default $3$ classes\n","\n","<pre>\n","number of class: 3\n","('bike', array([1., 0., 0.], dtype=float32), 'darkred')\n","('person', array([0., 1., 0.], dtype=float32), 'orangered')\n","('background', array([0., 0., 1.], dtype=float32), '')"]},{"cell_type":"markdown","metadata":{"id":"NJybLMrLtJFe"},"source":["---\n","## 2 - Define Image and Grid Size\n","In the actual YOLO Detection system, it divides the input image into an $S\\times S$ grid.\n","Each grid cell predicts only one object and it incorporates a fixed number of boundary boxes called **anchors** or **priors**. \n","\n","<br>\n","<center>\n","<img src='https://miro.medium.com/max/667/1*4Y1PaY3ZgxKt5w84_0pNxw.jpeg' width=350>\n","</center>\n","\n","The number anchors are defined by the shape of the bounding boxes. This tries to incorporate that in the real-life domain, the boundary boxes are not arbitrary. \n","\n","<br>\n","<center>\n","<img src='https://miro.medium.com/max/504/1*8Q8r9ixjTiKLi1mrF36xCw.jpeg' width=400>\n","</center>\n","\n","For example, cars and pedestrians have different box orientation (aspect ratio). Instead of predicting 5 arbitrary boundary boxes, we predict offsets to each of the constrained anchor boxes\n"]},{"cell_type":"markdown","metadata":{"id":"4gxgEficHSjl"},"source":["\n","\n","---\n","\n","\n","The more cells the image is divided to increase the detection accuracy as it will be more detailed. But too much cells and the detection will slow down.\n","\n","For this exercise, we will use only one anchor.\n","\n","The implementation in this exercise actually support multiple anchors, but we're not going to use it.\n","\n","You can, however, change the image size and grid number. For example changing it to $96\\times 96$ with $3\\times 3$ grid"]},{"cell_type":"markdown","metadata":{"id":"pVbOy4Kuc5FL"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","Define the image size and grid size"]},{"cell_type":"code","metadata":{"id":"9V36MjP_n529"},"source":["img_size  = (64, 64)\n","grid_size = (2, 2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wkPhKj9nnIZr"},"source":["for this exercise, we only use 1 anchor"]},{"cell_type":"code","metadata":{"id":"49wSeIzmtRT5"},"source":["nb_anchor = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vm71A8cNnFX6"},"source":["Now calculate the cell size in each grid"]},{"cell_type":"code","metadata":{"id":"XnC2-DmfNGSo"},"source":["img_w,  img_h  = img_size\n","grid_w, grid_h = grid_size\n","\n","cell_w = img_w//grid_w\n","cell_h = img_h//grid_h"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gKUVykEXkoZD"},"source":["print('image w/h :', img_w, img_h)\n","print('grid w/h  :', grid_w, grid_h)\n","print('cell w/h  :', cell_w, cell_h)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zuH4kjgWkk7h"},"source":["**EXPECTED OUTPUT**:\n","\n","if you're using default $64\\times 64$ image with $2\\times 2$ grid\n","\n","<pre>\n","image w/h : 64 64\n","grid w/h  : 2 2\n","cell w/h  : 32 32"]},{"cell_type":"markdown","metadata":{"id":"KsRyQkfPuY7B"},"source":["---\n","## 3 - Detection Target\n","\n","This is how we will generate our dataset.\n","\n","<font size=5 color='red'>**So read this carefully**</font>\n","\n","<br>\n","\n","* First we start off with a **blank image**\n","\n","* For each grid cell, we randomly add either <font color='blue'>**ONE**</font> object or <font color='blue'>**BACKGROUND** </font>\n","  * Adding background means that there is no object to draw in that grid\n","\n","  * If it is an object, randomly draw the object in that grid range\n","  * Generate the target list\n","* Each grid cell returns a list as the **cell target**\n","* All lists of cell targets of an image are then combined into the **image target** list\n","\n","<br>\n","\n","Now for the explanation of each list"]},{"cell_type":"markdown","metadata":{"id":"IXQjK8stwT5I"},"source":["---\n","### a. Cell Target\n","\n","Each cell has a list of number as target consisting three parts: <br>**class score**, **bounding box**, and **object confidence**\n","\n","\n","<center>\n","<img src='https://i.ibb.co/BLN90ML/anchor.png' ><br><caption>grid target list</caption>\n","</center>\n","\n","<br>\n","\n","* The **class score** is one-hot label score very much like classification target, indicates what object classified in that cell location. \n","\n","\n","* The **bounding box** consists of $4$ values indicates the starting position ($x, y$ coordinates) followed by its box **width** and **height** ($w, h$)\n","  * The $x$ and $y$ is a scalar ranged from $0$ to number of grid $S$\n","  * The $w$ and $h$ is a scalar ranged from $0$ to $1$ scaling the **image width** and **image height**\n","\n","* The **object confidence** score is a value range from $0$ to $1$ indicates the network confidance of the appearance of an object in that location\n","\n","\n","<br>\n","\n","The length of cell target is&nbsp; $C+4+1$, where&nbsp; $C$ &nbsp;is the number of object to be detected. Usually background is not included in label, but for our exercise we did. \n","\n","Thus for this exercise, with $3$ classes, the length of target should be&nbsp; $3+4+1=8$"]},{"cell_type":"markdown","metadata":{"id":"5Q6Ib1R1wWwY"},"source":["---\n","### b. Multiple Anchors\n","\n","As mentioned before, we can use multiple anchor box detection. This is useful if we want to detect multiple objects in one cell, or if we want to specialize different box shape for different class.\n","\n","<center><img src='https://i.ibb.co/gm871y9/anchor2.jpg'><br><caption>anchor box</caption></center>\n","\n","For multiple Anchors, the target list will be multiplied as many achors used\n","\n","So the length will be&nbsp; $B*(C+4+1)$, where&nbsp; $C$ &nbsp;is the number of class and&nbsp; $B$ &nbsp;is the number of anchor\n","\n","<center><img src='https://i.ibb.co/XkX3KS8/multi-anchors.png'><br><caption>grid target list (version A)</caption></center>\n","\n","<br>\n","\n","Another variation in multiple anchor box (**like the one implemented in this exercise**) is that although it uses multiple anchor, each grid only perform **single detection**.\n","\n","Thus the &nbsp;$C$&nbsp; number of class only defined once at the beginning. \n","So the length will only be&nbsp; $C + B*(4+1)$\n","\n","<br>\n","\n","<center><img src='https://i.ibb.co/JxzrskB/anchor3.png'></img><br>\n","<caption>grid target list (version B)</caption></center>\n"]},{"cell_type":"markdown","metadata":{"id":"Eboaa0WENltM"},"source":["---\n","### c. Image Target\n","\n","Each grid cell has a list $B*(C+4+1)$. Now for an input image of $S\\times S$ grid cell, we stack all those lists into a giant image target list\n","\n","So the target length of an image is $S*S*\\big(B*(C+4+1)\\big)$\n","\n","<br>\n","\n","Or if we use the other alternative, like the image below, we will get list with the length of\n","$S*S*\\big(C+B*(4+1)\\big)$\n","\n","\n","<center>\n","<img src='https://miro.medium.com/max/2113/1*OuMJUWo2rXYA-GYU63NUGw.jpeg' width=600>\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"iNwysNSctrWL"},"source":["---\n","## 4 - Add Background Function\n","\n","If in a grid, indicates by `row` and `col` position, we want to add a background target (no object), then all we have to do is generate a target in the center of that grid cell\n","\n","<center>\n","<img src='https://i.ibb.co/D5hMN5f/grid-bg.png' width=300><br><caption>add background at $(1,0)$\n","</center>\n","\n","For example, <br>if we have a background in grid $( 1, 0)$ from a $2\\times 2$ &nbsp;grid as depicted above, then\n","* the target $x$ will be at $1.5$\n","($\\text{col}+\\frac{1}{2}$  )\n","\n","* the target $y$ will be at $0.5$ \n","($\\text{row}+\\frac{1}{2}$  )\n","\n","* the width $w$ and height $h$ will be $0.5$ and $0.5$ <br>\n","(half the image, since it's $2\\times 2$ grid)\n","\n","* lastly, the object confidence is $0$"]},{"cell_type":"markdown","metadata":{"id":"Qnd0hKc8c7Dg"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","Implement the function as defined above\n"]},{"cell_type":"code","metadata":{"id":"b8m7W0PfRIK8"},"source":["def add_background(y_hot, col, row):\n","\n","    # convert y_hot vector \n","    # from array float into a list of integers\n","    y_hot = list(y_hot.astype('int'))\n","\n","    # calculate bounding box\n","    x = ??    # col number + 1/2\n","    y = ??    # row number + 1/2\n","    w = ??    # 1 / grid width\n","    h = ??    # 1 / grid height\n","    p = ??    # probability is 0\n","\n","    # combine all into a single list\n","    target = []\n","    target += y_hot\n","    target += [x, y, w, h]\n","    target += [0]\n","\n","    return target\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t6j1dF8RfAHi"},"source":["Check your implementation"]},{"cell_type":"code","metadata":{"id":"shITwbwqRUIu"},"source":["(l, y, c) = classes[-1]\n","\n","print('background at (0,0):')\n","t = add_background(y, 0, 0)\n","print('tarhet :', t)\n","print('len(t) :', len(t), '\\n')\n","\n","\n","print('background at (1,0):')\n","t = add_background(y, 1, 0)\n","print('tarhet :', t)\n","print('len(t) :', len(t), '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EWNgmOhYiToK"},"source":["**EXPECTED OUTPUT**:\n","\n","if you're using default $3$ classes\n","<pre>\n","  background at (0,0):\n","  tarhet : [0, 0, 1, 0.5, 0.5, 0.5, 0.5, 0]\n","  len(t) : 8\n","\n","  background at (1,0):\n","  tarhet : [0, 0, 1, 1.5, 0.5, 0.5, 0.5, 0]\n","  len(t) : 8\n"]},{"cell_type":"markdown","metadata":{"id":"hePHU_UNjkZi"},"source":["---\n","## 5 - Add Object Function\n","\n","Then if we want to add an object sized &nbsp; $[w_\\text{obj}\\times h_\\text{obj}]$  &nbsp;to the image at **CENTER** coordinate of $(x, y)$, <br>we need to draw the bounding box from half $w_\\text{obj}$ up and half $h_\\text{obj}$ left to the coordinate\n","\n","<center>\n","<img src='https://i.ibb.co/z2X1jc6/grid-obj.png' width=300>\n","</center>\n","\n","For example as shown in the picture, if we were to add  \n","* an object sized $[24\\times 10]$ \n","\n","* to an image sized $[64\\times 64]$ with $[2\\times 2]$ grid frame\n","* at a **CENTER** coordinate of $x=20$ and $y=40$ \n","<br>\n","\n","Then the object **STARTING** coordinate to draw is\n","* $x_\\text{obj} = 20-\\frac{24}{2} = 8$\n","\n","* $y_\\text{obj} = 40-\\frac{10}{2} = 35$\n","<br>\n","\n","Now to get the target, we need to scale it accordingly, thus we get\n","* $x = 20/32 = 0.625$\n","\n","* $y = 40/32 = 1.25$\n","* $w = 24/64 = 0.375$\n","* $h = 10/64 = 0.156$\n","\n","Lastly, the object confidence is $1$"]},{"cell_type":"markdown","metadata":{"id":"GsX4f8mhc7gj"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","Implement the function as defined above\n"]},{"cell_type":"code","metadata":{"id":"Nb6boAoWRj8Z"},"source":["def add_object(img_draw, obj_idx, x, y):\n","\n","    # retrieve the object information\n","    (label, y_hot, color) = classes[obj_idx]\n","\n","    # convert y_hot vector \n","    # from array float into a list of integers\n","    # see implementation above\n","    y_hot = ??\n","    \n","    # set object width and height\n","    obj_w = len(label)*6\n","    obj_h = 10\n","\n","    # calculate object coordinates\n","    obj_x = ??   # x - object width / 2\n","    obj_y = ??   # y - object height / 2\n","    \n","    # draw the object (label) to image\n","    img_draw.text((obj_x, obj_y), label, fill=color)\n","\n","    # calculate bounding box\n","    x = ??    # x / cell width\n","    y = ??    # y / cell height\n","    w = ??    # object width / image width\n","    h = ??    # object height / image height\n","    p = ??    # probability is 1\n","\n","    # combine all into a single list\n","    target = []\n","    target += y_hot\n","    target += [x, y, w, h]\n","    target += [1]\n","\n","    return target\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L9t3AIByoQXo"},"source":["Check your implementation"]},{"cell_type":"code","metadata":{"id":"kCeZKuUHSUqA"},"source":["test_img = Image.new('RGB', img_size, color=bg_color)\n","draw = ImageDraw.Draw(test_img)\n","x = 20\n","y = 40\n","\n","target = add_object(draw, 0, x, y)\n","\n","plt.imshow(test_img)\n","plt.axis('off')\n","plt.show()\n","\n","print('target:',target)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tX-a535JlFqD"},"source":["**EXPECTED OUTPUT**:\n","\n","if you're using default $3$ classes with $64\\times 64$ image with $2\\times 2$ grid\n","\n","<pre>\n","<img src='https://i.ibb.co/hR3CMc9/add-obj.png' width=150>\n","target: [1, 0, 0, 0.625, 1.25, 0.375, 0.15625, 1]"]},{"cell_type":"markdown","metadata":{"id":"ggL-bcdBjk6a"},"source":["---\n","## 6 - Generate Data Function\n","\n","Now we define our generate data function which repeatedly randomize an object and put it into each grid of an image.\n","\n","If the randomized object is `background`, call `add_background()` function, and\n","if it is an object, randomize the center location, and call `add_object()` function"]},{"cell_type":"markdown","metadata":{"id":"ZRUWq7d4c8UR"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","Implement the function as defined above\n"]},{"cell_type":"code","metadata":{"id":"2wNww5BAOAkb"},"source":["def generate_data(nb_data):\n","\n","    # create empty list for data and label\n","    x_train = []\n","    y_train = []\n","\n","    for j in range(0, nb_data):\n","\n","        # generate empty image base\n","        base_img = Image.new('RGB', img_size, color=bg_color)\n","        img_draw = ImageDraw.Draw(base_img)\n","        \n","        # create empty list for targets\n","        img_target = []\n","\n","        # loop over all grid (row and col)\n","        for row in range(grid_w):\n","\n","            for col in range(grid_h):\n","\n","                # randomize object id\n","                # call .randint() function from numpy \n","                # with random range (0 , nb_class)\n","                idx = ??\n","\n","                # get class information\n","                (label, y_hot, color) = classes[idx]\n","                \n","                # check if it's a background\n","                if(label=='background'):\n","\n","                    # call add_background() funtion with input y_hot, col, and row\n","                    new_target = ??\n","\n","                else:\n","                    # randomize coordinate center location\n","                    # call .randint() function from numpy \n","                    # with random range (col*cell_w , (col+1)*cell_w)\n","                    x = ??\n","\n","                    # call .randint() function from numpy \n","                    # with random range (row*cell_h , (row+1)*cell_h)\n","                    y = ??\n","                    \n","                    # call add_object() function with input img_draw, idx, x, and y\n","                    new_target = ??\n","\n","                # append new_target into img_target list\n","                img_target.??\n","\n","        # convert base_img into a numpy array\n","        np_img = ??\n","\n","        # append np_img into x_train list\n","        x_train.??    \n","\n","        # append img_target into y_train list\n","        y_train.??\n","\n","    # convert into numpy array\n","    x_train = np.array(x_train).astype('float32')/255\n","    y_train = np.array(y_train).astype('float32')\n","\n","    return x_train, y_train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bKGJDYxklNRp"},"source":["---\n","## 7 - Generate Data\n","\n","And that's it\n","\n","Now let's generate $5000$ training data and another $1000$ as validation data"]},{"cell_type":"code","metadata":{"id":"rBGRo2kItth3"},"source":["x_train, y_train = generate_data(5000)\n","x_val, y_val     = generate_data(1000)\n","\n","print('x_train shape:', x_train.shape)\n","print('y_train shape:', y_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ePrICIbvl0Xn"},"source":["**EXPECTED OUTPUT**:\n","\n","if you're using default $3$ classes $64\\times 64$ image with $2\\times 2$ grid\n","\n","<pre>\n","x_train shape: (5000, 64, 64, 3)\n","y_train shape: (5000, 4, 8)"]},{"cell_type":"markdown","metadata":{"id":"Pl3rIEYgH1ZX"},"source":["Let's view the first image from training set and its target"]},{"cell_type":"code","metadata":{"id":"MQMmnkt-aYpi"},"source":["plt.imshow(x_train[0])\n","plt.axis('off')\n","plt.show()\n","\n","for tgt in y_train[0]:\n","    print(tgt)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sijlJDOMIAOH"},"source":["Now view 10 images from training set\n","\n","You should see various images with random number of objects at random locations"]},{"cell_type":"code","metadata":{"id":"Y3XKGijpoONF"},"source":["plt.figure(figsize=(10,6))\n","for i in range(10):\n","    plt.subplot(2,5,i+1)\n","    plt.imshow(x_train[i])\n","    plt.axis('off')\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d4isshOdlZIR"},"source":["---\n","---\n","#[Part 2] Visualizing Detection Box\n","\n","Now let's create a function to draw the bounding box to an image.\n","\n","**REMEMBER** that we're using target list design where each grid consist of a list with length $C + B*(4+1)$\n","\n","<center><img src='https://i.ibb.co/JxzrskB/anchor3.png'></center>"]},{"cell_type":"markdown","metadata":{"id":"2uZvUOYxle_g"},"source":["---\n","## 1 - Box Grid Function\n","\n","Given an image, the target `y_grid`, along with `col` and `row` number for current grid location, we draw the bounding box as follow:\n","\n","* First, extract the class from `y_grid` and get the class index\n","\n","* Then reshape the rest of `y_grid` into a matrix of `(nb_anchor, 5)`\n","* Then loop over each anchor box\n"," * Extract the $x, y, w, h, $ and $p$ from the anchor\n","\n"," * The $x$ and $y$ from prediction is in range $0$ to $1$ as the result from the grid input, and not the image. <br>So to draw the prediction box, we need to add $x$ and $y$ with `row` and `col` number\n"," * Now to perform a simplified **Non-max Suppression**, check if confidence $p$ is higher than `max_p` from other anchor\n"," * If the current confidence $p$ is higher, calculate and overwrite the bounding box coordinates\n"," * Now, it's a little bit different when we draw the rectangle as it uses $[x1,y1,x2,y2]$ rather than using **width** and **height**\n"," * Set color to draw the box. <br>For example, target box is <font color=DarkGray>**gray**</font>, high confidence prediction is  <font color=LimeGreen>**green**</font>, and low confidence prediction is  <font color=RoyalBlue>**blue**</font>\n"," * If the class is not background, draw the box"]},{"cell_type":"markdown","metadata":{"id":"EvJaqFlDc-RB"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","Implement the function as defined above\n"]},{"cell_type":"code","metadata":{"id":"X_aVC2Vnuokv"},"source":["def draw_box_grid(draw, y_grid, row=0, col=0, pad=0, is_prediction=False, threshold  = 0.1):\n","    \n","    # initialize max probability = 0\n","    max_p   = 0\n","\n","    # get class from y_grid[0:nb_class]\n","    y_class = ??\n","\n","    # get class id, use np.argmax() with input y_class\n","    y_pred  = ??\n","\n","    # reshape the rest of anchor list into (nb_anchor, 5)\n","    anchor_box = y_grid[nb_class:].reshape(nb_anchor, 5)\n","\n","    # loop over anchor box\n","    for b in anchor_box:\n","\n","        # retrieve x, y, w, h and p\n","        # from b[0] to b[4]\n","        x = b[0]\n","        y = b[1]\n","        w = b[2]\n","        h = b[3]\n","        p = b[4]         \n","\n","        # add row number to x \n","        x += row\n","        # add col number to y \n","        y += col\n","\n","        # if current probability is higher than max\n","        if p > max_p:\n","            max_p = p\n","            rx1   = ??  # x*cell width - w*image width/2 + pad\n","            ry1   = ??  # y*cell height - h*image height/2 + pad\n","            rx2   = ??  # w*image width + rx1\n","            ry2   = ??  # h*image height + ry1\n","\n","    # is object if probability is higher than threshold\n","    is_object = p > threshold\n","\n","    # set color box\n","    if is_prediction:\n","        if is_object:\n","            box_color = 'LimeGreen'\n","        else:\n","            box_color = 'RoyalBlue'\n","    else:\n","        box_color = 'DarkGray'\n","\n","    # if class is not background, draw the box\n","    if y_pred!=nb_class-1:\n","        draw.rectangle([rx1, ry1, rx2, ry2], outline=box_color)\n","\n","    return y_pred, is_object"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kpUa-HPboSQf"},"source":["Check your implementation"]},{"cell_type":"code","metadata":{"id":"Kwq0db_rmZL_"},"source":["test_img = Image.new('RGB', img_size, color=bg_color)\n","draw = ImageDraw.Draw(test_img)\n","x = 20\n","y = 40\n","\n","target = add_object(draw, 0, x, y)\n","plt.subplot(121)\n","plt.imshow(test_img)\n","plt.axis('off')\n","\n","print('original target',target)\n","target = np.array(target)\n","\n","y_pred, is_object = draw_box_grid(draw, target, row=0, col=0, is_prediction=False)\n","plt.subplot(122)\n","plt.imshow(test_img)\n","plt.axis('off')\n","plt.show()\n","print('predicted:',y_pred, ', is object?',is_object)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ep0RPaEBmcaH"},"source":["**EXPECTED OUTPUT**:\n","\n","if you're using default $3$ classes $64\\times 64$ image with $2\\times 2$ grid\n","\n","<pre>original target [1, 0, 0, 0.625, 1.25, 0.375, 0.15625, 1]\n","<img src='https://i.ibb.co/ByVjcF3/box-test.png' width=300>\n","predicted: 0 , is object? True</pre>"]},{"cell_type":"markdown","metadata":{"id":"Nuh789MqLfGT"},"source":["---\n","## 2 - Draw Bounding Box Function\n","\n","Now we define function to iterate over grid and draw the bounding box in it.\n","Here's step by step of this function\n","* First we pad the image with zero pixels as a place to write the prediction class\n","\n","* Loop over the grid\n"," * Draw the target box\n","\n"," * If prediction is provided, draw the prediction box\n"," * write the predicted class on top and bottom of the image<br> note that the code only designed for $2\\times 2$ grid\n"," * set the text color. <br>For example <font color='darkgreen'>**green**</font> if it's the correct class, <font color='deeppink'>**pink**</font> if it's wrong or having low confidence, <br>and **black** if prediction is not provided"]},{"cell_type":"markdown","metadata":{"id":"QQmiXYnndHh9"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","Implement the function as defined above\n"]},{"cell_type":"code","metadata":{"id":"ehZEZUJOhto3"},"source":["def draw_bbox(np_img, target, prediction=None, pad=10, threshold=0.1):\n","\n","    # rescale np_img by multiplying it with 255\n","    img = ??\n","\n","    # add white padding as a place to write class prediction\n","    img = np.pad(img, ((pad,pad),(pad,pad), (0,0)), 'constant', constant_values=255)\n","\n","    # generate image\n","    img      = Image.fromarray(img.astype('uint8'), 'RGB')\n","    img_draw = ImageDraw.Draw(img)\n","    font     = ImageFont.truetype(r'font.ttf', 10) \n","\n","    for row in range(grid_w):\n","\n","        for col in range(grid_h):\n","\n","            # get current target for this grid\n","            target_grid = target[col*grid_h+row]\n","\n","            # call draw_box_grid() function with input img_draw, target_grid, and pad=pad\n","            y_act,_ = ??\n","\n","            if prediction is not None:\n","\n","                # get current prediction for this grid\n","                prediction_grid = prediction[col*grid_h+row]\n","\n","                # call draw_box_grid() function with input\n","                # img_draw, prediction_grid, row, col, \n","                # pad=pad, is_prediction=True, and threshold=threshold\n","                y_pred, conf = ??\n","                \n","                # set color for predicted class writing\n","                if y_pred == y_act and conf:\n","                    # correct detection\n","                    fill = 'DarkGreen'\n","                    s = str(y_act)+'-'+str(y_pred)\n","                else:\n","                    # wrong detection or low confidence\n","                    fill = 'DeepPink'\n","                    s = str(y_act)+'-'+str(y_pred)+' (?)'\n","                    \n","            else:\n","                # drawing target\n","                s = str(y_act)\n","                fill = 'black'\n","                \n","            # draw text class target/prediction\n","            img_draw.text((row+row*cell_w+pad, col+img_h*col+1+col*8), s, fill=fill, font=font)\n","\n","    # convert img into a numpy array\n","    img = np.array(img)\n","\n","    return img\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dt9bs81aoSxP"},"source":["Check your implementation\n","\n","You should see that the \"objects\" are correctly localized with its bounding boxes."]},{"cell_type":"code","metadata":{"id":"Y1eEY83rS941"},"source":["plt.figure(figsize=(15,8))\n","for i in range(10):\n","    img = draw_bbox(x_train[i], y_train[i])\n","    plt.subplot(2,5,i+1)\n","    plt.imshow(img)\n","    plt.axis('off')\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p-ReETgxLn2r"},"source":["---\n","---\n","#[Part 3] YOLO Detection\n","\n","And we're arrive at the main function, the YOLO Detection itself\n","\n","<center>\n","<img src='https://miro.medium.com/max/804/1*jtnrhMFNwGxiQmkY6LkdCQ.jpeg'>\n","</center>\n","\n","\n","First we define our classification model. The original YOLO network consists of $24$ convolutional layers alternating between $3\\times 3$ convolution and $1\\times 1$ bottleneck layers to reduce the features space from preceding layers, followed by $2$ FC layers from a $448\\times 448$ image input. But for our simple exercise, we won't need that big network.\n","\n","So let's define our own"]},{"cell_type":"markdown","metadata":{"id":"Vu2pod4dLrQO"},"source":["---\n","## 1 - Define Input Shape\n","\n","Use Functional API to build the model.\n"]},{"cell_type":"markdown","metadata":{"id":"82UWZtXjnVpW"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","Define input and output shape"]},{"cell_type":"code","metadata":{"id":"GVrmLr48Z8kN"},"source":["# input shape is a tuple of image height, image width, and 3 channel\n","input_shape   = ??\n","\n","# total grid is grid width * grid height\n","total_grid    = ??\n","\n","# anchor length is number class + number anchor * 5\n","anchor_length = ??"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i8U57nkknVcP"},"source":["Check your implementation "]},{"cell_type":"code","metadata":{"id":"vyebhptVaCpO"},"source":["print('input shape   :', input_shape)\n","print('total grid    :', total_grid)\n","print('anchor length :', anchor_length)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EP0d2sTuafJX"},"source":["**EXPECTED OUTPUT**:\n","\n","if you're using default $3$ classes $64\\times 64$ image with $2\\times 2$ grid\n","\n","<pre>\n","input shape   : (64, 64, 3)\n","total grid    : 4\n","anchor length : 8"]},{"cell_type":"markdown","metadata":{"id":"pxchNUdbqi5C"},"source":["---\n","## 2 - Define Classification Model\n","\n","Use Functional API to build the model.\n"]},{"cell_type":"markdown","metadata":{"id":"AgJ9PebndIZ5"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","Build model implementing the architecture as follow\n","\n","<pre>\n","    * <b>Input</b> layer of  <font color='blue'><b>(img_h,img_w,3)</b></font>  \n","    * <b>conv</b> layer with <font color='blue'><b>16</b></font> filters of <font color='blue'><b>1x1</b></font> without activation\n","    * <b>conv</b> layer with <font color='blue'><b>32</b></font> filters of <font color='blue'><b>3x3</b></font> without activation\n","    * <b>LeakyReLU</b> activation with alpha <font color='blue'><b>0.01</b></font> \n","    * <b>MaxPool2D</b> layer      \n","    * <b>conv</b> layer with <font color='blue'><b>16</b></font> filters of <font color='blue'><b>3x3</b></font> without activation\n","    * <b>conv</b> layer with <font color='blue'><b>32</b></font> filters of <font color='blue'><b>3x3</b></font> without activation\n","    * <b>LeakyReLU</b> activation with alpha <font color='blue'><b>0.01</b></font> \n","    * <b>MaxPool2D</b> layer      \n","    * <b>Flatten</b> layer \n","    * <b>Fully connected</b> layer with <font color='blue'><b>256</b></font> neurons and activation <font color='blue'><b>sigmoid</b></font>\n","    * <b>Fully connected</b> layer with <font color='blue'><b>output_shape</b></font> neurons and activation <font color='blue'><b>sigmoid</b></font>\n","    * <b>Reshape</b> layer to reshape output activation to <font color='blue'><b>(grid, anchors)</b></font>  shape\n","</pre>"]},{"cell_type":"code","metadata":{"id":"7sb-dY8LQYvU"},"source":["# define Input() layer with shape=input_shape\n","input_tensor = ??\n","\n","# add conv2d to input_tensor with 16 filters, kernel size 1\n","x = ?? (??)\n","\n","# add conv2d to x with 32 filters, kernel size 3\n","x = ?? (??)\n","\n","# add leakyrelu to x alpha=0.3\n","x = ?? (??)\n","\n","# add maxpool2d layer to x\n","x = ?? (??)\n","\n","# add conv2d to x with 16 filters, kernel size 3\n","x = ?? (??)\n","\n","# add conv2d to x with 32 filters, kernel size 3\n","x = ?? (??)\n","\n","# add leakyrelu to x alpha=0.3\n","x = ?? (??)\n","\n","# add maxpool2d layer to x\n","x = ?? (??)\n","\n","# add flatten layer to x\n","x = ?? (??)\n","\n","# add dense layer to x with 256 neurons and sigmoid activation\n","x = ?? (??)\n","\n","# add dense layer to x with total_grid * anchor_length neurons and sigmoid activation\n","x = ?? (??)\n","\n","# add reshape layer to x with input (total_grid, anchor_length)\n","output_tensor = Reshape((total_grid, anchor_length))(x)\n","\n","# initialize model by calling Model() function with input input_tensor and output_tensor\n","model = ??"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_HS38mhyqy5d"},"source":["Now to check your implementation"]},{"cell_type":"code","metadata":{"id":"h2b_OIbD1Qwv"},"source":["print(model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zZFcAz0yV6f0"},"source":["**EXPECTED OUTPUT**:\n","\n","if you're using default $3$ classes $64\\times 64$ image with $2\\times 2$ grid\n","\n","<pre>\n","input_? (InputLayer)         [(None, 64, 64, 3)]       0         \n","conv2d (Conv2D)              (None, 64, 64, 16)        64        \n","...\n","dense_? (Dense)              (None, 32)                8224      \n","reshape (Reshape)            (None, 4, 8)              0         \n","\n","Total params: 1,406,896\n","Trainable params: 1,406,896\n","Non-trainable params: 0\n","_________________________________________________________________"]},{"cell_type":"markdown","metadata":{"id":"tfq1R4knnu1o"},"source":["Visualize the Network architecture"]},{"cell_type":"code","metadata":{"id":"R7x7KSnbTVCQ"},"source":["plot_model(model, show_shapes=True,\n","    show_layer_names=False,\n","    rankdir='LR',\n","    expand_nested=False,\n","    dpi=60\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7NjxRqxGLx67"},"source":["---\n","## 3 - Define Loss\n","\n","YOLO uses sum-squared error between the predictions and the ground truth to calculate loss. \n","\n","The loss function composes of:\n","* the **classification loss.**\n","* the **localization loss** (errors between the predicted boundary box and the ground truth).\n","* the **confidence loss** (the objectness of the box)."]},{"cell_type":"markdown","metadata":{"id":"Jbdz8h19wjiT"},"source":["---\n","### a. Classification Loss\n","If an object is detected, the classification loss at each cell is the squared error of the class conditional probabilities for each class:\n","\n","$$\n"," \\sum_{i=0}^{S^2}{1}_i^\\text{obj} \\sum_{c \\in \\text{classes}}\\big(p_i(c)-\\hat{p_i}(c)\\big)^2\n","$$"]},{"cell_type":"markdown","metadata":{"id":"TYBTjrpSyPQ4"},"source":["---\n","### b. Localization Loss\n","The localization loss measures the errors in the predicted boundary box locations and sizes. We only count the box responsible for detecting the object.\n","\n","$$\n"," x\\lambda_\\text{coord}\\sum_{i=0}^{S^2}\\sum_{j=0}^{B}{1}_{ij}^\\text{obj} \\big[(x_i-\\hat{x}_i)^2+(y_i-\\hat{y}_i)^2\\big]\\\\+\\lambda_\\text{coord}\\sum_{i=0}^{S^2}\\sum_{j=0}^{B}\\rm{1}_{ij}^\\text{obj} \\big[(\\sqrt{w_i}-\\sqrt{\\hat{w}_i})^2+(\\sqrt{h_i}-\\sqrt{\\hat{h}_i})^2\\big]\n","$$"]},{"cell_type":"markdown","metadata":{"id":"riqcUuWRyPTg"},"source":["---\n","### c. Confidence Loss\n","If an object is detected in the box, the confidence loss (measuring the objectness of the box) is:\n","$$\n","\\sum_{i=0}^{S^2}\\sum_{j=0}^{B}{1}_{ij}^\\text{obj}(C_i-\\hat{C}_i)^2\n","$$\n","\n","If an object is **NOT** detected in the box, the confidence loss is:\n","$$\n","\\lambda_\\text{noobj}\\sum_{i=0}^{S^2}\\sum_{j=0}^{B}{1}_{ij}^\\text{noobj}(C_i-\\hat{C}_i)^2\n","$$"]},{"cell_type":"markdown","metadata":{"id":"-3Tl8aL1q8KQ"},"source":["---\n","### d. Complete Implementation\n","\n","Now don't be disheartened, we already prepared the loss implementation for you. So read the code carefully."]},{"cell_type":"code","metadata":{"id":"Z2BDqW2OQldU"},"source":["def custom_loss(y_true, y_pred):\n","  \n","    grid = np.array([ [[float(x),float(y)]]*nb_anchor   for y in range(grid_h) for x in range(grid_w)])\n","\n","    # get the actual and predicted class\n","    y_true_class   = y_true[...,0:nb_class-1]\n","    y_pred_class   = y_pred[...,0:nb_class-1]\n","\n","    # get the actual and predicted box\n","    pred_boxes     = K.reshape(y_pred[...,nb_class:], (-1,grid_w*grid_h,nb_anchor,5))\n","    true_boxes     = K.reshape(y_true[...,nb_class:], (-1,grid_w*grid_h,nb_anchor,5))\n","    \n","    # get predicted coordinates and confidence\n","    y_pred_xy      = pred_boxes[...,0:2] + K.variable(grid)\n","    y_pred_wh      = pred_boxes[...,2:4]\n","    y_pred_conf    = pred_boxes[...,4]\n","   \n","    # get actual coordinates and confidence\n","    y_true_xy      = true_boxes[...,0:2]\n","    y_true_wh      = true_boxes[...,2:4]\n","    y_true_conf    = true_boxes[...,4]\n","\n","    # calculate classification loss\n","    clss_loss      = K.sum(K.square(y_true_class - y_pred_class), axis=-1)\n","    \n","    # calculate localization loss\n","    xy_loss        = K.sum(K.sum(K.square(y_true_xy - y_pred_xy),axis=-1)*y_true_conf, axis=-1)\n","    wh_loss        = K.sum(K.sum(K.square(K.sqrt(y_true_wh) - K.sqrt(y_pred_wh)), axis=-1)*y_true_conf, axis=-1)\n","\n","    # non-max suppression\n","    intersect_wh   = K.maximum(K.zeros_like(y_pred_wh), (y_pred_wh + y_true_wh)/2 - K.abs(y_pred_xy - y_true_xy) )\n","    intersect_area = intersect_wh[...,0] * intersect_wh[...,1]\n","\n","    true_area      = y_true_wh[...,0] * y_true_wh[...,1]\n","    pred_area      = y_pred_wh[...,0] * y_pred_wh[...,1]\n","\n","    # calculate intersection over union\n","    union_area     = pred_area + true_area - intersect_area\n","    iou            = intersect_area / union_area\n","\n","    # calculate confidence loss\n","    conf_loss      = K.sum(K.square(y_true_conf*iou - y_pred_conf)*y_true_conf, axis=-1)\n","\n","    # sum all losses\n","    d = clss_loss + xy_loss + wh_loss + conf_loss    \n","\n","    return d"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RONoPBO4L8QD"},"source":["---\n","## 4 - Compile Model\n","\n","Now compile model by adding the custom loss and Adam optimizer"]},{"cell_type":"markdown","metadata":{"id":"1go-FVJ91tXL"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","compile model using custom_loss and Adam optimizer with lr=0.001"]},{"cell_type":"code","metadata":{"id":"MMMwxYswQyos"},"source":["from tensorflow.keras.optimizers import Adam\n","\n","# initialize Adam optimizer with lr=0.001\n","myAdam = ??\n","\n","# compile model with loss=custom_loss and optimizer=myAdam\n","model.??"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M0y1uR1YL-rk"},"source":["---\n","## 5 - Train Model\n","\n","Train the model for 80 epochs"]},{"cell_type":"code","metadata":{"id":"ySRznr3VTj6x"},"source":["hist = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=512, epochs=80)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KfoRy05W2s9i"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","your loss should start around 0.6 and end around 0.01 after 80 epochs"]},{"cell_type":"markdown","metadata":{"id":"46S7or-A1_w-"},"source":["Visualize training history"]},{"cell_type":"code","metadata":{"id":"hljJ-XMlrzrC"},"source":["plt.rcParams['figure.figsize'] = [8, 4]\n","plt.subplots_adjust(wspace=0.2)\n","\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Val'])\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gl1Nk0mTMFdW"},"source":["---\n","## 6 - Test Detection\n","\n","Let's show the detection results"]},{"cell_type":"markdown","metadata":{"id":"95z4KPICQbmH"},"source":["---\n","### a. Using Data Train\n","\n","First, let's see the performance on training data"]},{"cell_type":"code","metadata":{"id":"zyuuWAtl-CQM"},"source":["y_pred = model.predict(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CL0zNI37-CN_"},"source":["plt.figure(figsize=(15,8))\n","for i in range(10):\n","    img = draw_bbox(x_train[i], y_train[i], y_pred[i], threshold=0.1)\n","    plt.subplot(2,5,i+1)\n","    plt.imshow(img)\n","    plt.axis('off')\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_ssSEAN52H8h"},"source":["You should see that most of the objects are detected with quite precision\n","\n","the <font color=DeepPink>**pink**</font> label and <font color=RoyalBlue>**blue**</font> detection box means low confidence or wrong classification\n","\n","you can train it longer to get more precision on the detection box\n","\n","you can also lower the threshold when drawing the detection box\n"]},{"cell_type":"markdown","metadata":{"id":"XDK3_BnZQlgd"},"source":["---\n","### b. Using Data Validation\n","\n","\n","Now view the detection results on validation data "]},{"cell_type":"code","metadata":{"id":"yfmnH3JBX4zg"},"source":["y_pred_val = model.predict(x_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zt96cZ7mX4zl"},"source":["plt.figure(figsize=(15,8))\n","for i in range(10):\n","    img = draw_bbox(x_val[i], y_val[i], y_pred_val[i], threshold=0.1)\n","    plt.subplot(2,5,i+1)\n","    plt.imshow(img)\n","    plt.axis('off')\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GloxDfAiXypL"},"source":["---\n","### c. Using Data Test\n","\n","Lastly, let's generate another 20 new data, and test it "]},{"cell_type":"code","metadata":{"id":"1EpVJUR2Xp6W"},"source":["# generate 20 new data\n","x_test, y_test = generate_data(20)\n","\n","# predict new data\n","y_pred_test = model.predict(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GTF5rODRXjcd"},"source":["plt.figure(figsize=(15,12))\n","for i in range(20):\n","    img = draw_bbox(x_test[i], y_test[i], y_pred_test[i], threshold=0.1)\n","    plt.subplot(4,5,i+1)\n","    plt.imshow(img)\n","    plt.axis('off')\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aQqQ_gcO92ub"},"source":["\n","---\n","\n","# Congratulation, You've Completed Exercise 15\n","<p>Copyright &copy;  <a href=https://www.linkedin.com/in/andityaarifianto/>2020 - ADF</a> </p>"]},{"cell_type":"markdown","metadata":{"id":"7_Hkr9kg9Do-"},"source":["![footer](https://i.ibb.co/yX0jfMS/footer2020.png)"]}]}