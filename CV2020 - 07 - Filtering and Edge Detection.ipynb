{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CV2020 - 07 - Filtering and Edge Detection.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"f_ChrQTZyAZU"},"source":["![title](https://i.ibb.co/f2W87Fg/logo2020.png)\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"oUkeuLWzoHoN"},"source":["<table  class=\"tfo-notebook-buttons\" align=\"left\"><tr><td>\n","    \n","<a href=\"https://colab.research.google.com/github/adf-telkomuniv/CV2020_Exercises/blob/main/CV2020 - 07 - Filtering and Edge Detection.ipynb\" source=\"blank\" ><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>\n","</td><td>\n","<a href=\"https://github.com/adf-telkomuniv/CV2020_Exercises/blob/main/CV2020 - 07 - Filtering and Edge Detection.ipynb\" source=\"blank\" ><img src=\"https://i.ibb.co/6NxqGSF/pinpng-com-github-logo-png-small.png\"></a>\n","    \n","</td></tr></table>"]},{"cell_type":"markdown","metadata":{"id":"sjlcHwermNUS"},"source":["\n","# Task 7 - Filtering and Edge Detection\n","\n","Previously, you have tried implementing Convolution and use it for a few Image Processing tasks like shifting, blurring, and edge detection (Sobel). However, those convolution implementations were mostly intended for creating a Convolutional Layer for CNNs. That's why it's 3D shaped.\n","\n","But this time, we will try the already built-in convolution operation from SciPy library and perform several classical computer vision tasks like Smoothing and Edge Detection.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6VAE_sE-Bgk1"},"source":["---\n","---\n","#[Part 0] Import Libraries "]},{"cell_type":"markdown","metadata":{"id":"TTQ4Oo52-b00"},"source":["---\n","## 1 - Import Libraries\n","\n","Write down your Name and Student ID"]},{"cell_type":"code","metadata":{"id":"S5yg44U8cZzk"},"source":["## --- start your code here ----\n","\n","NIM = ??\n","Nama = ??\n","\n","## --- end your code here ----"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DvPSXMEIaFm1"},"source":["Import required libraries"]},{"cell_type":"code","metadata":{"id":"hsZYqgngcZzY"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy import ndimage\n","from skimage.color import rgb2gray"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yhwf0dGRILme"},"source":["---\n","## 2 - Helper Functions\n","below are helper functions to load an image and show a list of images"]},{"cell_type":"markdown","metadata":{"id":"FeYVjP9qIXad"},"source":["---\n","### a. Load Image"]},{"cell_type":"code","metadata":{"id":"waAnj4GPgL7G","cellView":"both"},"source":["def load_image(filename):\n","    img = rgb2gray(plt.imread(filename))\n","    img = np.array(img)\n","\n","    return img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oSbz8bzAIajk"},"source":["---\n","### b. Show Images"]},{"cell_type":"code","metadata":{"id":"w9i9dh13gL-H"},"source":["def show_images(images, titles, width=4, figsize=(6,6) ):\n","    i, j = 0, 1\n","    k = len(images)\n","    if k>width:\n","        j = k//width+1\n","        k = width\n","    x = figsize[0]*k\n","    y = figsize[1]*j\n","    plt.rcParams['figure.figsize'] =  (x, y) \n","    for img, title in zip(images, titles):\n","        i+=1\n","        plt.gray()\n","        plt.subplot(j, k, i)\n","        plt.imshow(img)\n","        plt.title(title)\n","        plt.axis('off')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"siRd12aYIgO7"},"source":["---\n","## 3 - Load an Image\n","\n","Now let's download an image for us to use in this exercise. \n","\n","Below we have provided you an url to Lena test image, but you may change it to other image."]},{"cell_type":"code","metadata":{"id":"tGD_pLVegMAo"},"source":["!wget -q -O 'input.png' 'https://upload.wikimedia.org/wikipedia/en/thumb/7/7d/Lenna_%28test_image%29.png/220px-Lenna_%28test_image%29.png'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nlqTx68rI-sQ"},"source":["Then let's visualize the image"]},{"cell_type":"code","metadata":{"id":"x9pfuzRbgL4f"},"source":["ori_img = load_image( 'input.png' )\n","show_images([ori_img], [' Original Image'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bg8jDUqPJIYr"},"source":["---\n","---\n","#[Part 1] Filtering using Convolution\n","\n","You have learned about filtering using convolution functions. Now it's the time to test it to filter an image using different kind of kernels"]},{"cell_type":"markdown","metadata":{"id":"LGnUIrSbJIY4"},"source":["---\n","## 1 - Shift Left Kernel\n","\n","You've learned about kernel to shift an image, so now implement a $5\\times5$ kernel to perform the left shift operation"]},{"cell_type":"markdown","metadata":{"id":"zq42FNsRlICi"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","Complete the $5\\times5$ shift kernel. Use `np.array()` or `np.zeros()`"]},{"cell_type":"code","metadata":{"id":"3qb9UVPGtksA"},"source":["shift_kernel = ??"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uLBhrm6azJZd"},"source":["print the kernel"]},{"cell_type":"code","metadata":{"id":"mqp8rJHAzJZk"},"source":["print(shift_kernel)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z1R4w1QpzJZy"},"source":["**EXPECTED OUTPUT**:\n","<pre>[[0 0 0 0 0]\n"," [0 0 0 0 0]\n"," [1 0 0 0 0]\n"," [0 0 0 0 0]\n"," [0 0 0 0 0]]"]},{"cell_type":"markdown","metadata":{"id":"07gnc364KL3D"},"source":["Now let's use the filter and convolve it into the image. Here we're using the `convolve` function from `ndimage.filters` library.\n","\n","Shifting the image once may not be too visible the difference, so let's do it 5 times. \n","\n","Then visualize the result."]},{"cell_type":"code","metadata":{"id":"23hG_UBatkpv"},"source":["shifted = ori_img\n","for i in range(5):\n","    shifted = ndimage.filters.convolve(shifted, shift_kernel, mode='constant')\n","\n","show_images([shifted], ['shifted left 5 times'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OfHVdp8FcZ1w"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src='https://i.ibb.co/FDYfG6Q/01-shift.png' height=150>"]},{"cell_type":"markdown","metadata":{"id":"E0gJIBBGLmk7"},"source":["---\n","## 2 - Box Smoothing Kernel\n","\n","You've also learned about Box Smoothing or Box Filtering. \n","\n","So now implement a kernel to perform the $5\\times5$ Box Filtering"]},{"cell_type":"markdown","metadata":{"id":"442vacdPNZws"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","Complete the $ 5\\times5 $ box kernel. Use `np.array()` or `np.ones()`"]},{"cell_type":"code","metadata":{"id":"Ur6QqTngtkmi"},"source":["box_kernel = ??\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0SVioBm3zAgV"},"source":["print the kernel"]},{"cell_type":"code","metadata":{"id":"VuDbXNr1y4qp"},"source":["print(box_kernel)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HTzAi5s_y_8c"},"source":["**EXPECTED OUTPUT**:\n","<pre>[[0.04 0.04 0.04 0.04 0.04]\n"," [0.04 0.04 0.04 0.04 0.04]\n"," [0.04 0.04 0.04 0.04 0.04]\n"," [0.04 0.04 0.04 0.04 0.04]\n"," [0.04 0.04 0.04 0.04 0.04]]"]},{"cell_type":"markdown","metadata":{"id":"XG7d0m2YMzPR"},"source":["Filter the image, then visualize the result."]},{"cell_type":"code","metadata":{"id":"XT0BfIGutkjY"},"source":["box_blur = ndimage.filters.convolve(ori_img, box_kernel)\n","\n","show_images([ori_img, box_blur], ['Original','Box Smoothing 5x5'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z6OibTArQOKX"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src='https://i.ibb.co/HPRs6nr/02-box.png' height=150>"]},{"cell_type":"markdown","metadata":{"id":"1TaubuAouLyE"},"source":["---\n","## 3 - Detail Kernel\n","\n","Now, what would happened if we substract the Original image with the box blurred image?"]},{"cell_type":"code","metadata":{"id":"OtHunLI5vTAj"},"source":["detail_1 = ori_img - box_blur\n","\n","show_images([ori_img, box_blur, detail_1], ['Original','Box Smoothing 5x5', 'Original-Box Blur'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ePyOFXC_vtmT"},"source":["Turns out we get the detail feature of the image.\n","\n","And you've learned that Convolution is associative and distributes over addition. \n","\n","$$\n","I_1=(I*f_1)\\qquad I_2=(I*f_2)\n","$$\n","\n","$$\n","\\begin{align}\n","I_1-I_2& = (I*f_1)-(I*f_2) \\\\\n","& = I*(f1-f2)\\end{align}\n","$$\n","<br>\n","\n","Therefore we can achieve the same result by calculating the third kernel as\n","$f_3=f_1-f_2$ <br> with $f_1$ is an identity kernel\n","\n","<br>\n","$$\n","f_1 = \\left[\\begin{array}{ccccc}0&0&0&0&0\\\\\n","0&0&0&0&0\\\\0&0&1&0&0\\\\\n","0&0&0&0&0\\\\0&0&0&0&0\\end{array}\\right]\n","$$"]},{"cell_type":"markdown","metadata":{"id":"kS8VEbPSuLyM"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","Complete the $5\\times5$ identity kernel. Use `np.array()` or `np.zeros()`"]},{"cell_type":"code","metadata":{"id":"WvuWtKFZyVNx"},"source":["identity_kernel = ??\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eGZUTxkVzkkG"},"source":["print the kernel"]},{"cell_type":"code","metadata":{"id":"DZ3HHImFzkkJ"},"source":["print(identity_kernel)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Gcy0L79zkkT"},"source":["**EXPECTED OUTPUT**:\n","<pre>[[0 0 0 0 0]\n"," [0 0 0 0 0]\n"," [0 0 1 0 0]\n"," [0 0 0 0 0]\n"," [0 0 0 0 0]]"]},{"cell_type":"markdown","metadata":{"id":"yoTTk5QPz3gm"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","Complete the detail kernel by substracting identity kernel with box kernel"]},{"cell_type":"code","metadata":{"id":"8aWlXOOBzpRh"},"source":["detail_kernel = ??"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l8FQQgcWzpRo"},"source":["print the kernel"]},{"cell_type":"code","metadata":{"id":"73X9BcA5zpRr"},"source":["print(detail_kernel)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wAMsExkTzpRz"},"source":["**EXPECTED OUTPUT**:\n","<pre>[[-0.04 -0.04 -0.04 -0.04 -0.04]\n"," [-0.04 -0.04 -0.04 -0.04 -0.04]\n"," [-0.04 -0.04  0.96 -0.04 -0.04]\n"," [-0.04 -0.04 -0.04 -0.04 -0.04]\n"," [-0.04 -0.04 -0.04 -0.04 -0.04]]"]},{"cell_type":"markdown","metadata":{"id":"SfjCFIYC0GW0"},"source":["Now filter the image and visualize the result."]},{"cell_type":"code","metadata":{"id":"ZMKMZl_H0GW3"},"source":["detail_2 = ndimage.filters.convolve(ori_img, detail_kernel)\n","\n","show_images([ori_img, box_blur, detail_2], ['Original','Box Smoothing 5x5', 'Detail Kernel'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"11oL5X4Y0GXA"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src='https://i.ibb.co/YDQcqsr/02b-detail.png' height=150>"]},{"cell_type":"markdown","metadata":{"id":"cfI-ngSJNLoJ"},"source":["---\n","## 4 - Gaussian Smoothing Kernel\n","\n","Next is the gaussian filtering. This is different from the previous two, here you actually need a function to build the kernel\n","\n","Gaussian function is defined as:<br>\n","\n","$$\n","g(x, y) = \\frac{1}{2\\pi\\sigma^2}\\exp{(-\\dfrac{x^2+y^2}{2\\sigma^2})}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"1MjACrCKNLoM"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","Complete the Gaussian Function. Use `np.pi`"]},{"cell_type":"code","metadata":{"id":"h54K2UXUnVKy"},"source":["def gaussian_fn(size=3, sigma=1):\n","\n","    size = int(size) // 2\n","    x, y = np.mgrid[-size:size+1, -size:size+1]\n","\n","    g = ??\n","\n","    return g"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SgU1_OQzOjOO"},"source":["Now create a $5\\times5$ Gaussian Kernel with standard deviation of 1.4"]},{"cell_type":"markdown","metadata":{"id":"NXXgR4VQOlSg"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","Call the Gaussian Function with `size=5` and `sigma=1.4`"]},{"cell_type":"code","metadata":{"id":"OEnyjLcAznjy"},"source":["gauss_kernel = ??"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"guObZ2StPK4U"},"source":["You've seen how to use the `convolve` function, now use it to perform Gaussian Smoothing to the image"]},{"cell_type":"markdown","metadata":{"id":"O0N0dv8iPCNA"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","Call `ndimage.filters.convolve` with input `ori_img` and `gauss_kernel`"]},{"cell_type":"code","metadata":{"id":"4A0u-5K7Pc5s"},"source":["gauss_blur = ??"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jLhzBaStPlI4"},"source":["Now let's visualize the filter and the gaussian smoothing result"]},{"cell_type":"code","metadata":{"id":"KlQzySFMnthF"},"source":["images = [ori_img, gauss_kernel, gauss_blur]\n","titles = ['Original', 'Gaussian Filter', 'Gaussian Smoothing']\n","show_images(images, titles)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UgfO1QqWQVbQ"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src='https://i.ibb.co/Q8hX28J/03-gaus1.png' height=150>"]},{"cell_type":"markdown","metadata":{"id":"I-bg4Z9hPtM4"},"source":["Let's compare the result between Box Filter and Gaussian Filter"]},{"cell_type":"code","metadata":{"id":"9MdbHxIR0SPJ"},"source":["images = [ori_img, box_blur, gauss_blur]\n","titles = ['Original', 'Box Smoothing 5x5', 'Gaussian Smoothing']\n","show_images(images, titles)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ve5MU20UQZnH"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src='https://i.ibb.co/2Nxdk2s/04-gaus2.png' height=150>"]},{"cell_type":"markdown","metadata":{"id":"QO4edMszQ8sF"},"source":["---\n","---\n","# [Part 2] Sobel Edge Detector\n","Moving on, now we will implement two famous Edge Detection Algorithms: Sobel Edge Detector and Canny Edge Detector.\n","\n","Sobel operator or Sobel filter creates an image emphasising edges. Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function.\n"]},{"cell_type":"markdown","metadata":{"id":"K4zXRwNV_-Ls"},"source":["---\n","## 1 - Image Gradient\n","\n","\n","Sobel Edge Detector defined by computing the image derivative in $x$ and $y$ direction, then calculate the Gradient Magnitude $(G)$. \n","\n","The Sobel operator ended by thresholding the magnitude.\n","\n","The kernels for Sobel Operator are defined as:\n","\n","<br>\n","\n","$$\n","K_x=\\left[ \\begin{array}{ccc}-1 &0 &1\\\\-2 &0 &2\\\\-1 &0 &1 \\end{array} \\right] \\qquad K_y=\\left[ \\begin{array}{ccc}1 &2 &1\\\\0 &0 &0\\\\-1 &-2 &-1 \\end{array} \\right]\n","$$\n","\n","<br>\n","\n","While computing the gradient, here we'll also compute the Gradient Orientation $(\\theta)$ to use it later in Canny Edge Detector"]},{"cell_type":"markdown","metadata":{"id":"YrhEXHCkQjI4"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","Complete the Sobel Filtering Function"]},{"cell_type":"code","metadata":{"id":"VBs2FzDghwOU"},"source":["def sobel_filter(img):\n","\n","    #define the kernels\n","    Kx = ??\n","    Ky = ??\n","\n","    # convolve each kernel to input image\n","    Ix = ??\n","    Iy = ??\n","\n","    G = np.hypot(Ix, Iy)\n","    G = G / G.max() * 255\n","    theta = np.arctan2(Iy, Ix)\n","\n","    return G, theta"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wd9yYwaM8Fey"},"source":["With that, let's calculate the gradient magnitude from original image using sobel filter"]},{"cell_type":"code","metadata":{"id":"6zpglZku1trI"},"source":["g_ori, t_ori = sobel_filter(ori_img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qPcCEjlG8Spl"},"source":["Now to visualize the gradient magnitude and orientation"]},{"cell_type":"code","metadata":{"id":"ylSXNYkF1sFG"},"source":["images = [ori_img, g_ori, t_ori ]\n","titles = ['Original', 'Gradient Magnitude', 'Gradient Orientation']\n","show_images(images, titles)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CpDyXKE3-boV"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src='https://i.ibb.co/8sQ6VQ8/05-ori-grad.png' height=150>"]},{"cell_type":"markdown","metadata":{"id":"NN4qOHFNAJU4"},"source":["You should see that using Sobel Operator we can already detect the edges"]},{"cell_type":"markdown","metadata":{"id":"L3T23B0GAPZU"},"source":["---\n","## 2 - SciPy Sobel Library\n","\n","Now let's compare our implementation with the Sobel funtion from SciPy Library"]},{"cell_type":"code","metadata":{"id":"5FkSXTk04di3"},"source":["Ix    = ndimage.sobel(ori_img,0)\n","Iy    = ndimage.sobel(ori_img,1)\n","lib_sobel = np.hypot(Ix,Iy)\n","\n","images = [ori_img, g_ori, lib_sobel, Ix, Iy ]\n","titles = ['Original', 'Sobel Manual', 'Sobel Library', 'Gradient in x-direction', 'Gradient in y-direction']\n","show_images(images, titles, width=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RoVDOPC_AiJR"},"source":["The results of your implementation should match those of the sobel library"]},{"cell_type":"markdown","metadata":{"id":"e5rct2UEEJMy"},"source":["---\n","---\n","# [Part 3] Canny Edge Detector\n","The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. It was developed by John F. Canny in 1986. This technique dramatically reduce the amount of data to be processed and has been widely applied in various computer vision systems. \n"]},{"cell_type":"markdown","metadata":{"id":"GsPbnrpyFPm8"},"source":["---\n","## 1 - Gaussian Smoothing\n","\n","Since all edge detection results are easily affected by the noise in the image, it is essential to filter out the noise to prevent false detection caused by it.\n","\n","Here, Canny use Gaussian filtering to smoothen the image.\n","\n","Since we have already performed Gaussian Smoothing up above, so we can just use the `gauss_blur` result"]},{"cell_type":"markdown","metadata":{"id":"dlohyIJ3F6vK"},"source":["---\n","## 2 - Gradient Intensity\n","\n","The next step is to use the Sobel Filter to the blurred image to get the gradient magnitudes and its orientations.\n","\n","And we've already implemented the `sobel_filter()` before, so"]},{"cell_type":"markdown","metadata":{"id":"HI1mzAMXGgZf"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","call `sobel_filter()` function with input `gauss_blur`"]},{"cell_type":"code","metadata":{"id":"8NkNVZo1CNNa"},"source":["g_blur, t_blur = ??"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WKrYm16dG5of"},"source":["Now let's visualize the gradient magnitude and orientation. \n","\n","Along with that, let's also compare it with the result of sobel operator in the original image"]},{"cell_type":"code","metadata":{"id":"QlWOOT_kCNNo"},"source":["images = [ori_img, g_ori, t_ori, gauss_blur, g_blur, t_blur ]\n","titles = ['Original', 'Gradient Magnitude', 'Gradient Orientation', \n","          'Gaussian Smoothing', 'Gaussian Magnitude', 'Gaussian Orientation']\n","show_images(images, titles, width=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LOw-YQJi-d2y"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src='https://i.ibb.co/HHZSBJ8/07-ori-sobel.png' height=300>"]},{"cell_type":"markdown","metadata":{"id":"BjvprRnwHdiU"},"source":["You should see that as we reduce the noise, we also achieved thicker edge blob from the blurred image. And that's not good"]},{"cell_type":"markdown","metadata":{"id":"Xxng3KCZH8k8"},"source":["---\n","## 3 - Non-Maximum Suppression\n","\n","That's why the next step is to mitigate the thick edges, as ideally, the final edge image should have thin edges. Thus, we must perform non-maximum suppression to thin out the edges.\n","\n","The principle is simple: the algorithm goes through all the points on the gradient intensity matrix and finds the pixels with the maximum value in the edge directions\n","\n","<center>\n","<img src='https://i.ibb.co/WDSTsdY/14-non-max.png' height=300>\n","</center>\n","\n","So we need to compare current pixel gradient (`gradient[i,j]`) with one pixel ahead in its direction (we call it `a`) and one pixel behind it (we call it `b`).\n","\n","Since it's symmetrical, so we only need to compare in 4 directions:\n","<pre>              a              b\n","* angle 0  : [i  , j+1] and [i, j-1] \n","* angle 45 : [i+1, j-1] and [i-1, j+1] \n","* angle 90 : [i+1, j]   and [i-1, j] \n","* ange 135 : [i+1, j+1] and [i-1, j-1]</pre>"]},{"cell_type":"markdown","metadata":{"id":"eWi9s-qkIj1A"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","complete the function"]},{"cell_type":"code","metadata":{"id":"cByces29x8BV"},"source":["def non_max_suppression(gradient, direction):\n","        M, N = gradient.shape\n","        Z = np.zeros((M,N), dtype=np.int32)\n","\n","        # calculate the angle based on\n","        # the gradient direction\n","        angle = direction * 180. / np.pi\n","        angle[angle < 0] += 180\n","\n","        # loop through all pixels\n","        # get gradient one pixel ahead and behind\n","        # compare with current gradient\n","        for i in range(1,M-1):\n","            for j in range(1,N-1):\n","                try:\n","                    a = 255\n","                    b = 255\n","\n","                   #angle 0\n","                    if (0 <= angle[i,j] < 22.5) or (157.5 <= angle[i,j] <= 180):\n","                        a = gradient[??,??]\n","                        b = gradient[??,??]\n","                    #angle 45\n","                    elif (22.5 <= angle[i,j] < 67.5):\n","                        a = ??\n","                        b = ??\n","                    #angle 90\n","                    elif (67.5 <= angle[i,j] < 112.5):\n","                        a = ??\n","                        b = ??\n","                    #angle 135\n","                    elif (112.5 <= angle[i,j] < 157.5):\n","                        a = ??\n","                        b = ??\n","\n","                    # if current gradient is bigger\n","                    # store as final gradient\n","                    if (gradient[i,j] >= a) and (gradient[i,j] >= b):\n","                        Z[i,j] = gradient[i,j]\n","                    else:\n","                        Z[i,j] = 0\n","\n","                except IndexError as e:\n","                    pass\n","\n","        return Z"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5JaaESwrPyH6"},"source":["Now let's apply the non-max suppression function to the gradient"]},{"cell_type":"code","metadata":{"id":"N9XHWcGSyER4"},"source":["suppressed = non_max_suppression(g_blur, t_blur)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Svnk_oHNP5YF"},"source":["Then visualize the supressed edge"]},{"cell_type":"code","metadata":{"id":"SK46ohPuyEPa"},"source":["images = [ori_img, g_blur, t_blur, suppressed]\n","titles = ['Original', 'Gradient Magnitude', 'Gradient Orientation', 'Suppressed']\n","show_images(images, titles)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1z0cv15K-eoM"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src='https://i.ibb.co/5vssTjM/08-suppressed.png' height=150>"]},{"cell_type":"markdown","metadata":{"id":"HX9EpzudP9o9"},"source":["You should see that now the edges have been thinned out, and it looks much more clean."]},{"cell_type":"markdown","metadata":{"id":"leqqIXbIQKWn"},"source":["---\n","## 4 - Double Threshold\n","\n","After the edges are suppressed, the image has thinner edges. We can however still notice some variation regarding the edges’ intensity: some pixels seem to be brighter than others, and we will try to cover this shortcoming with the two final steps.\n","\n","The double threshold step aims to identify and normalized 3 kinds of pixels: strong, weak, and non-relevant. \n","\n","Basically:\n","* we set all pixel higher than `high_th` threshold into `strong_pixel` value, \n","* set all pixel lower than `low_th` threshold into $0$, \n","* and all between the thresholds into `weak_pixel` value.\n"]},{"cell_type":"markdown","metadata":{"id":"k4LTSLe5Sgjt"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","complete the function"]},{"cell_type":"code","metadata":{"id":"jJ5bhqEKyEMV"},"source":["def double_threshold(img, weak_value=75, strong_value=255, low_th=0.05, high_th=0.15):\n","\n","    high_th = img.max() * high_th;\n","    low_th = high_th * low_th;\n","\n","    M, N = img.shape\n","\n","    # create zeros matrix for the result\n","    # so that we don't need to filter the low value\n","    result = np.zeros((M,N))\n","\n","    # find index of pixels higher than high_th\n","    # use np.where with condition img >= high_th\n","    strong_i, strong_j = ??\n","\n","    # find index of pixels between than low_th and high_th\n","    # use np.where with condition img < high_th & img >= low_th\n","    weak_i, weak_j = ??\n","\n","    # set strong and weak pixels with new value\n","    result[strong_i, strong_j] = strong_value\n","    result[weak_i, weak_j]     = weak_value\n","\n","    return (result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bY4XlYgcTerw"},"source":["Now perform the double threshold to the suppressed edge"]},{"cell_type":"code","metadata":{"id":"DjYhJP80ytvo"},"source":["filtered = double_threshold(suppressed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EfT8edf2TlTD"},"source":["Then visualize the filtered edge"]},{"cell_type":"code","metadata":{"id":"Ds_fj8vQ_YqS"},"source":["images = [suppressed, filtered]\n","titles = ['Supressed', 'Filtered']\n","show_images(images, titles, figsize=(7,8))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xZLCwOOW-fDD"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src='https://i.ibb.co/MZHd00f/09-suppressed-filtered.png' height=150>"]},{"cell_type":"markdown","metadata":{"id":"E7XTBCmnTses"},"source":["You should see that now there are only 2 pixel intensity values (strong and weak)\n","\n","Now if we visualize our progress, we can see that, gradually, the edges are becoming more clearer"]},{"cell_type":"code","metadata":{"id":"QMrlQa-sytso"},"source":["images = [ori_img, g_blur, suppressed, filtered]\n","titles = ['Original', 'Gradient Magnitude', 'Suppressed', 'Filtered']\n","show_images(images, titles)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oXVBmSPt-fi3"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src='https://i.ibb.co/thq69v6/10-filtered.png' height=150>"]},{"cell_type":"markdown","metadata":{"id":"wcgdnKNmUk-_"},"source":["---\n","## 5 - Edge Tracking by Hysteresis\n","\n","So far, the strong edge pixels should certainly be involved in the final edge image, as they are extracted from the true edges in the image. However, there will be some debate on the weak edge pixels, as these pixels can either be extracted from the true edge, or the noise/color variations. \n","\n","To achieve an accurate result, the weak edges caused by the latter reasons should be removed. \n","\n","Based on the threshold results, the hysteresis consists of transforming weak pixels into strong ones, if and only if at least one of the pixels around the one being processed is a strong one\n","\n","<center>\n","<img src='https://miro.medium.com/max/675/1*jnqS5hbRwAmU-sgK552Mgg.png'>\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"aDWBkEeuVPcA"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","complete the function"]},{"cell_type":"code","metadata":{"id":"xDT3lHkDytpl"},"source":["def hysteresis(img, weak_value=75, strong_value=255):\n","\n","    M, N = img.shape\n","    img = img.copy()\n","\n","    # loop through all pixels\n","    for i in range(1, M-1):\n","        for j in range(1, N-1):\n","\n","            # if it is a weak valued pixel, \n","            # check neighbor\n","            if (img[i,j] == weak_value):\n","                try:\n","                    # check if any of its 8 neighbors (adjacent pixels) is strong_value\n","                    if (??):\n","                        # if any, set this pixel as strong\n","                        img[i, j] = strong_value\n","                    else:\n","                        # else, delete\n","                        img[i, j] = 0\n","                except IndexError as e:\n","                    pass\n","\n","    return img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"miWh6CBtV3Mi"},"source":["And that's it.\n","\n","Now we can apply `hysteresis` function to the filtered edge to get the final edge image"]},{"cell_type":"code","metadata":{"id":"NJx95kM9zX2P"},"source":["final_img = hysteresis(filtered)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WPA6d1hdWGLX"},"source":["Now to visualize all of the process"]},{"cell_type":"code","metadata":{"id":"9HEnFWfnAfHD"},"source":["images = [ori_img, g_blur, t_blur, suppressed, filtered, final_img]\n","titles = ['Original', 'Gradient Magnitude', 'Gradient Orientation', 'Suppressed', 'Filtered', 'Final Edge']\n","show_images(images, titles, width=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zckmk-Ea-gDz"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src='https://i.ibb.co/2tJrh2s/11-final-edge.png' height=300>"]},{"cell_type":"markdown","metadata":{"id":"G7qQvRO5WMcC"},"source":["You should see a clean edge on the final image.\n","\n","If we compare to just the original image, we get"]},{"cell_type":"code","metadata":{"id":"yYSH7dCY5iiz"},"source":["show_images([ori_img, final_img], ['Original', 'Final Edge'], figsize=(7,8))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H2gBLbKd-hGf"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src='https://i.ibb.co/sb830L7/12-final-edge.png' height=150>"]},{"cell_type":"markdown","metadata":{"id":"32migsl_XAbA"},"source":["---\n","## 6 - Complete Function\n","\n","Just as an extra, let's gather and combine all those components together into one complete function."]},{"cell_type":"code","metadata":{"id":"1-VDloWFAtH3"},"source":["def canny_detection(img, size=5, sigma=1.4, weak_value=75, strong_value=255, low_th=0.05, high_th=0.15):\n","    gauss_kernel = gaussian_fn(size=size, sigma=sigma)\n","    gauss_blur   = ndimage.filters.convolve(img, gauss_kernel)\n","    g_ori, t_ori = sobel_filter(gauss_blur)\n","    suppressed   = non_max_suppression(g_blur, t_blur)\n","    filtered     = double_threshold(suppressed, weak_value, strong_value, low_th, high_th)\n","    result       = hysteresis(filtered, weak_value, strong_value)\n","\n","    return result\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tcnzQQ5xXdNr"},"source":["So now we can use it easily, and it should still results the same image"]},{"cell_type":"code","metadata":{"id":"xPrIF08WC8jp"},"source":["final_img = canny_detection(ori_img)\n","show_images([ori_img, final_img], ['Original', 'Final Edge'], figsize=(7,8))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k7F4Jc0AXr0s"},"source":["---\n","## 7 - Scipy Canny Detector\n","Another extra, let's compare the result with the Canny Edge Detector module from Scikit Image Library.\n","\n","Our implementation above uses `sigma=1.4`, so let's use it here too."]},{"cell_type":"code","metadata":{"id":"42ZFrsjEDgDa"},"source":["from skimage import feature\n","lib_canny = feature.canny(ori_img, sigma=1.4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"onNBXa24Y8TT"},"source":["Then visualize and compare the results"]},{"cell_type":"code","metadata":{"id":"PompZBRf700T"},"source":["images = [ori_img, final_img, lib_canny]\n","titles = ['Original', 'Final Edge', 'Canny Library']\n","show_images(images, titles, figsize=(7,8))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4LtrUhBr-htT"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src='https://i.ibb.co/gP45X7p/13-canny-lib.png' height=150>"]},{"cell_type":"markdown","metadata":{"id":"nGbAIdhdZC-1"},"source":["Not bad, eh?\n","There're still some differences here and there, but overall our Canny Edge detector implementation has had pretty good results"]},{"cell_type":"markdown","metadata":{"id":"aQqQ_gcO92ub"},"source":["\n","---\n","\n","# Congratulation, You've Completed Exercise 7\n","\n","<p>Copyright &copy;  <a href=https://www.linkedin.com/in/andityaarifianto/>2020 - ADF</a> </p>"]},{"cell_type":"markdown","metadata":{"id":"7_Hkr9kg9Do-"},"source":["![footer](https://i.ibb.co/yX0jfMS/footer2020.png)"]}]}