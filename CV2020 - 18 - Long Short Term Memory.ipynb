{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"CV2020 - 18 - Long Short Term Memory.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"f_ChrQTZyAZU"},"source":["![title](https://i.ibb.co/f2W87Fg/logo2020.png)\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"ldK4D4kkvEu-"},"source":["<table  class=\"tfo-notebook-buttons\" align=\"left\"><tr><td>\n","    \n","<a href=\"https://colab.research.google.com/github/CNN-ADF/Task2020/blob/master/notebooks/CNN2020 - 18 - Long Short Term Memory.ipynb\" source=\"blank\" ><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>\n","</td><td>\n","<a href=\"https://github.com/CNN-ADF/Task2020/blob/master/notebooks/CNN2020 - 18 - Long Short Term Memory.ipynb\" source=\"blank\" ><img src=\"https://i.ibb.co/6NxqGSF/pinpng-com-github-logo-png-small.png\"></a>\n","    \n","</td></tr></table>"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"7pXdgN4HasNh"},"source":["# Task 18 - Long Short Term Memory\n","\n","In the previous exercise you implemented a Vanilla Recurrent Neural Network and applied it to image captioning. In this notebook you will implement the Long Short-Term Memory update rule and use it for image captioning.\n","\n","\n","The goals of this assignment are as follows:\n","\n","* Understand the architecture of Long Short Term Memory (LSTM) and how they operate on sequences by sharing weights over time\n","* Understand and implement LSTMs \n","* Understand how to sample from an LSTM language model at test-time\n","* Understand how to combine convolutional neural nets and recurrent nets to implement an image captioning system"]},{"cell_type":"markdown","metadata":{"id":"SF71bN55cZzi"},"source":["Write down your Name and Student ID"]},{"cell_type":"code","metadata":{"id":"S5yg44U8cZzk"},"source":["## --- start your code here ----\n","\n","NIM  = ??\n","Nama = ??\n","\n","## --- end your code here ----"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BkN9g_WeogtU"},"source":["---\n","---\n","#[Part 0] Import Libraries \n","As usual, a bit of setup"]},{"cell_type":"code","metadata":{"id":"ihM9JDP6asNm"},"source":["import time, os, json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import urllib.request, urllib.error, urllib.parse, os, tempfile\n","from imageio import imread\n","from PIL import Image\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize']      = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap']          = 'gray'\n","\n","%load_ext autoreload\n","%autoreload 2\n","np.set_printoptions(precision=7)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PvMOoCw7ogtd"},"source":["---\n","## 1 - Helper Functions\n","\n","Below are helper functions to check your implementation"]},{"cell_type":"markdown","metadata":{"id":"Bl8Ql2-7o70u"},"source":["---\n","### a. Sigmoid Function\n","\n","A numerically stable version of the logistic sigmoid function. Use this sigmoid in LSTM"]},{"cell_type":"code","metadata":{"id":"GvODRIqdasNx"},"source":["def sigmoid(x):\n","    pos_mask = (x >= 0)\n","    neg_mask = (x < 0)\n","\n","    z = np.zeros_like(x)\n","    z[pos_mask] = np.exp(-x[pos_mask])\n","    z[neg_mask] = np.exp(x[neg_mask])\n","\n","    top = np.ones_like(x)\n","    top[neg_mask] = z[neg_mask]\n","    \n","    return top / (1 + z)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PIeMwF8obvdl"},"source":["---\n","### b. Numerical Gradient Check\n","\n","Functions to check the gradients from your implementation\n","\n","a naive implementation of numerical gradient of $f$ at $x$\n"]},{"cell_type":"code","metadata":{"id":"dKSr0LufasN1"},"source":["from random import randrange\n","\n","def eval_numerical_gradient(f, x, verbose=True, h=0.00001):\n","\n","    # evaluate function value at original point\n","    fx = f(x) \n","    grad = np.zeros_like(x)\n","\n","    # iterate over all indexes in x\n","    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n","    \n","    while not it.finished:\n","\n","        # evaluate function at x+h\n","        ix     = it.multi_index\n","        oldval = x[ix]\n","        x[ix]  = oldval + h   # increment by h\n","        fxph   = f(x)         # evalute f(x + h)\n","        x[ix]  = oldval - h\n","        fxmh   = f(x)         # evaluate f(x - h)\n","        x[ix]  = oldval       # restore\n","\n","        # compute the partial derivative with centered formula\n","        grad[ix] = (fxph - fxmh) / (2 * h) # the slope\n","\n","        if verbose:\n","            print(ix, grad[ix])\n","        it.iternext() # step to next dimension\n","\n","    return grad"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5P7el209pB5m"},"source":["---\n","### c. Array Gradient Check\n","\n","Functions to check the array of gradients from your implementation\n","\n","Evaluate a numeric gradient for a function that accepts a numpy    array and returns a numpy array.\n"]},{"cell_type":"code","metadata":{"id":"S_DNe1giogtk"},"source":["def num_grad_array(f, x, df, h=1e-5):\n","\n","    grad = np.zeros_like(x)\n","    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n","\n","    while not it.finished:\n","\n","        ix = it.multi_index\n","        oldval = x[ix]\n","        x[ix]  = oldval + h\n","        pos    = f(x).copy()\n","        x[ix]  = oldval - h\n","        neg    = f(x).copy()\n","        x[ix]  = oldval\n","\n","        grad[ix] = np.sum((pos - neg) * df) / (2 * h)\n","        it.iternext()\n","        \n","    return grad\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MCnbsppvwD-Q"},"source":["---\n","### d. Relative Error Function\n","\n","Function to calculate difference between your matrix and our expected results"]},{"cell_type":"code","metadata":{"id":"hBF5HAFBogtp"},"source":["def rel_error(x, y):\n","  \n","    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MYMv3bjxJJ3K"},"source":["---\n","### e. Download Image Funtion\n","\n","Read an image from a URL. Returns a numpy array with the pixel data."]},{"cell_type":"code","metadata":{"id":"FM1gc4QAoguI"},"source":["def image_from_url(url):\n","    try:\n","        f = urllib.request.urlopen(url)\n","        _, fname = tempfile.mkstemp()\n","        with open(fname, 'wb') as ff:\n","            ff.write(f.read())\n","\n","        img = imread(fname)\n","        # os.remove(fname)\n","        \n","        return img\n","\n","    except urllib.error.URLError as e:\n","        print('URL Error: ', e.reason, url)\n","        return Image.new('RGB', (64,64), color='LightGray')\n","        \n","    except urllib.error.HTTPError as e:\n","        print('HTTP Error: ', e.code, url) \n","        return Image.new('RGB', (64,64), color='LightGray')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"amwox6dGogtu"},"source":["---\n","## 2 - Install h5py\n","The COCO dataset we will be using is stored in HDF5 format. To load HDF5 files, we will need to install the `h5py` Python package. \n","\n","So install it if it's not already installed"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"NCzppM-Dogtv"},"source":["!pip install h5py\n","\n","import h5py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ze9A7cpBogtz"},"source":["---\n","---\n","# [Part 1] Microsoft COCO Dataset\n","Like the previous exercise, in this exercise we will also use the $2014$ release of the [Microsoft COCO dataset](http://mscoco.org/) which has become the standard testbed for image captioning.\n","\n","The dataset consists of $80,000$ training images and $40,000$ validation images, each annotated with $5$ captions written by workers on **Amazon Mechanical Turk**."]},{"cell_type":"markdown","metadata":{"id":"TF-OMq63ogt2"},"source":["---\n","## 1 - Download Preprocessed Data\n","\n","You already use this, so let's just skip the explanation and run the cell below to dwnload the Preprocessed Microsoft COCO Dataset."]},{"cell_type":"code","metadata":{"id":"y8jqWkbzwUUF"},"source":["!wget -O 'coco_downloader.py' 'https://github.com/adf-telkomuniv/CV2020_Exercises/raw/main/resources/coco_downloader.py' -q"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUG7aCqOwdLd"},"source":["from coco_downloader import *\n","\n","download_coco()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dpj5IlpwsVln"},"source":["!unzip -o coco_captioning.zip\n","\n","!rm coco_captioning.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lVcujoQHogt4"},"source":["---\n","## 2 - Text Processing\n"]},{"cell_type":"code","metadata":{"id":"sSRNI_Juogt6"},"source":["def decode_captions(captions, idx_to_word):\n","  \n","    singleton = False\n","    if captions.ndim == 1:\n","        singleton = True\n","        captions = captions[None]\n","\n","    decoded = []\n","    N, T = captions.shape\n","    for i in range(N):\n","        words = []\n","        for t in range(T):\n","            word = idx_to_word[captions[i, t]]\n","            if word != '<NULL>':\n","                words.append(word)\n","            if word == '<END>':\n","                break\n","        decoded.append(' '.join(words))\n","    if singleton:\n","        decoded = decoded[0]\n","\n","    return decoded"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3NbCgWUuogt9"},"source":["---\n","## 3 - Load Coco Dataset\n","\n"]},{"cell_type":"code","metadata":{"id":"Kh5q32zeogt_"},"source":["def load_coco_data(base_dir='coco_captioning', max_train=None, pca_features=True):\n","\n","    data = {}\n","    \n","    # read caption encoding\n","    caption_file = os.path.join(base_dir, 'coco2014_captions.h5')\n","    with h5py.File(caption_file, 'r') as f:\n","        for k, v in f.items():\n","            data[k] = np.asarray(v)\n","\n","    # use original training features or pca-reduced features\n","    if pca_features:\n","        train_feat_file = os.path.join(base_dir, 'train2014_vgg16_fc7_pca.h5')\n","    else:\n","        train_feat_file = os.path.join(base_dir, 'train2014_vgg16_fc7.h5')\n","    with h5py.File(train_feat_file, 'r') as f:\n","        data['train_features'] = np.asarray(f['features'])\n","\n","    # use original validation features or pca-reduced features\n","    if pca_features:\n","        val_feat_file = os.path.join(base_dir, 'val2014_vgg16_fc7_pca.h5')\n","    else:\n","        val_feat_file = os.path.join(base_dir, 'val2014_vgg16_fc7.h5')\n","    with h5py.File(val_feat_file, 'r') as f:\n","        data['val_features'] = np.asarray(f['features'])\n","\n","    # read vocabulary token\n","    dict_file = os.path.join(base_dir, 'coco2014_vocab.json')\n","    with open(dict_file, 'r') as f:\n","        dict_data = json.load(f)\n","        for k, v in dict_data.items():\n","            data[k] = v\n","\n","    # read training image urls\n","    train_url_file = os.path.join(base_dir, 'train2014_urls.txt')\n","    with open(train_url_file, 'r') as f:\n","        train_urls = np.asarray([line.strip() for line in f])\n","    data['train_urls'] = train_urls\n","\n","    # read validation image urls\n","    val_url_file = os.path.join(base_dir, 'val2014_urls.txt')\n","    with open(val_url_file, 'r') as f:\n","        val_urls = np.asarray([line.strip() for line in f])\n","    data['val_urls'] = val_urls\n","\n","    # Maybe subsample the training data\n","    if max_train is not None:\n","        num_train = data['train_captions'].shape[0]\n","        mask = np.random.randint(num_train, size=max_train)\n","\n","        data['train_captions']   = data['train_captions'][mask]\n","        data['train_image_idxs'] = data['train_image_idxs'][mask]\n","\n","    return data\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zLfrsgZQInai"},"source":["Load COCO data from disk"]},{"cell_type":"code","metadata":{"id":"v9wwijpKoguD"},"source":["data = load_coco_data(pca_features=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DD24CW8EI3qp"},"source":["Print out all the keys and values from the data dictionary\n"]},{"cell_type":"code","metadata":{"id":"zK-pu5CtI5F-"},"source":["p = ['  ', '', '    ','  ','  ','    ','     ','     ','      ','        ']\n","i=0\n","for k, v in data.items():\n","    if type(v) == np.ndarray:\n","        print(k+p[i], type(v), v.shape, '\\t', v.dtype)\n","    else:\n","        print(k+p[i], type(v), '\\t', len(v))\n","    i += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"galG568toguH"},"source":["---\n","## 4 - Look at the data\n"]},{"cell_type":"code","metadata":{"id":"-oNya34eoguL"},"source":["def sample_coco_minibatch(data, batch_size=100, split='train'):\n","    split_size = data['%s_captions' % split].shape[0]\n","    mask       = np.random.choice(split_size, batch_size)\n","\n","    captions       = data['%s_captions' % split][mask]\n","    image_idxs     = data['%s_image_idxs' % split][mask]\n","    image_features = data['%s_features' % split][image_idxs]\n","    \n","    urls = data['%s_urls' % split][image_idxs]\n","    \n","    return captions, image_features, urls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yt_v-pT4oguP"},"source":[" Sample a minibatch and show the images and captions"]},{"cell_type":"code","metadata":{"id":"_OUo-_8noguQ"},"source":["batch_size = 3\n","\n","captions, features, urls = sample_coco_minibatch(data, batch_size=batch_size)\n","for i, (caption, url) in enumerate(zip(captions, urls)):\n","    caption_str = decode_captions(caption, data['idx_to_word'])\n","\n","    fig = plt.figure(figsize=(8,6))\n","    fig.suptitle(caption_str, x=0, y=0.96, ha='left', size=15)\n","\n","    plt.imshow(image_from_url(url))\n","    plt.axis('off')\n","    plt.show()\n","    \n","    print('\\n-----------------------------------------------------\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XFT0HzEerE0o"},"source":["run the cell again to view another set of images\n","\n","You might also see that some of the images are already **removed** or **lost** from the Internet. \n","\n","But fear not since we have already retrieved all the feature for this training"]},{"cell_type":"markdown","metadata":{"id":"Utd1UgmzasOo"},"source":["---\n","# [Part 2] Long-Short Term Memory\n","\n","If you read recent papers, you'll see that many people use a variant on the vanilla RNN called **Long-Short Term Memory (LSTM) RNNs**. Vanilla RNNs can be tough to train on long sequences due to vanishing and exploding gradients caused by repeated matrix multiplication.\n","\n","LSTMs solve this problem by replacing the simple update rule of the vanilla RNN with a gating mechanism as follows.\n","\n","<center><img src='https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png' width=600></center>\n","\n","Long Short Term Memory networks – usually just called “**LSTM**s” – are a special kind of RNN, capable of learning long-term dependencies. They were introduced by Hochreiter & Schmidhuber (1997), and were refined and popularized by many people in following work.1 They work tremendously well on a large variety of problems, and are now widely used.\n","\n","LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!\n"," \n"]},{"cell_type":"markdown","metadata":{"id":"1rUYIDwYdZfd"},"source":["\n","---\n","## 1 - LSTM Detailed\n","\n","The LSTM does have the ability to remove or add information to the cell state, carefully regulated by structures called gates.\n","\n","Gates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.\n","\n","<center><img src='https://i.ibb.co/fXRRrf2/lstm.png'></center>\n","\n","Similar to the vanilla RNN, \n","* At each timestep we receive an **input** &nbsp; $\\color{firebrick} {x_t}\\in\\mathbb{R}^D$ and the **previous hidden state** &nbsp; $\\color{tomato}{h_{t-1}}\\in\\mathbb{R}^H$; \n","\n","* The LSTM also maintains an $\\color{tomato}H$-dimensional **cell state**, so we also receive the **previous cell state** $\\color{tomato}{c_{t-1}}\\in\\mathbb{R}^H$. \n","\n","* The learnable parameters of the LSTM are an **input-to-hidden** matrix $\\color{olive}{W_x}\\in\\mathbb{R}^{4H\\times D}$, \n","\n","* A **hidden-to-hidden** matrix $\\color{darkcyan}{W_h}\\in\\mathbb{R}^{4H\\times H}$ and a **bias vector**&nbsp; $b\\in\\mathbb{R}^{4H}$.\n","\n","<br>\n","\n","In the rest of the notebook we will implement the LSTM update rule and apply it to the image captioning task.\n"]},{"cell_type":"markdown","metadata":{"id":"v_doiba_oguW"},"source":["---\n","## 2 - Single Forward Step\n","\n","\n","First implement the `lstm_step_forward()` function which implements the forward pass for a **single timestep** of an LSTM.\n","\n","\n","At each timestep:\n","* We first compute an **Activation Vector**  from input, where $\\color{blue}A \\in \\mathbb{R}^{N\\times 4H}$ \n","\n","* In the code, we assume that data is stored in batches so that &nbsp;  $\\color{firebrick}{X_t}  \\in \\mathbb{R}^{N\\times D}$, &nbsp; and will work with *transposed* versions of the parameters: \n","\n","\n","\\begin{array}{ | c | c | }\n","\\hline\\rule{0pt}{4ex} \\rule[-1em]{0pt}{1em} \n","\\hspace{1pc} \\color{olive}{W_x} \\in \\mathbb{R}^{D \\times 4H} \\hspace{1pc} & \\hspace{1pc} \\color{darkcyan}{W_h} \\in \\mathbb{R}^{H\\times 4H} \\hspace{1pc}\\\\\n","\\hline\n","\\end{array}\n","\n","\n","* so that activations $A$ can be computed efficiently as \n","\n","$$\n","\\begin{array}{| c | }\n","\\hline \\rule{0pt}{4ex} \\rule[-1em]{0pt}{1em} \n","& \\color{blue}A\\ = \\ \\Big[\\ \\color{firebrick}{X_t} \\cdot \\color{olive}{W_x}\\ \\Big] \\ +\\ \\ \\Big[\\  \\color{tomato}{H_{prev}} \\cdot \\color{darkcyan}{W_h}\\ \\Big] \\ +\\ \\ b & \\\\\n","\\hline\n","\\end{array}\n","\\hspace{3pc}...(1)\n","$$\n","\n","<br>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"f5cKOdYiDKg_"},"source":["\n","* We then compute the gates:\n","\n","\\begin{array}{| c | c | c | c |}\n","\\hline\n","\\textbf{input}\\ gate &\n","\\textbf{forget}\\ gate &\n","\\textbf{output}\\ gate &\n","\\textbf{intermediate}\\ gate\\\\\n","\\hline\\rule{0pt}{2ex} \\rule[-0.5em]{0pt}{1em}\n","\\color{red}g & \\color{red}f & \\color{red}o & \\color{red}i\n","\\\\\n","\\hline\n","\\end{array}\n","\n","<br>\n","\n","* From activation vector $A$, we can easily calculate the output gates by dividing it into four vectors &nbsp; $a_i,a_f,a_o,a_g\\in\\mathbb{R}^H$,&nbsp; <br>and feed it to each activation function as follow\n","\n","\n","\n","$$\n","\\begin{array}{| c | c | c | c |}\n","\\hline\n","\\rule{0pt}{4ex} \\rule[-1em]{0pt}{1em} \\hspace{0.5pc} \n","\\color{darkgreen}{i_t} = \\sigma(a_i) \\hspace{0.5pc}&\\hspace{0.5pc}\n","\\color{darkred}{f_t} = \\sigma(a_f) \\hspace{0.5pc}&\\hspace{0.5pc}\n","\\color{darkblue}{o_t} = \\sigma(a_o) \\hspace{0.5pc}&\\hspace{0.5pc}\n","\\color{purple}{g_t} = \\tanh(a_g)  \\hspace{0.5pc}\\\\\n","\\hline\n","\\end{array}\n","\\hspace{3pc}...(2)\n","$$\n","\n","\n","* where $a_i$ consists of the first $H$ elements of $A$, $a_f$ is the next $H$ elements of $A$, and so on, like so:\n","\n","$$\n","\\begin{array}{| c c | c c |}\n","\\hline\n","\\rule{0pt}{4ex} \\rule[-1em]{0pt}{1em}\n","\\hspace{0.5pc}\\color{darkgreen}{a_i} & = A[\\ :\\ ,\\hspace{0.5pc}0:\\hspace{0.5pc}H]\\hspace{0.5pc}\n","&\\hspace{0.5pc} \\color{darkblue}{a_o} & = A[\\ :\\ ,\\ 2H:3H]\\hspace{0.5pc}\\\\\n","\\hline\n","\\rule{0pt}{4ex} \\rule[-1em]{0pt}{1em}\n","\\hspace{0.5pc}\\color{darkred}{a_f} & = A[\\ :\\ ,\\ H:2H]\\hspace{0.5pc}\n","&\\hspace{0.5pc} \\color{purple}{a_g} & = A[\\ :\\ ,\\ 3H:4H]\\hspace{0.5pc}\\\\\n","\\hline\n","\\end{array}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"nUzfnGLjDPFb"},"source":["\n","* Lastly, calculate the the next cell state $C_t$ and next hidden state $H_t$ as\n","\n","\n","$$\n","\\begin{array}{c c}\n","\\begin{array}{| c c | }\n","\\hline \\rule{0pt}{4ex} \\rule[-1em]{0pt}{1em} \n","\\hspace{1pc} C_{next} & = ( \\color{darkred}{f_t} \\odot  C_{prev} ) + ( \\color{darkgreen}{i_t} \\odot  \\color{purple}{g_t} )  \\hspace{1pc} \\\\\n","\\hline\n","\\end{array}\n","&\\hspace{3pc}...(3)\\\\\n","\\begin{array}{| c c | }\n","\\hline \\rule{0pt}{4ex} \\rule[-1em]{0pt}{1em} \n","\\hspace{2.5ex}H_{next} &= \\color{darkblue}{o_t} \\odot  \\tanh(C_{next})\\hspace{8.8ex}  \\\\\n","\\hline\n","\\end{array}\n","&\\hspace{3pc}...(4)\\\\\n","\\end{array}\n","$$\n","\n","\n","\n"," * where $\\odot $ is the element-wise product of vectors, and **NOT** the dot product\n","\n","<br>\n"]},{"cell_type":"markdown","metadata":{"id":"L1VCtTJjvaRd"},"source":["---\n","Check the illustration below to better understand the implementation\n","\n","<center>\n","<img src='https://i.ibb.co/1z6SKqk/lstm-dot.png' width=800>\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"xc2RyhhXUYMU"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n"," \n","    Forward pass for a single timestep of an LSTM.\n","    The input data has dimension D, the hidden state has dimension H, and we use a minibatch size of N.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ztbCL6QhXgEe"},"source":["\n","**Note:**    \n","<font color='red'>\n","* Use the `sigmoid()` function has already been provided for you in this file.\n","* Use `*` for element-wise multiplication ( $A\\odot B $ ) or ( $A*B $ )\n","* Use `.dot()` for dot product ( $A\\cdot B$ )\n","</font>"]},{"cell_type":"code","metadata":{"id":"G-JZqGhKasOr"},"source":["def lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b):\n","    \n","    N, H = prev_h.shape\n","\n","    # 1. calculate activation as\n","    #    A = x dot Wx + prev_h dot Wh + b\n","    A = ??\n","\n","    # 2. calculate each gate activation\n","    i = sigmoid( A[??] )\n","    f = ??\n","    o = ??\n","    g = np.tanh( ?? )\n","\n","    # 3. calculate next cell activation as shown in the formula\n","    #    use * for elementwise product\n","    next_c = ??\n","    \n","    # 4. calculate next hidden activation as shown in the formula\n","    #    use * for elementwise product\n","    next_h = ??\n","    \n","    # store all necessary intermediate values for backwrd pass\n","    cache = (x, prev_h, prev_c, Wx, Wh, A, i, f, o, g, next_c, next_h)\n","\n","    return next_h, next_c, cache"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FIW__2uvasOu"},"source":["\n","After doing so run the following to check your implementation. \n","You should see errors on the order of `e-8` or less."]},{"cell_type":"code","metadata":{"id":"Er_KyW-xasOv"},"source":["N, D, H = 3, 4, 5\n","\n","x      = np.linspace(-0.4, 1.2, num=N*D).reshape(N, D)\n","prev_h = np.linspace(-0.3, 0.7, num=N*H).reshape(N, H)\n","prev_c = np.linspace(-0.4, 0.9, num=N*H).reshape(N, H)\n","Wx     = np.linspace(-2.1, 1.3, num=4*D*H).reshape(D, 4 * H)\n","Wh     = np.linspace(-0.7, 2.2, num=4*H*H).reshape(H, 4 * H)\n","b      = np.linspace(0.3, 0.7, num=4*H)\n","\n","next_h, next_c, cache = lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q2iNDqpT3QKT"},"source":["expected_next_h = np.asarray([\n","    [ 0.24635157,  0.28610883,  0.32240467,  0.35525807,  0.38474904],\n","    [ 0.49223563,  0.55611431,  0.61507696,  0.66844003,  0.7159181 ],\n","    [ 0.56735664,  0.66310127,  0.74419266,  0.80889665,  0.858299  ]])\n","\n","expected_next_c = np.asarray([\n","    [ 0.32986176,  0.39145139,  0.451556,    0.51014116,  0.56717407],\n","    [ 0.66382255,  0.76674007,  0.87195994,  0.97902709,  1.08751345],\n","    [ 0.74192008,  0.90592151,  1.07717006,  1.25120233,  1.42395676]])\n","\n","print('next_h error: ', rel_error(expected_next_h, next_h))\n","print('next_c error: ', rel_error(expected_next_c, next_c))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0UchuTB6asOz"},"source":["**Expected Output**:\n","<pre>\n","next_h error:  5.7054131185818695e-09\n","next_c error:  5.8143123088804145e-09"]},{"cell_type":"markdown","metadata":{"id":"nYTrRB8GasOz"},"source":["---\n","## 3 - Single Backward Step\n","\n","Next, implement the backward pass for a single step of an LSTM in `lstm_step_backward()` function below.\n","\n","For sigmoid and tanh function, you can compute the local derivative in terms of the output value from `sigmoid` and `tanh`. \n","\n","\\begin{array}{ | c | c | }\n","\\hline\\rule{0pt}{4ex} \\rule[-1em]{0pt}{1em} \n","\\hspace{0.5pc} \\partial\\tanh(x) = 1-\\tanh^2(x) \\hspace{0.5pc} & \\hspace{0.5pc} \\partial \\sigma(x) = \\sigma(x)*(1-\\sigma(x)) \\hspace{0.5pc}\\\\\n","\\hline\n","\\end{array}\n","\n","<br>\n","\n","As for the complete derivative of backward LSTM, we need to detailed it further into 4 steps"]},{"cell_type":"markdown","metadata":{"id":"9m547LoVasO0"},"source":["---\n","### a. Backward from $H_{next}$ \n","\n","<br>\n","\n","The first is calculating gradient from next state.\n","\n","You should see that if we going backward from $H_{next}$ output, we get element-wise product form output gate $o_t$ and $\\tanh$ of cell state\n","\n","<center>\n","<img src=\"https://i.ibb.co/nm8CB0w/dhnext.png\"/>\n","</center>\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VazKYqStm6vl"},"source":["\n","* Thus, with &nbsp; \n","$$\n","\\begin{array}{| c | }\n","\\hline \\rule{0pt}{4ex} \\rule[-1em]{0pt}{1em} \n","& \\partial \\tanh(C) = 1-\\tanh(C_{next})^2 \\hspace{0.5pc}& \\\\\n","\\hline\n","\\end{array}\n","\\hspace{2.5pc}...(1)\n","$$\n","\n","* We can calculate the derivative as \n","\n","$$\n","\\begin{array}{c c}\n","\\hspace{5ex}\n","\\begin{array}{| c c | }\n","\\hline \\rule{0pt}{4ex} \\rule[-1em]{0pt}{1em} \n","\\hspace{5.5ex}\\partial o = \\partial H_{next} * \\tanh(C_{next})  \\hspace{4ex} \\\\\n","\\hline\n","\\end{array}\n","&\\hspace{1.5pc}...(2)\\\\\n","\\hspace{5ex}\n","\\begin{array}{| c c | }\n","\\hline \\rule{0pt}{4ex} \\rule[-1em]{0pt}{1em} \n","\\hspace{0.5pc}\\partial C_{temp}= \\partial H_{next}*o_t*\\partial \\tanh(C)\\hspace{0.5pc} \\\\\n","\\hline\n","\\end{array}\n","&\\hspace{1.5pc}...(3)\\\\\n","\\end{array}\n","$$\n","\n","* Note that we put the gradient of cell state $\\partial C_{next}$ into a temporary matrix $ \\partial C_{temp}$. \n","\n","* This was done since we need to accumulate it with the gradient from output cell state path. So now we need to do just that and add the gradients to \n","$\\partial C_{next}$\n","$$\n","\\begin{array}{| c | }\n","\\hline \\rule{0pt}{4ex} \\rule[-1em]{0pt}{1em} \n","\\hspace{1pc} \\partial C_{next} = \\partial C_{temp}+\\partial C_{next}  \\hspace{2pc} \\\\\n","\\hline\n","\\end{array}\n","\\hspace{2.5pc}...(4)\n","$$"]},{"cell_type":"markdown","metadata":{"id":"roLTrm2ESA-I"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n"," \n","    calculate backward step from H_next = o * tanh(C_next)\n"]},{"cell_type":"markdown","metadata":{"id":"Yy2b3aJRWZuY"},"source":["\n","**Note:**    \n","<font color='red'>\n","* Use the `sigmoid()` function has already been provided for you in this file.\n","* Use `*` for element-wise multiplication ( $A\\odot B $ ) or ( $A*B $ )\n","* Use `.dot()` for dot product ( $A\\cdot B$ )\n","</font>"]},{"cell_type":"code","metadata":{"id":"J9JrtL6PasO1"},"source":["def backward_step_a(dnext_h, dnext_c, next_c, o):\n","        \n","    # 1. calculate tanh local derivative\n","    dtanh_c = ??\n","    \n","    # 2. calculate o gate derivative as shown in the formula\n","    #    use * for elementwise product\n","    do = ??\n","    \n","    # 3. calculate C_temp derivative as shown in the formula\n","    #    use * for elementwise product\n","    dtemp_c = ??\n","    \n","    # 4. add dtemp_c to gradient highway dnext_c\n","    dnext_c =  ??\n","    \n","    return do, dnext_c"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GGIY0RPQasO5"},"source":["---\n","### b. Backward from $C_{next}$  \n","\n","<br>\n","\n","Next is calculating gradient from cell state.\n","\n","Now this seems scary since we met all other gates, but actually not at all. \n","\n","<center>\n","<img src=\"https://i.ibb.co/Xk9630C/dcnext.png\"/>\n","</center>\n","\n","Remember that add operation is just passing gradients to all input. And since the rest are actually element-wise product, the derivatives are also element-wise product with the inputs' pair.\n","\n","Thus we get each gates' gradients as:\n","\n","$$\n","\\begin{align*}\n","\\partial i &= \\partial C_{next} * g &\\hspace{1pc}...\\hspace{1pc}(1)\\\\\n","\\partial g &= \\partial C_{next} * i &\\hspace{1pc}...\\hspace{1pc}(2)\\\\\n","\\partial f&= \\partial C_{next} * C_{prev}&\\hspace{1pc}...\\hspace{1pc}(3)\\\\\n","\\partial C_{prev} &= \\partial C_{next} * f &\\hspace{1pc}...\\hspace{1pc}(4)\\\\\n","\\\\\n","\\end{align*}\n","$$\n"]},{"cell_type":"markdown","metadata":{"id":"bN03JJWXYQ3j"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n"," \n","    calculate backward step from C_next = (f * C_prev) + (i * g)\n"]},{"cell_type":"markdown","metadata":{"id":"_oILKuKjXlii"},"source":["\n","**Note:**    \n","<font color='red'>\n","* Use the `sigmoid()` function has already been provided for you in this file.\n","* Use `*` for element-wise multiplication ( $A\\odot B $ ) or ( $A*B $ )\n","</font>"]},{"cell_type":"code","metadata":{"id":"1jtKwU23asO5"},"source":["def backward_step_b(dnext_c, prev_c, i, f, g):\n","    \n","    # 1. calculate i gate derivative\n","    di = ??\n","    \n","    # 2. calculate g gate derivative\n","    dg = ??\n","    \n","    # 3. calculate f gate derivative\n","    df = ??\n","    \n","    # 4. calculate c_prev derivative\n","    dprev_c = ??\n","    \n","    return di, df, dg, dprev_c"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"novr15gdaCe0"},"source":["---\n","### c. Backward from Gates\n","\n","<br>\n","\n","Now calculate backward pass from all four gates to previous state $H_{prev}$ and input $X_t$\n","\n","<center>\n","<img src=\"https://i.ibb.co/QvdfxpF/lstm2.png\"/>\n","</center>\n","\n","Thus we get each gates' gradients as:\n","\n","$$\n","\\begin{align*}\n","\\\\\n","\\partial \\sigma(i_t) &=  i * (1-i_t) &\\hspace{0.5pc}...\\hspace{0.5pc}(1)&\\hspace{1pc}|\\hspace{1pc}\\partial a_i= \\partial i_t * \\partial \\sigma(i_t)&\\hspace{0.5pc}...\\hspace{0.5pc}(5)\\\\\\\\\n","\\partial \\sigma(f_t) &= f * (1-f_t)&\\hspace{0.5pc}...\\hspace{0.5pc}(2)&\\hspace{1pc}|\\hspace{1pc}\\partial a_f= \\partial f_t * \\partial \\sigma(f_t)&\\hspace{0.5pc}...\\hspace{0.5pc}(6)\\\\\\\\\n","\\partial \\sigma(o_t) &=  o * (1-o_t)&\\hspace{0.5pc}...\\hspace{0.5pc}(3)&\\hspace{1pc}|\\hspace{1pc}\\partial a_o= \\partial o_t * \\partial \\sigma(o_t)&\\hspace{0.5pc}...\\hspace{0.5pc}(7)\\\\\\\\\n","\\partial \\tanh(g_t) &=1 - g_t^ 2&\\hspace{0.5pc}...\\hspace{0.5pc}(4)&\\hspace{1pc}|\\hspace{1pc}\\partial a_g = \\partial g_t * \\partial \\tanh(g_t)&\\hspace{0.5pc}...\\hspace{0.5pc}(8)\\\\\\\\\n","\\end{align*}\n","$$\n","\n","\n","* where $\\partial a_i$ consists of the first $H$ elements of $\\partial A$; and $\\partial a_f$ is the next $H$ elements of $\\partial A$, and so on, like so:\n","\n","$$\n","\\begin{align*}\n","  \\partial a_i & = \\partial A[\\ :\\ ,\\hspace{0.5pc}0:\\hspace{0.5pc}H]\\hspace{2pc}\n","& \\partial a_o & = \\partial A[\\ :\\ ,\\ 2H:3H]\\\\\n","  \\partial a_f & = \\partial A[\\ :\\ ,\\ H:2H]\\hspace{2pc}\n","& \\partial a_g & = \\partial A[\\ :\\ ,\\ 3H:4H]\n","\\\\\\\\\n","\\end{align*}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"kHxY02_Cyiwh"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n"," \n","    calculate backward step from all four gates to A\n"]},{"cell_type":"markdown","metadata":{"id":"HYdoAD2aXowM"},"source":["\n","**Note:**    \n","<font color='red'>\n","* Use the `sigmoid()` function has already been provided for you in this file.\n","* Use `*` for element-wise multiplication ( $A\\odot B $ ) or ( $A*B $ )\n","</font>"]},{"cell_type":"code","metadata":{"id":"z8302ttwasO-"},"source":["def backward_step_c(di, df, do, dg, A, i, f, o, g):\n","  \n","    N, H = dg.shape    \n","    \n","    # create matrix zeros with size (N, 4*H)\n","    dA = ??\n","    \n","    # 1. calculate sigmoid local derivative from gate i\n","    dsigm_i = ??\n","    \n","    # 2. calculate sigmoid local derivative from gate f\n","    dsigm_f = ??\n","\n","    # 3. calculate sigmoid local derivative from gate o\n","    dsigm_o = ??\n","\n","    # 4. calculate tanh local derivative from gate g\n","    dtanh_g = ??\n","\n","\n","    # 5. calculate derivative from gate i\n","    dA[:, :H] = ??\n","    \n","    # 6. calculate derivative from gate f\n","    dA[:, H:2*H] = ??\n","\n","    # 7. calculate derivative from gate o\n","    dA[:, 2*H:3*H] = ??\n","\n","    # 8. calculate derivative from gate g\n","    dA[:, 3*H:] = ??\n","\n","\n","    return dA\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SJnkLZESqgTt"},"source":["---\n","### d. Backward from $A$\n","\n","<br>\n","\n","Lastly, we calculate the weights $W_x$ and $W_h$ gradients\n","\n","<center>\n","<img src=\"https://i.ibb.co/QvdfxpF/lstm2.png\" width=400/>\n","\n","<br>\n","</center>\n","\n","From forward pass \n","<font color='blue'>$A$ </font>$ = $ <font color='firebrick'>$X_t$</font>$\\cdot$ <font color='olive'> $W_x$ </font> $ + $<font color='tomato'>$H_{prev}$</font> $\\cdot$<font color='darkcyan'> $W_h$</font>$ + b$ \n","\n","We got the derivatives as\n","\n","\n","$$\n","\\begin{align*}\n","\\\\\n","\\partial X_t&= \\partial A \\cdot (W_x)^T \n","  & \\hspace{0.5pc} ... \\hspace{0.5pc}(1) \n","  & \\hspace{1pc}|\\hspace{1pc}\n","  \\partial H_{prev}=\\partial A \\cdot (W_h)^T\n","  & \\hspace{0.5pc}...\\hspace{0.5pc}(3)\\\\\n","\\\\\n","\\partial W_x&=(X_t)^T \\cdot \\partial A\n","  & \\hspace{1pc}...\\hspace{0.5pc}(2)\n","  & \\hspace{1pc}|\\hspace{1pc}\n","  \\partial W_h=(H_{prev})^T\\cdot\\partial A\n","  & \\hspace{0.5pc}...\\hspace{0.5pc}(4)\n","\\end{align*}\n","$$\n","\n","$$\n","\\begin{align*}\n","\\\\\n","\\partial b&=\\sum(\\partial A)& \\hspace{1pc}...\\hspace{0.5pc}(5)\\\\\n","\\end{align*}\n","$$\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"kknTfjqcw-kf"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n"," \n","    calculate backward step from A to weights\n"]},{"cell_type":"markdown","metadata":{"id":"3mIzsdenXzxW"},"source":["\n","**Note:**    \n","<font color='red'>\n","* Use the `sigmoid()` function has already been provided for you in this file.\n","* Use `.dot()` for dot product ( $A\\cdot B$ )\n","</font>"]},{"cell_type":"code","metadata":{"id":"tEoowWRkasPD"},"source":["def backward_step_d(dA, Wx, Wh, x, prev_h):\n","\n","    # calculate backward step from a = xWx + prev_hWh + b\n","    \n","    # 1. calculate x derivative\n","    dx = ??\n","    \n","    # 2. calculate Wx derivative\n","    dWx = ??\n","    \n","    # 3. calculate prev_h derivative\n","    dprev_h = ??\n","    \n","    # 4. calculate Wh derivative\n","    dWh = ??\n","    \n","    # 5. calculate bias derivative, use np.sum with axis=0\n","    db = ??\n","    \n","    return dx, dWx, dprev_h, dWh, db"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"srqWVFN3asPE"},"source":["---\n","### e. Complete Backward Step\n","\n","Combine all steps into one LSTM backward step below"]},{"cell_type":"markdown","metadata":{"id":"XzIaaDL-xTm2"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n"," \n","    implement backward step LSTM\n"]},{"cell_type":"code","metadata":{"id":"-0-jpqEKasPF"},"source":["def lstm_step_backward(dnext_h, dnext_c, cache):\n","    \n","    x, prev_h, prev_c, Wx, Wh, A, i, f, o, g, next_c, next_h = cache\n","\n","    # get N and H\n","    N, H = dnext_h.shape\n","\n","    \n","    # Backward step A\n","    # call backward_step_a() function with input dnext_h, dnext_c, next_c, and o\n","    do, dnext_c = ??\n","    \n","    \n","    # Backward step B\n","    # call backward_step_b() function with input dnext_c, prev_c, i, f, and g\n","    di, df, dg, dprev_c = ??\n","    \n","    \n","    # Backward step C\n","    # call backward_step_c() function with input di, df, do, dg, a, i, f, o, and g\n","    dA = ??\n","\n","    # Backward step D    \n","    # call backward_step_d() function with input dA, Wx, Wh, x, and prev_h\n","    dx, dWx, dprev_h, dWh, db = ??\n","\n","\n","    return dx, dprev_h, dprev_c, dWx, dWh, db\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GVULElDaasPH"},"source":["After doing so run the following to numerically gradient check your implementation. You should see errors on the order of `e-8` or less."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"QcmLUFXvasPI"},"source":["np.random.seed(231)\n","N, D, H = 4, 5, 6\n","\n","x      = np.random.randn(N, D)\n","prev_h = np.random.randn(N, H)\n","prev_c = np.random.randn(N, H)\n","Wx     = np.random.randn(D, 4 * H)\n","Wh     = np.random.randn(H, 4 * H)\n","b      = np.random.randn(4 * H)\n","\n","next_h, next_c, cache = lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HR__zmcl1ecO"},"source":["np.random.seed(231)\n","\n","dnext_h = np.random.randn(*next_h.shape)\n","dnext_c = np.random.randn(*next_c.shape)\n","\n","fx_h  = lambda x:  lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n","fh_h  = lambda h:  lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n","fc_h  = lambda c:  lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n","fWx_h = lambda Wx: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n","fWh_h = lambda Wh: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n","fb_h  = lambda b:  lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[0]\n","\n","fx_c  = lambda x:  lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n","fh_c  = lambda h:  lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n","fc_c  = lambda c:  lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n","fWx_c = lambda Wx: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n","fWh_c = lambda Wh: lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n","fb_c  = lambda b:  lstm_step_forward(x, prev_h, prev_c, Wx, Wh, b)[1]\n","\n","dx_num  = num_grad_array(fx_h,   x, dnext_h) + num_grad_array(fx_c, x, dnext_c)\n","dh_num  = num_grad_array(fh_h, prev_h, dnext_h) + num_grad_array(fh_c, prev_h, dnext_c)\n","dc_num  = num_grad_array(fc_h, prev_c, dnext_h) + num_grad_array(fc_c, prev_c, dnext_c)\n","dWx_num = num_grad_array(fWx_h, Wx, dnext_h) + num_grad_array(fWx_c, Wx, dnext_c)\n","dWh_num = num_grad_array(fWh_h, Wh, dnext_h) + num_grad_array(fWh_c, Wh, dnext_c)\n","db_num  = num_grad_array(fb_h,   b, dnext_h) + num_grad_array(fb_c, b, dnext_c)\n","\n","dx, dh, dc, dWx, dWh, db = lstm_step_backward(dnext_h, dnext_c, cache)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3tWxewQM2YqF"},"source":["print('dx error  : ', rel_error(dx_num, dx))\n","print('dh error  : ', rel_error(dh_num, dh))\n","print('dc error  : ', rel_error(dc_num, dc))\n","print('dWx error : ', rel_error(dWx_num, dWx))\n","print('dWh error : ', rel_error(dWh_num, dWh))\n","print('db error  : ', rel_error(db_num, db))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_DW2rfh0asPM"},"source":["**Expected Output**:\n","<pre>\n","dx error  :  1.2120559407420112e-09\n","dh error  :  2.423350410468521e-10\n","dc error  :  1.1811747138523406e-08\n","dWx error :  1.6842746743670454e-09\n","dWh error :  5.570851510737813e-09\n","db error  :  3.643760111307456e-10"]},{"cell_type":"markdown","metadata":{"id":"ACFPGOgFasPN"},"source":["---\n","## 4 - Forward Pass\n","Now that you have implemented the forward and backward passes for a single timestep of an LSTM, you will combine these pieces to implement an LSTM that processes an entire sequence of data.\n","\n","Implement Forward pass for an LSTM over an entire sequence of data. We assume an input   sequence composed of $T$ vectors, each of dimension $D$. \n","\n","The LSTM uses a hidden    size of $H$, and we work over a minibatch containing $N$ sequences. \n","\n","After running    the LSTM forward, we return the hidden states for all timesteps.\n","\n","Note that the initial cell state is passed as input, but the initial cell    state is set to zero. Also note that the cell state is not returned; it is    an internal variable to the LSTM and is not accessed from outside."]},{"cell_type":"markdown","metadata":{"id":"Uq4UjLXB-Azw"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","Implement forward pass for an LSTM running on a sequence of input data.\n"]},{"cell_type":"code","metadata":{"id":"G3mbmxqtasPO"},"source":["def lstm_forward(x, h0, Wx, Wh, b):\n","\n","    # get the size of N, T, H, and D\n","    N, T, D = x.shape\n","    N, H    = h0.shape  \n","    \n","    # create matrix zeros with size (N, T, H)\n","    h = ??\n","    \n","    # set h0 as previous hidden activation \n","    prev_h =  h0\n","\n","    # Initial cell state\n","    # create matrix zeros with size (N, H)\n","    next_c = ??\n","\n","    #initialize cache dictionary\n","    cache = {}    \n","        \n","    \n","    # start LSTM forward \n","    # loop over the timestep\n","    for i in range(T):\n","\n","        # select x at timestep i \n","        xt = x[:, i, :]  \n","        \n","        # call lstm_step_forward function with input xt, prev_h, next_c, and its weights\n","        current_h, next_c, cache_i = ??\n","        \n","        # store the current hidden activation current_h to the i-th timestep in matrix h\n","        h[:, i, :] = current_h      \n","        \n","        # store the cache_i result to dictionary\n","        cache[i] = cache_i \n","        \n","        # for the next iteration, \n","        # set current hidden activation current_h as previous activation\n","        prev_h = current_h \n","        \n","        \n","    return h, cache"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rfnom2cvasPR"},"source":["\n","After doing so run the following to check your implementation. \n","You should see errors on the order of `e-7` or less."]},{"cell_type":"code","metadata":{"id":"u9gn5YYvasPS"},"source":["N, D, H, T = 2, 5, 4, 3\n","\n","x  = np.linspace(-0.4, 0.6, num=N*T*D).reshape(N, T, D)\n","h0 = np.linspace(-0.4, 0.8, num=N*H).reshape(N, H)\n","Wx = np.linspace(-0.2, 0.9, num=4*D*H).reshape(D, 4 * H)\n","Wh = np.linspace(-0.3, 0.6, num=4*H*H).reshape(H, 4 * H)\n","b  = np.linspace( 0.2, 0.7, num=4*H)\n","\n","h, cache = lstm_forward(x, h0, Wx, Wh, b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjfNdFuq83Nh"},"source":["expected_h = np.asarray([\n"," [[ 0.01764008,  0.01823233,  0.01882671,  0.0194232 ],\n","  [ 0.11287491,  0.12146228,  0.13018446,  0.13902939],\n","  [ 0.31358768,  0.33338627,  0.35304453,  0.37250975]],\n"," [[ 0.45767879,  0.4761092,   0.4936887,   0.51041945],\n","  [ 0.6704845,   0.69350089,  0.71486014,  0.7346449 ],\n","  [ 0.81733511,  0.83677871,  0.85403753,  0.86935314]]])\n","\n","print('h error: ', rel_error(expected_h, h))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NcijaAwdasPU"},"source":["**Expected Output**:\n","<pre>\n","h error:  8.610537452106624e-08\n"]},{"cell_type":"markdown","metadata":{"id":"oXwBiQ-oasPV"},"source":["---\n","## 5 - Backward Pass\n","\n","Implement the backward pass for an LSTM running an entire sequence of data in the function `lstm_backward()`. \n","\n","This should run back-propagation over the entire sequence, making calls to the `lstm_step_backward` function that you defined earlier. \n","\n","**NOTE**:<br>`dh` contains the upstream gradients produced by the individual loss functions at each timestep,\n","and ***NOT*** the gradients being passed between timesteps <br>(which you'll have to compute yourself by calling `lstm_step_backward` in a loop).\n"]},{"cell_type":"markdown","metadata":{"id":"M3jrrqjG9CCK"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","Implement forward pass for an LSTM running on a sequence of input data.\n"]},{"cell_type":"code","metadata":{"id":"nCp6wo1basPV"},"source":["def lstm_backward(dh, cache):\n","\n","    # get the x data and D dimension\n","    x = cache[0][0]\n","    D = x.shape[1]\n","    \n","    # get the size of N, T, and H\n","    N, T, H = dh.shape\n","    \n","    # initialize zeros matrix with the appropriate size\n","    # Note that dWx, dWh, and bias width is 4H\n","    dx  = ?? # zeros shape (N, T, D)\n","    dh0 = ?? # zeros shape (N, H)\n","    dWx = ?? # zeros shape (D, 4H)\n","    dWh = ?? # zeros shape (H, 4H)\n","    db  = ?? # zeros shape (4H)\n","\n","\n","\n","    # initialzie zeros matrix for the current gradient h and cell c for the loop\n","    # all is sized (N, H) \n","    dprev_c = ??\n","    dprev_h = ??\n","\n","     \n","    # backward loop over timestep\n","    for i in reversed(range(T)):\n","        \n","        # select dh at timestep i        \n","        dht = dh[:, i, :]\n","        \n","        # gradient of next_h is the total of dht and dprev_h\n","        dnext_h = ??\n","        \n","        # set dprev_c as the next gradient\n","        dnext_c = dprev_c\n","        \n","        # get i-th cache from cache dictionary\n","        cache_i = cache[i]\n","\n","        # call lstm_step_backward() with input dnext_h, dnext_c, and cache_i\n","        dx[:, i, :], dprev_h, dprev_c, dWx_t, dWh_t, db_t = ??\n","\n","        # accumulate weight gradient over loop dWx_t into dWx\n","        dWx = dWx + dWx_t\n","        \n","        # accumulate weight gradient over loop dWh_t into dWh\n","        dWx = ??\n","        \n","        # accumulate bias gradient over loop db_t into db\n","        db  = ??\n","\n","    # store the last gradient of hidden state as dh0\n","    dh0 = dprev_h\n","\n","    return dx, dh0, dWx, dWh, db\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9S9oNi4zasPY"},"source":["Test your implementation. You should see errors on the order of `e-8` or less.\n","For dWh, it's fine if your error is on the order of e-6 or less"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"DtTTGq7vasPY"},"source":["np.random.seed(231)\n","\n","N, D, T, H = 2, 3, 10, 6\n","\n","x  = np.random.randn(N, T, D)\n","h0 = np.random.randn(N, H)\n","Wx = np.random.randn(D, 4 * H)\n","Wh = np.random.randn(H, 4 * H)\n","b  = np.random.randn(4 * H)\n","\n","out, cache = lstm_forward(x, h0, Wx, Wh, b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FrElY56s-f0b"},"source":["np.random.seed(231)\n","dout = np.random.randn(*out.shape)\n","\n","dx, dh0, dWx, dWh, db = lstm_backward(dout, cache)\n","\n","fx  = lambda x:  lstm_forward(x, h0, Wx, Wh, b)[0]\n","fh0 = lambda h0: lstm_forward(x, h0, Wx, Wh, b)[0]\n","fWx = lambda Wx: lstm_forward(x, h0, Wx, Wh, b)[0]\n","fWh = lambda Wh: lstm_forward(x, h0, Wx, Wh, b)[0]\n","fb  = lambda b:  lstm_forward(x, h0, Wx, Wh, b)[0]\n","\n","dx_num  = num_grad_array(fx,   x, dout)\n","dh0_num = num_grad_array(fh0, h0, dout)\n","dWx_num = num_grad_array(fWx, Wx, dout)\n","dWh_num = num_grad_array(fWh, Wh, dout)\n","db_num  = num_grad_array(fb,   b, dout)\n","\n","print('dx error  : ', rel_error(dx_num, dx))\n","print('dh0 error : ', rel_error(dh0_num, dh0))\n","print('dWx error : ', rel_error(dWx_num, dWx))\n","print('dWh error : ', rel_error(dWh_num, dWh))\n","print('db error  : ', rel_error(db_num, db))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TWCMAtPwasPa"},"source":["**Expected Output**:\n","<pre>\n","dx error  :  6.56688634275682e-10\n","dh0 error :  6.8284665719089884e-09\n","dWx error :  2.0705351060661793e-09\n","dWh error :  3.452581713210269e-07\n","db error  :  1.6341597938420703e-09\n"]},{"cell_type":"markdown","metadata":{"id":"oc3yEiaiogvN"},"source":["---\n","---\n","# [Part 3] Temporal Affine Layer\n","At every timestep we use an affine function to transform the RNN hidden vector at that timestep into scores for each word in the vocabulary. \n","\n","This is very similar to the affine layer that you implemented in previous assignments, so complete the `temporal_affine_forward` and `temporal_affine_backward` functions below. "]},{"cell_type":"markdown","metadata":{"id":"WK3ZWE_8KkwT"},"source":["---\n","## 1 - Forward Pass\n","Forward pass for a temporal affine layer. \n","\n","The input is a set of $D$-dimensional     vectors arranged into a minibatch of $N$ timeseries, each of length $T$. \n","\n","We use     an affine function to transform each of those vectors into a new vector of     dimension $M$."]},{"cell_type":"markdown","metadata":{"id":"3mzeLqnvFJXP"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","implement the function as described above"]},{"cell_type":"code","metadata":{"id":"lWiUZY4rogvP"},"source":["def temporal_affine_forward(x, w, b):\n","\n","    # get the size of N, T, and D\n","    N, T, D = x.shape\n","\n","    # get the size of M\n","    M = b.shape[0]\n","\n","    # reshape x into shape (N*T, D)\n","    x_reshape = ??\n","\n","    # output = dot product x_reshape with w\n","    out = ??\n","    \n","    # reshape output into shape (N, T, M)\n","    out = ??\n","    \n","    # add output with bias b\n","    out = ??\n","\n","    # store cache for backward pass\n","    cache = x, w, b, out\n","\n","    return out, cache"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mDCyXfrrLo3Z"},"source":["---\n","## 2 - Backward Pass Pass\n","\n","Backward pass for a temporal affine layer. \n","\n","Again, it's very much alike normal affine layer, but with temporal input shape\n","\n","Thus you need to reshape the matrix to the appropriate shape before calculating dot product\n"]},{"cell_type":"markdown","metadata":{"id":"AODPadlxrimo"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","implement the function as described above"]},{"cell_type":"code","metadata":{"id":"uaxrzpTsogvQ"},"source":["def temporal_affine_backward(dout, cache):\n","  \n","    # extract cache\n","    x, w, b, out = cache\n","\n","    # get the size of N, T, and D\n","    N, T, D = x.shape\n","\n","    # get the size of M\n","    M = b.shape[0]\n","\n","    # reshape dout into shape (N*T, M)\n","    dout_reshape = ??\n","\n","    # reshape x into shape (N*T, D)\n","    x_reshape = ??\n","\n","    # dx = dot product dout_reshape with w.transpose\n","    dx = ??\n","    \n","    # reshape dx back into shape (N, T, D)\n","    dx = ??\n","    \n","    # dw = dot product dout_reshape.transpose with x_reshape\n","    dw = ??\n","\n","    # transpose back dw\n","    dw = dw.T\n","\n","    # sum dout over axis=(0,1)\n","    db = dout.sum(axis=(0, 1))\n","\n","    return dx, dw, db"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dS4RiHoPogvd"},"source":["---\n","## 3 - Temporal Softmax loss\n","In an RNN language model, at every timestep we produce a score for each word in the vocabulary. We know the ground-truth word at each timestep, so we use a softmax loss function to compute loss and gradient at each timestep. We sum the losses over time and average them over the minibatch.\n","\n","However there is one wrinkle: since we operate over minibatches and different captions may have different lengths, we append `<NULL>` tokens to the end of each caption so they all have the same length. We don't want these `<NULL>` tokens to count toward the loss or gradient, so in addition to scores and ground-truth labels our loss function also accepts a `mask` array that tells it which elements of the scores count towards the loss.\n","\n","Since this is very similar to the softmax loss function you implemented in previous assignment, we have implemented this loss function for you; look at the `temporal_softmax_loss` function below."]},{"cell_type":"markdown","metadata":{"id":"rPh2-38nNtih"},"source":["We assume that we are     making predictions over a vocabulary of size $V$ for each timestep of a    timeseries of length $T$, over a minibatch of size $N$. \n","\n","The input $x$ gives scores    for all vocabulary elements at all timesteps, and $y$ gives the indices of the    ground-truth element at each timestep. \n","\n","We use a cross-entropy loss at each    timestep, summing the loss over all timesteps and averaging across the    minibatch.\n","\n","As an additional complication, we may want to ignore the model output at some\n","timesteps, since sequences of different length may have been combined into a\n","minibatch and padded with NULL tokens. The optional mask argument tells us\n","which elements should contribute to the loss.\n"]},{"cell_type":"code","metadata":{"id":"maChXoh1ogve"},"source":["def temporal_softmax_loss(x, y, mask, verbose=False):\n","\n","    N, T, V = x.shape\n","\n","    x_flat = x.reshape(N * T, V)\n","    y_flat = y.reshape(N * T)\n","    \n","    mask_flat = mask.reshape(N * T)\n","\n","    probs  = np.exp(x_flat - np.max(x_flat, axis=1, keepdims=True))\n","    probs /= np.sum(probs, axis=1, keepdims=True)\n","    loss   = -np.sum(mask_flat * np.log(probs[np.arange(N * T), y_flat])) / N\n","\n","    dx_flat = probs.copy()\n","    dx_flat[np.arange(N * T), y_flat] -= 1\n","    dx_flat /= N\n","    dx_flat *= mask_flat[:, None]\n","\n","    if verbose: print('dx_flat: ', dx_flat.shape)\n","\n","    dx = dx_flat.reshape(N, T, V)\n","\n","    return loss, dx"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-HRsmhbdOoSZ"},"source":["---\n","---\n","# [Part 4] Helper Functions\n","\n","To further implement the image captioning process, we need several other funtions, such as Affine Layer functions and Optimizer functions. Which you have already made before.\n","\n","Thus for the rest of the function, we've provided you with the implementation\n","\n","But let's walk through each of them"]},{"cell_type":"markdown","metadata":{"id":"-uvZH8hcogu8"},"source":["---\n","## 1 - Word Embedding\n","In deep learning systems, we commonly represent words using vectors. \n","\n","Each word of the vocabulary will be associated with a vector, and these vectors will be learned jointly with the rest of the system.\n","\n","Below we've provided you with the simple implementation of Forward and Backward pass of Word Embedding"]},{"cell_type":"markdown","metadata":{"id":"5svJQT60ogu9"},"source":["---\n","### a. Forward Pass\n","\n","Function `word_embedding_forward` below is the implementation of the forward pass for word embeddings. \n","\n","The function will convert words (represented by integers) into vectors. \n","\n","* operate on minibatches of size $N$ where    each sequence has length $T$.\n","\n","* assume a vocabulary of $V$ words, assigning each    word to a vector of dimension $D$.\n"]},{"cell_type":"code","metadata":{"id":"1-nBgQBjogu-"},"source":["def word_embedding_forward(x, W):\n","    \n","    out   = W[x, :]\n","    cache = x, W\n","\n","    return out, cache"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4AJEZ06IogvH"},"source":["---\n","### b. Backward Pass\n","Function `word_embedding_backward` below is the implementation of the backward pass for the word embedding.\n","\n","We cannot back-propagate into the words     since they are integers, so we only return gradient for the word embedding     matrix."]},{"cell_type":"code","metadata":{"id":"qRn7q9RbogvI"},"source":["def word_embedding_backward(dout, cache):\n","\n","    x, W = cache\n","    dW   = np.zeros_like(W)\n","    \n","    np.add.at(dW, x, dout)\n","\n","    return dW"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wE7GDDaEogvo"},"source":["---\n","## 2 - Affine Functions\n","\n","Affine implementation as you have implemented in previous assignments"]},{"cell_type":"markdown","metadata":{"id":"ymDAvPRoPqTm"},"source":["---\n","### a. Forward Pass\n","\n","Computes the forward pass for an affine (fully-connected) layer.\n","\n","The input $x$ has shape $(N, d_1, ..., d_k)$ where $x[i]$ is the $i^{th}$ input.\n","\n","We multiply this against a weight matrix of shape $(D, M)$ "]},{"cell_type":"code","metadata":{"id":"d1aW5oMTogvp"},"source":["def affine_forward(x, w, b):\n","  \n","    out   = x.reshape(x.shape[0], -1).dot(w) + b\n","    cache = (x, w, b)\n","\n","    return out, cache"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QwCGxm1QQM0b"},"source":["---\n","### b. Backward Pass\n","\n","Computes the backward pass for an affine layer."]},{"cell_type":"code","metadata":{"id":"GqwAalTFogvr"},"source":["def affine_backward(dout, cache):\n","\n","    x, w, b = cache\n","\n","    dx = dout.dot(w.T).reshape(x.shape)\n","    dw = x.reshape(x.shape[0], -1).T.dot(dout)\n","    db = np.sum(dout, axis=0)\n","    \n","    return dx, dw, db"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"__qeInmcogvt"},"source":["---\n","## 3 - Optimizer Functions\n","\n","Here we also provide you with `SGD` and `Adam` optimization function"]},{"cell_type":"markdown","metadata":{"id":"tx2xQ7xoQawH"},"source":["---\n","### a. SGD Optimizer\n"," Performs vanilla stochastic gradient descent.\n"]},{"cell_type":"code","metadata":{"id":"l3CFV_WAogvv"},"source":["def sgd(w, dw, config=None):\n","\n","    if config is None: config = {}\n","    config.setdefault('learning_rate', 1e-2)\n","\n","    w -= config['learning_rate'] * dw\n","\n","    return w, config"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6UOYmOgAQhhj"},"source":["---\n","### b. Adam Optimizer\n","Uses the Adam update rule, which incorporates moving averages of both the     gradient and its square and a bias correction term.\n"]},{"cell_type":"code","metadata":{"id":"m-i8sXXyogvy"},"source":["def adam(x, dx, config=None):\n","\n","    if config is None: config = {}\n","    config.setdefault('learning_rate', 1e-3)\n","    config.setdefault('beta1', 0.9)\n","    config.setdefault('beta2', 0.999)\n","    config.setdefault('epsilon', 1e-8)\n","    config.setdefault('m', np.zeros_like(x))\n","    config.setdefault('v', np.zeros_like(x))\n","    config.setdefault('t', 0)\n","\n","    next_x = None\n","    beta1, beta2, eps = config['beta1'], config['beta2'], config['epsilon']\n","    t, m, v = config['t'], config['m'], config['v']\n","\n","    m = beta1 * m + (1 - beta1) * dx\n","    v = beta2 * v + (1 - beta2) * (dx * dx)\n","    t += 1\n","\n","    alpha = config['learning_rate'] * np.sqrt(1 - beta2 ** t) / (1 - beta1 ** t)\n","\n","    x -= alpha * (m / (np.sqrt(v) + eps))\n","\n","    config['t'] = t\n","    config['m'] = m\n","    config['v'] = v\n","\n","    next_x = x\n","\n","    return next_x, config"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nLxjhm6yasQN"},"source":["---\n","---\n","# [Part 5] LSTM for image captioning\n","Now that you have implemented the necessary layers, you can combine them to build an image captioning model. \n","\n","\n","Implement the forward and backward pass of the model in the `loss` function. \n","\n","After doing so, run the following to check your forward pass using a small test case; you should see error on the order of `e-10` or less."]},{"cell_type":"markdown","metadata":{"id":"GtdJ9Y-hasQN"},"source":["---\n","## 1 - Weights Initialization Function\n","\n","below is the cuntion to initialize weights of the LSTM"]},{"cell_type":"code","metadata":{"id":"qNp-oyqLasQN"},"source":["def init_weights(word_to_idx, input_dim=512, wordvec_dim=128, hidden_dim=128, dtype=np.float32):\n","    \n","    vocab_size = len(word_to_idx)\n","    idx_to_word = {i: w for w, i in word_to_idx.items()}\n","    weights = {}\n","\n","    # Initialize word vectors\n","    # Word embedding matrix\n","    weights['W_embed'] = np.random.randn(vocab_size, wordvec_dim)\n","    weights['W_embed'] /= 100\n","\n","    # Initialize CNN -> hidden state projection parameters    \n","    # Weight and bias for the affine transform from image features to initial\n","    # hidden state\n","    weights['W_proj'] = np.random.randn(input_dim, hidden_dim)\n","    weights['W_proj'] /= np.sqrt(input_dim)\n","    weights['b_proj'] = np.zeros(hidden_dim)\n","\n","    # Initialize parameters for the LSTM\n","    # Input-to-hidden, hidden-to-hidden, and biases for the LSTM\n","    # dim_mul = {'lstm': 4, 'rnn': 1}\n","    dim_mul = 4\n","    weights['Wx'] = np.random.randn(wordvec_dim, dim_mul * hidden_dim)\n","    weights['Wx'] /= np.sqrt(wordvec_dim)\n","    weights['Wh'] = np.random.randn(hidden_dim, dim_mul * hidden_dim)\n","    weights['Wh'] /= np.sqrt(hidden_dim)\n","    weights['b'] = np.zeros(dim_mul * hidden_dim)\n","\n","    # Initialize output to vocab weights\n","    # Weight and bias for the hidden-to-vocab transformation.\n","    weights['W_vocab'] = np.random.randn(hidden_dim, vocab_size)\n","    weights['W_vocab'] /= np.sqrt(hidden_dim)\n","    weights['b_vocab'] = np.zeros(vocab_size)\n","\n","    # Cast parameters to correct dtype\n","    for k, v in weights.items():\n","        weights[k] = v.astype(dtype)\n","\n","    return weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RQlG7w8j3S9-"},"source":["---\n","## 2 - Captioning Step\n","\n","\n","Implement the forward and backward passes for the RNN Model.\n","\n","In the forward pass you will need to do the following:                   \n","* Use an affine transformation to compute the initial hidden state from the image features. <br>This should produce an array of shape `(N, H)`\n","\n","* Use a word embedding layer to transform the words in captions_in from indices to vectors, <br>giving an array of shape `(N, T, W)`.         \n","* Use a LSTM to process the sequence of input word vectors and produce hidden state vectors for all timesteps, <br>producing an array of shape `(N, T, H)`.\n","* Use a (temporal) affine transformation to compute scores over the vocabulary at every timestep using the hidden states, giving an array of shape `(N, T, V)`.                                            \n","* Use (temporal) softmax to compute loss using captions_out, <br>ignoring the points where the output word is `<NULL>` using the mask defined.     \n","                                                                         \n","In the backward pass you will need to compute the gradient of the loss with respect to all model parameters.\n","* `grads[k]` should give the gradients for `weights[k]`."]},{"cell_type":"markdown","metadata":{"id":"iMJ5qtRYgHVa"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","implement the function as described above"]},{"cell_type":"code","metadata":{"id":"LpxxSfHHasQR"},"source":["def lstm_step(weights, features, captions, word_to_idx):\n","  \n","    # create special token\n","    token_null  = word_to_idx['<NULL>']\n","    token_start = word_to_idx.get('<START>', None)\n","    token_end   = word_to_idx.get('<END>', None)\n","\n","\n","    # Cut captions into two pieces: \n","    #   captions_in has everything but the last word and will be input to the RNN; \n","    #   captions_out has everything but the first word and this is what we will expect the RNN to generate. \n","\n","    # These are offset by one relative to each other because the RNN should produce word (t+1)\n","    # after receiving word t. \n","\n","    # The first element of captions_in will be the START token, \n","    # and the first element of captions_out will be the first word.\n","    captions_in  = captions[:, :-1]\n","    captions_out = captions[:, 1:]\n","\n","    # mask to calculate temporal softmax loss\n","    mask = (captions_out != token_null)\n","\n","    # Weight and bias for the affine transform from image features to initial\n","    # hidden state\n","    W_proj, b_proj = weights['W_proj'], weights['b_proj']\n","\n","    # Word embedding matrix\n","    W_embed = weights['W_embed']\n","\n","    # Input-to-hidden, hidden-to-hidden, and biases for the LSTM\n","    Wx, Wh, b = weights['Wx'], weights['Wh'], weights['b']\n","\n","    # Weight and bias for the hidden-to-vocab transformation.\n","    W_vocab, b_vocab = weights['W_vocab'], weights['b_vocab']\n","    \n","    # initialize gradients dictionary\n","    grads = {}\n","    \n","    ############################################################################\n","    # TODO: Implement the forward and backward passes for the CaptioningLSTM.  #\n","    ############################################################################\n","    \n","    # ------------------------------------------------\n","    # Forward Pass\n","    # ------------------------------------------------\n","    \n","    # (1) project the input image feature into hidden vector\n","    # call affine_forward() function with input features, with W_proj and b_proj as the projection weights\n","    hidden_init, cache_init = ??\n","\n","    # (2) convert the caption of image batch into word embedding\n","    # call word_embedding_forward() function with input caption_in and W_embed weight\n","    captions_in_init, cache_embed = ??\n","\n","    # (3) LSTM Forward Pass\n","    # call lstm_forward() function with input captions_in_init and hidden_init\n","    # also pass the Wx, Wh, and bias b weights into the function\n","    hidden_lstm, cache_lstm = ??\n","    \n","    # (4) calculate temporal scores\n","    # call temporal_affine_forward() function with input hidden_lstm also W_vocab and b_vocab\n","    scores, cache_scores = ??\n","        \n","    # ------------------------------------------------\n","    # Calculate Temporal Softmax Loss\n","    # ------------------------------------------------\n","    # call temporal_softmax_loss() function with input scores, caption_out, and mask that was defined above\n","    loss, dscores = ??\n","\n","   \n","    # ------------------------------------------------\n","    # Backward Pass\n","    # ------------------------------------------------   \n","        \n","    # (4) backward pass temporal affine\n","    # call temporal_affine_backward() function with input dscores and its appropriate cache (see the forward pass)\n","    dhidden_lstm, grads['W_vocab'], grads['b_vocab'] = ??\n","\n","    # (3) LSTM Backward Pass\n","    # call lstm_backward() function with input dhidden_lstm and its appropriate cache (see the forward pass)\n","    dcaptions_in_init, dhidden_init, grads['Wx'], grads['Wh'], grads['b'] = ??\n","\n","\n","    # (2) backward pass embedding\n","    # call word_embedding_backward() function with input dcaption_in_init and its appropriate cache (see the forward pass)\n","    grads['W_embed'] = ??\n","\n","    # (1) backward pass affine\n","    # call affine_backward() function with input dhidden_init and its appropriate cache (see the forward pass)\n","    dfeatures, grads['W_proj'], grads['b_proj'] = ??\n","    \n","    \n","    return loss, grads"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UpX3uth_asQR"},"source":["After doing so, run the following to check your forward pass using a small test case; \n","\n","you should see error on the order of `e-10` or less."]},{"cell_type":"code","metadata":{"id":"1Kqv1XJkasQT"},"source":["N, D, W, H = 10, 20, 30, 40\n","word_to_idx = {'<NULL>': 0, 'cat': 2, 'dog': 3}\n","\n","V = len(word_to_idx)\n","T = 13\n","\n","model = init_weights(word_to_idx, input_dim=D, wordvec_dim=W, hidden_dim=H, dtype=np.float64)\n","\n","# Set all model parameters to fixed values\n","for k, v in model.items():\n","    model[k] = np.linspace(-1.4, 1.3, num=v.size).reshape(*v.shape)\n","    \n","features = np.linspace(-0.5, 1.7, num=N*D).reshape(N, D)\n","captions = (np.arange(N * T) % V).reshape(N, T)\n","\n","loss, grads   = lstm_step(model, features, captions, word_to_idx)\n","expected_loss = 9.82445935443\n","\n","print('loss          : ', loss)\n","print('expected loss : ', expected_loss)\n","print('difference    : ', abs(loss - expected_loss))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xylB0igTasQW"},"source":["**Expected Output**:\n","<pre>\n","loss          :  9.824459354432264\n","expected loss :  9.82445935443\n","difference    :  2.2648549702353193e-12"]},{"cell_type":"markdown","metadata":{"id":"Uu1aYAbiogwB"},"source":["---\n","## 3 - Training Function\n","\n","\n","Here we also provide you the training function for the LSTM Captioning. \n","\n","Read through the `lstm_captioning_train()` function below; \n","\n","it should look very familiar. This is exactly the same with the previous `rnn_captioning_train()` function. The only difference is that we call `lstm_step()` function here\n"]},{"cell_type":"code","metadata":{"id":"RRt4qATkasQX"},"source":["def lstm_captioning_train(weights, data, word_to_idx, \n","                          optimizer = sgd, optim_config={},\n","                          epochs=10, batch_size=100, lr_decay=1.0, \n","                          print_every=10, verbose=1):\n","    tic = time.time()\n","\n","    best_val_acc = 0\n","    best_params  = {}\n","\n","    loss_history      = []\n","    train_acc_history = []\n","    val_acc_history   = []\n","    \n","    # Make a deep copy of the optim_config for each parameter\n","    optim_configs = {}\n","    for p in weights:\n","        d = {k: v for k, v in optim_config.items()}\n","        optim_configs[p] = d\n","\n","    num_train = data['train_captions'].shape[0]\n","\n","    # total iteration per epoch\n","    num_iter  = max(num_train // batch_size, 1)\n","    \n","    #start iteration counts\n","    it = 0\n","\n","    # Start Train\n","    for ep in range(epochs):    \n","\n","        # loop over batch iteration\n","        for i in range(num_iter):\n","        \n","            # ------------------------------------------------\n","            # 1. Sample Minibatch of Training Data\n","            # ------------------------------------------------\n","            captions, features, urls = sample_coco_minibatch(data, \n","                                                             batch_size=batch_size, \n","                                                             split='train')\n","\n","            # ------------------------------------------------\n","            # 2. Compute loss and gradient\n","            # ------------------------------------------------\n","            loss, grads = lstm_step(weights, features, captions, word_to_idx)\n","            loss_history.append(loss)\n","\n","\n","            # ------------------------------------------------\n","            # 3. Parameter Update\n","            # ------------------------------------------------   \n","            # Perform a parameter update\n","            for p, w in weights.items():\n","                dw     = grads[p]\n","                config = optim_configs[p]\n","\n","                next_w, next_config = optimizer(w, dw, config)\n","                weights[p]          = next_w\n","                optim_configs[p]    = next_config\n","            \n","            # iteration count\n","            it +=1\n","\n","            # Maybe print training loss\n","            if verbose==1 and it % print_every == 0:\n","                print ('iteration',it,'(epoch', ep,'/',epochs, '): loss =', loss_history[-1])\n","\n","        # At the end of one epoch:\n","        # Decay learning rate        \n","        for k in optim_configs:\n","            optim_configs[k]['learning_rate'] *= lr_decay\n","\n","\n","    print('Training Done')\n","    toc = time.time()\n","    print('Training Time:= %.2f seconds' % (toc-tic))\n","    print('Training Time:= %.2f minutes' % ((toc-tic)/60))\n","    \n","    return loss_history, weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b-OrfRvpogwE"},"source":["---\n","## 4 - Overfit small data\n","\n","Once you have familiarized yourself with the function, run the following to make sure your model overfits a small sample of 100 training examples. You should see a final loss of less than 0.1.\n","\n","First, initialize the model"]},{"cell_type":"code","metadata":{"id":"cqmMFCYoogwE"},"source":["np.random.seed(231)\n","\n","small_data = load_coco_data(max_train=70)\n","\n","small_lstm_model = init_weights(\n","    word_to_idx = data['word_to_idx'], \n","    input_dim   = data['train_features'].shape[1],\n","    wordvec_dim = 256, \n","    hidden_dim  = 512,\n","    dtype=np.float32,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WyUjZulXiIi-"},"source":["Overfit small data"]},{"cell_type":"code","metadata":{"id":"ifqkMrxwasQZ"},"source":["loss_history, small_lstm_model = lstm_captioning_train(\n","    small_lstm_model,\n","    data         = small_data, \n","    word_to_idx  = data['word_to_idx'], \n","    optimizer    = adam, \n","    optim_config = {'learning_rate': 5e-3,},\n","    epochs       = 100,\n","    batch_size   = 128,\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-xEzEbZK82DU"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","    loss shoud start around 40 and end around 0.05\n","    in about 4 minutes"]},{"cell_type":"markdown","metadata":{"id":"C4VPpNA5iHX-"},"source":["Plot the training losses"]},{"cell_type":"code","metadata":{"id":"iquPyX3WiF4v"},"source":["plt.figure(figsize=(6,4))\n","plt.plot(loss_history)\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.title('Training loss history')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ArddwQa5ogwI"},"source":["---\n","---\n","# [Part 6] LSTM Captioning Testing \n","Unlike classification models, image captioning models behave very differently at training time and at test time. \n","\n","At training time, we have access to the ground-truth caption, so we feed ground-truth words as input to the LSTM at each timestep.\n","\n","While at test time, we sample from the distribution over the vocabulary at each timestep, and feed the sample as input to the LSTM at the next timestep.\n","\n","Therefore we need to implement slightly different forward pass"]},{"cell_type":"markdown","metadata":{"id":"jFrkw-FyogwI"},"source":["---\n","## 1 - Forward Testing Function\n","\n","Implement a test-time forward pass for the model, sampling captions for input feature vectors.\n","\n","At each timestep, we embed the current word, pass it and the previous hidden state to the LSTM to get the next hidden state, use the hidden state to get scores for all vocab words, and choose the word with the highest score as the next word. The initial hidden state is computed by applying an affine transform to the input image features, and the initial word is the `<START>` token\n","\n","\n","You will need to initialize the hidden state of the LSTM by applying the learned affine transform to the input image features. The first word that you feed to the LSTM should be the `<START>` token; its value is stored in the variable `token_start`. \n","    "]},{"cell_type":"markdown","metadata":{"id":"YlzlxzXAji4y"},"source":["\n","First, you need to project the input feature. Then, at each timestep you will need to do to:  \n"," 1. Embed the previous word using the learned word embeddings \n","\n"," 2. Make an `LSTM step` using the previous hidden state and the embedded current word to get the next hidden state.\n"," 3. Apply the learned affine transformation to the next hidden state to get scores for all words in the vocabulary                          \n"," 4. Select the word with the `highest score` as the next word, writing it (the word index) to the appropriate slot in the captions variable   \n","                                                                        \n","For simplicity, you do not need to stop generating after an `<END>` token is sampled, but you can if you want to.                                 \n","\n","NOTE: we are still working over minibatches in this function.      "]},{"cell_type":"markdown","metadata":{"id":"nWev3ZIqi3Ob"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","Run a test-time forward pass for the model, sampling captions for input    feature vectors."]},{"cell_type":"code","metadata":{"id":"On7mPHBmasQc"},"source":["def lstm_captioning_test(weights, features, word_to_idx, max_length=30):\n","\n","    # create special token\n","    token_null  = word_to_idx['<NULL>']\n","    token_start = word_to_idx.get('<START>')\n","    token_end   = word_to_idx.get('<END>')\n","    \n","    N = features.shape[0]\n","    captions = token_null * np.ones((N, max_length), dtype=np.int32)\n","\n","    # Unpack parameters\n","    W_proj, b_proj   = weights['W_proj'], weights['b_proj']\n","    W_embed          = weights['W_embed']\n","    Wx, Wh, b        = weights['Wx'], weights['Wh'], weights['b']\n","    W_vocab, b_vocab = weights['W_vocab'], weights['b_vocab']\n","    \n","    # (0) project the input image feature into current hidden vector\n","    # call affine_forward() function with input features, W_proj, and b_proj as the projection weights\n","    current_h, _ = ??\n","\n","    \n","    # create zeros matrix with size the same as current_h\n","    current_c = np.zeros_like(current_h)\n","\n","    # initialize array to accumulate the generated words\n","    words = np.zeros(N, dtype=int)\n","    words.fill(token_start)\n","\n","    # start generating caption\n","    for step in range(max_length):\n","        \n","        # (1) Embedding the output word for the next iteration\n","        #     call word_embedding_forward() function with input words and W_embed weight\n","        word_embed, _ = ??\n","        \n","        # (2) Make an lstm step using the previous hidden state and the embedded current word to get the next hidden state;\n","        #     call lstm_step_forward() function with input word_embed, current_h, and current_c\n","        #     also pass the Wx, Wh, and bias b weights into the function\n","        current_h, current_c, _ = ??\n","\n","        # (3) Apply the learned affine transformation to the next hidden state to get scores for all words in the vocabulary \n","        #     call affine_forward() function with input current_h also W_vocab and b_vocab\n","        scores, _ = ??\n","\n","        # (4) Select the word with the highest score as the next word\n","        #     use np.argmax() to scores with axis=1\n","        captions[:, step] = ??\n","\n","        # store the generated caption as input word for the next iteration\n","        words = captions[:, step]\n","        \n","    return captions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Ry4WejR296o"},"source":["---\n","## 2 - Image Captioning Testing Function\n","\n","Now define function to load several image and generate the caption"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"X02DNfWPogwN"},"source":["def generate_caption(model, data, split, batch_size):\n","    print('Generating Caption from ',split,'set images')\n","    print('-------------------------------------------')\n","    \n","    gt_captions, features, urls = sample_coco_minibatch(data, split=split, batch_size=batch_size)\n","    gt_captions = decode_captions(gt_captions, data['idx_to_word'])\n","\n","    sample_captions = lstm_captioning_test(model, features, data['word_to_idx'])\n","    sample_captions = decode_captions(sample_captions, data['idx_to_word'])\n","\n","    for gt_caption, sample_caption, url in zip(gt_captions, sample_captions, urls):\n","        fig = plt.figure(figsize=(8,6))\n","        plt.imshow(image_from_url(url))\n","        fig.suptitle('Caption Result : %s\\nGround Truth   : %s' % (sample_caption, gt_caption), x=0, y=0.96, ha='left', size=15)\n","        plt.axis('off')\n","        plt.show()\n","        print('\\n-----------------------------------------------------\\n')\n","\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e-v49HktogwN"},"source":["---\n","## 3 - Test-time sampling\n","\n","After you finish the testing function implementations, run the following to sample from your overfitted model on both training and validation data. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"NQdihb7VT2nz"},"source":["---\n","### a. Test on Training Set\n","\n","The samples on training data should be very good; \n"]},{"cell_type":"code","metadata":{"id":"bkORBYxt3TFd"},"source":["generate_caption(model=small_lstm_model, data=small_data, split='train', batch_size=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a57l4AvI3XCB"},"source":["---\n","### b. Test on Validation  Set\n","The samples on validation data are still bad, but you should see that it's <font color='red'>much better than using Vanilla RNN</font>"]},{"cell_type":"code","metadata":{"id":"WJKC19BY3S5s"},"source":["generate_caption(model=small_lstm_model, data=small_data, split='val', batch_size=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7QVEFWxFogwP"},"source":["---\n","---\n","# [Part 7] Train your own model\n","\n","* You can continue the training on bigger set of data and test it \n","* Or you can change the model to a bigger model"]},{"cell_type":"markdown","metadata":{"id":"IKskq82nogwP"},"source":["---\n","## 1 - Get a bigger set of sample data\n","\n","load a bigger sample set from coco dataset\n"]},{"cell_type":"code","metadata":{"id":"1I5bKC_yogwQ"},"source":["bigger_data = load_coco_data(max_train=500)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CrwlCiWxogwS"},"source":["---\n","## 2 - Generate new and bigger Model\n","create a new model, or just use the previous model\n"]},{"cell_type":"code","metadata":{"id":"ag3_p0j7ogwT"},"source":["new_model = init_weights(\n","    word_to_idx = data['word_to_idx'], \n","    input_dim   = data['train_features'].shape[1],\n","    wordvec_dim = 256, \n","    hidden_dim  = 512,\n","    # dtype=np.float32,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XfzB4U6pogwU"},"source":["---\n","## 3 - Train your model\n","\n","you can generate new model\n","\n","you can run this part over-and-over to overfit the data"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"LbThTZxPogwW"},"source":["loss_history, new_model = lstm_captioning_train(\n","    new_model,\n","    data         = bigger_data, \n","    word_to_idx  = data['word_to_idx'], \n","    optimizer    = adam, \n","    optim_config = {'learning_rate': 5e-3,},\n","    epochs       = 100,\n","    batch_size   = 64,\n","    lr_decay     = 0.99,\n","    print_every  = 20,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gVWoPkvT9DSg"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","    loss shoud start around 50 and end around 0.04\n","    in about 15 minutes"]},{"cell_type":"markdown","metadata":{"id":"6squGVisl46i"},"source":["Plot the training losses"]},{"cell_type":"code","metadata":{"id":"S6Ib0JBMl3mP"},"source":["plt.figure(figsize=(6,4))\n","plt.plot(loss_history)\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.title('Training loss history')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KEhrzSrHogwX"},"source":["---\n","## 4 - Test the trained model\n","\n","Now test it\n","\n","Again, you should see that, compared to the Vanilla RNN, the results are much better "]},{"cell_type":"markdown","metadata":{"id":"4PbFluDdUEi7"},"source":["---\n","### a. Test on Training Set\n","\n","The samples on training data should be very good; \n"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Ryt0SAGmogwX"},"source":["generate_caption(model=new_model, data=bigger_data, split='train', batch_size=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q0ClIoNf33WU"},"source":["after several training step, you should see that the validation captioning is getting better"]},{"cell_type":"markdown","metadata":{"id":"GXaeOR0TUHNj"},"source":["---\n","### b. Test on Validation  Set\n","You should see that some of the captions are starting to get it right\n","\n"]},{"cell_type":"code","metadata":{"id":"Hsl53ZLy3prI"},"source":["generate_caption(model=new_model, data=bigger_data, split='val', batch_size=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xLSMxAh6xnEC"},"source":["\n","You can train it more to increase the performance"]},{"cell_type":"markdown","metadata":{"id":"aQqQ_gcO92ub"},"source":["\n","---\n","\n","# Congratulation, You've Completed Exercise 18\n","<p>Copyright &copy;  <a href=https://www.linkedin.com/in/andityaarifianto/>2020 - ADF</a> </p>"]},{"cell_type":"markdown","metadata":{"id":"7_Hkr9kg9Do-"},"source":["![footer](https://i.ibb.co/yX0jfMS/footer2020.png)"]}]}