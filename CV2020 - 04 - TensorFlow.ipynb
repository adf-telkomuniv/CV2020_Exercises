{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CV2020 - 04 - TensorFlow.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"f_ChrQTZyAZU"},"source":["![title](https://i.ibb.co/f2W87Fg/logo2020.png)\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"oUkeuLWzoHoN"},"source":["<table  class=\"tfo-notebook-buttons\" align=\"left\"><tr><td>\n","    \n","<a href=\"https://colab.research.google.com/github/adf-telkomuniv/CV2020_Exercises/blob/master/CV2020 - 04 - TensorFlow.ipynb\" source=\"blank\" ><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>\n","</td><td>\n","<a href=\"https://github.com/adf-telkomuniv/CV2020_Exercises/blob/master/CV2020 - 04 - TensorFlow.ipynb\" source=\"blank\" ><img src=\"https://i.ibb.co/6NxqGSF/pinpng-com-github-logo-png-small.png\"></a>\n","    \n","</td></tr></table>"]},{"cell_type":"markdown","metadata":{"id":"sjlcHwermNUS"},"source":["\n","# Task 4 - TensorFlow\n","\n","\n","You've written a lot of code in this assignment to provide a whole host of neural network functionality. Dropout, Batch Norm, and 2D convolutions are some of the workhorses of deep learning in computer vision. \n","\n","You've also worked hard to make your code efficient and vectorized.\n","\n","For the this assignment, though, we're going to leave behind your beautiful codebase and instead migrate to one of two popular deep learning frameworks: in this instance, **TensorFlow**\n","\n","The goals of this assignment are as follows:\n","\n","    * Use TensorFlow at three different levels of abstraction,\n","    * Barebone TensorFlow: work directly with low-level TensorFlow graphs.\n","    * Keras Sequential API: use tf.keras.Sequential to define a linear feed-forward network.\n","    * Keras Model API: use tf.keras.Model to define arbitrary neural network architecture.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"M8molz1J9Dl-"},"source":["Write down your Name and Student ID"]},{"cell_type":"code","metadata":{"id":"CkzQo8MY9DmB"},"source":["## --- start your code here ----\n","\n","NIM = ??\n","Nama = ??\n","\n","## --- end your code here ----"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pMlC1Kwa9Dl0"},"source":["---\n","## About Tensorflow\n","\n","\n","<img src=\"https://www.gstatic.com/devrel-devsite/va3a0eb1ff00a004a87e2f93101f27917d794beecfd23556fc6d8627bba2ff3cf/tensorflow/images/lockup.svg\" alt=\"tensorflow\" width=\"300px\"/>\n","\n","[TensorFlow](https://www.tensorflow.org/) is a **Deep Learning Library**, developed by the Google Brain Team within the Google Machine Learning Intelligence research organization, for the purposes of machine learning and artificial neural network research.\n","\n","TensorFlow is a system for executing computational graphs over Tensor objects, with native support for performing backpropogation for its Variables. In it, we work with Tensors which are n-dimensional arrays analogous to the numpy ndarray.\n","\n","\n","\n","**Tensorflow Key Features**\n","\n","* Define, optimize and efficiently calculate mathematical expressions involving multi-dimensional arrays (tensors).\n","* Programming support from deep neural networks and machine learning techniques.\n","* Use of GPU computing and automatic memory optimization.\n","* High computing capability across machines and large data sets.\n","\n","TensorFlow is available with Python and C ++ support, but the Python API is more supported and easier to learn.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zf0ePYsfVHvc"},"source":["---\n","## About Keras\n","\n","<img src=\"https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png\" alt=\"keras\" width=\"300px\"/>\n","\n","[Keras](https://keras.io/) is a very modular and minimalist **Deep Learning Library**, written in Python and capable of running on TensorFlow or Theano. This library was developed with a focus on enabling fast experiments.\n","\n","At first Keras was developed to help users to easily use Theano and Tensorflow's which at the time was very technical and complex in implementation.\n","\n","Since Tensorflow version 1.5, Keras was adopted by Google and since then the built API has been included in the Tensorflow distribution."]},{"cell_type":"markdown","metadata":{"id":"MHosKd7SVR78"},"source":["---\n","\n","Working with Tensorflow will give us benefits:\n","\n","* Our code will now run on GPUs! Much faster training. Writing your own modules to run on GPUs is beyond the scope of this class, unfortunately.\n","\n","* We want you to be ready to use one of these frameworks for your project so you can experiment more efficiently than if you were writing every feature you want to use by hand. \n","\n","* We want you to stand on the shoulders of giants! TensorFlow and PyTorch are both excellent frameworks that will make your lives a lot easier, and now that you understand their guts, you are free to use them :) \n","\n","* We want you to be exposed to the sort of deep learning code you might run into in academia or industry. "]},{"cell_type":"markdown","metadata":{"id":"QGarRj9tWulZ"},"source":["---\n","## GPU Runtime\n","Since we're going to use TensorFlow, we can utilize the GPU to accelerate the process\n","\n","For that, make sure that this Colaboratory file is set to use GPU\n","\n","* select **Runtime** in taskbar\n","* select **Change Runtime Type**\n","* choose Hardware accelerator **GPU**\n","\n","<center>\n","  \n","![gpu](https://i.ibb.co/QX3Brf0/gpu.png)\n"]},{"cell_type":"markdown","metadata":{"id":"6VAE_sE-Bgk1"},"source":["---\n","---\n","#[Part 0] Import Libraries and Load Data"]},{"cell_type":"markdown","metadata":{"id":"12SMnaunBw96"},"source":["---\n","## 1 - Import Libraries\n","\n","Import required libraries"]},{"cell_type":"code","metadata":{"id":"hsZYqgngcZzY"},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os, datetime\n","from tabulate import tabulate\n","\n","%matplotlib inline\n","%load_ext autoreload\n","%load_ext tensorboard\n","%autoreload 2\n","\n","# tensorboard log\n","logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fTMPdtW1mNVv"},"source":["---\n","## 2 - Load CIFAR-10"]},{"cell_type":"code","metadata":{"id":"HJMZF1BZmNVw"},"source":["(X_train_ori, y_train), (X_test_ori, y_test) = tf.keras.datasets.cifar10.load_data()\n","\n","class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c57WBdtqmNVz"},"source":["---\n","## 3 - Split Validation Data"]},{"cell_type":"code","metadata":{"id":"5vuvkKCdmNV1","cellView":"both"},"source":["X_val_ori = X_train_ori[-10000:,:]\n","y_val     = y_train[-10000:]\n","\n","X_train_ori = X_train_ori[:-10000, :]\n","y_train     = y_train[:-10000]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WJZisKPImNV4"},"source":["---\n","## 4 - Normalize and Reshape Data"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"TwP9wbYLmNV5","cellView":"both"},"source":["X_train = X_train_ori.astype('float32')\n","X_val   = X_val_ori.astype('float32')\n","X_test  = X_test_ori.astype('float32')\n","\n","mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n","std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n","\n","X_train = (X_train - mean_pixel) / std_pixel\n","X_val   = (X_val - mean_pixel) / std_pixel\n","X_test  = (X_test - mean_pixel) / std_pixel\n","\n","X_train = X_train.astype('float32')\n","X_val   = X_val.astype('float32')\n","X_test  = X_test.astype('float32')\n","\n","\n","print('X_train.shape =',X_train.shape)\n","print('X_val.shape   =',X_val.shape)\n","print('X_test.shape  =',X_test.shape)\n","\n","y_train = y_train.ravel()\n","y_val   = y_val.ravel()\n","y_test  = y_test.ravel()\n","\n","print('\\ny_train.shape =',y_train.shape)\n","print('y_val.shape   =',y_val.shape)\n","print('y_test.shape  =',y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3o3xBPOGpPoV"},"source":["---\n","---\n","# [Part 1] Keras Model API\n","Implementing a neural network using the low-level TensorFlow API is a good way to understand how TensorFlow works, but it's a little inconvenient, we had to manually keep track of all Tensors holding learnable parameters, and we had to use a control dependency to implement the gradient descent update step. .\n","\n","Furthermore, since the release of version 2.0, Tensorflow is standardizing its implementation using High-level Keras API. This is enabled by the introduction of the [\"Eager Execution mode\"](https://www.tensorflow.org/guide/eager) which allows you to evaluates Tensor operations imperatively (in the order you write them), similar to NumPy and PyTorch, without building graphs.\n","\n","Eager-mode is slightly less performant but a lot more intuitive. This makes it easy to get started with TensorFlow and debug models, and it reduces boilerplate as well.\n","\n","\n","In this part of the notebook we will define neural network models using the&nbsp; `tf.keras.Sequential` &nbsp;and&nbsp; `tf.keras.Model` API. \n"]},{"cell_type":"markdown","metadata":{"id":"Ze7hwafepemO"},"source":["---\n","## 1 - Keras Model and Layers\n","\n","Keras is a Deep Learning API that was built as an independent open source project by more than 700 contributors. \n","\n","During its construction until, Keras is constantly updated so that there are often changes in the technical side of writing code. One of them is how to define a network model.\n","\n","There are two basic model building in Keras, using linear [**Sequential**](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model, or using more advance graphical [**Models**](https://www.tensorflow.org/api_docs/python/tf/keras/Model).\n","\n","For now, let's import those two packages\n"]},{"cell_type":"code","metadata":{"id":"c3wiwW-0pg8G"},"source":["from tensorflow.keras import Sequential\n","from tensorflow.keras import Model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vbqPF7nKpg8W"},"source":["\n","For this example, let's create a **2 layers neural network** with **100 neurons** in its hidden layer\n","\n","There are four types of layers that we will use to build this model:\n","\n","     * Input layer      to receive input shape\n","     * Flatten layer    to reshape input into one-dimensional matrix for neural network\n","     * Dense layer      to add affine fully connected layer\n","     * Activation layer to add nonlinearity\n","     \n","For other types of layers, you can look it in **[tf.keras.layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers)**"]},{"cell_type":"code","metadata":{"id":"Rb1jELxgpg8Z"},"source":["from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Activation"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zyjgxRHYpv4s"},"source":["---\n","## 2 - Old Sequential API\n","\n","The first way to build a model using Keras, and one of the oldest ways, is to initialize the [**Sequential**](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model object, \n","\n","then one by one we add the layers that we want to stack as follows\n"]},{"cell_type":"code","metadata":{"id":"3qVDUXlApv44"},"source":["model = Sequential(name='my_model_1')\n","\n","model.add( Input((32,32,3)) )           # input layer to receive image 32x32x3\n","model.add( Flatten() )                  # Flatten layer to reshape input into 3072x1\n","model.add( Dense(100) )                 # First affine layer (hidden layer) with 100 neurons\n","model.add( Activation('sigmoid') )      # Sigmoid activation function\n","model.add( Dense(10) )                  # Second affine layer (output layer) with 10 neuron\n","model.add( Activation('softmax') )      # Softmax activation function\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mQiRgmbudo3S"},"source":["\n","The following summary shows how many parameters each layer is made up of (the number of entries in the weight matrices and bias vectors). Note that a value of ```None``` in a particular dimension of a shape means that the shape will dynamically adapt based on the shape of the inputs."]},{"cell_type":"code","metadata":{"id":"BJW5YA0WlhqO"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vCa-UQ26pv5B"},"source":["---\n","## 3 - Compact Sequential API\n","\n","The update on the Keras layer API allows us to add the input shape into the first layer directly.\n","It also allows up to add the activation function directly from the `Dense` layer without adding the `Activation` layer. \n"]},{"cell_type":"code","metadata":{"id":"GKWYVDd7pv5D"},"source":["# create model new\n","model = Sequential(name='my_model_2')\n","\n","model.add( Flatten(input_shape=(32,32,3))   )    # Flatten layer to receive image 32x32x3 and reshape it into 3072x1\n","model.add( Dense(100, activation='sigmoid') )    # First affine layer (hidden layer) with 100 neurons and sigmoid activation\n","model.add( Dense(10,  activation='softmax') )    # Second affine layer (output layer) with 10 neuron and softmax activation\n","      \n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D2FPxKaGpv5N"},"source":["---\n","## 4 - Functional Model API\n","The third way to build models is to use **functional API** which allows us to build more complex model graphs, for example, having many input and output. The functional API can handle models with non-linear topology, models with shared layers, and models with multiple inputs or outputs. After the graph is defined, group layers into an object using [**Models**](https://www.tensorflow.org/api_docs/python/tf/keras/Model) module\n","\n","The following is an example of building a model using **functional API**"]},{"cell_type":"code","metadata":{"id":"pC5yPz4Hpv5N"},"source":["\n","# create model graph\n","in_node  = Input(shape=(32,32,3))                 # define input node to receive image 32x32x3\n","x        = Flatten() (in_node)                    # define x node as Flatten layer that receive input node\n","x        = Dense(100, activation='sigmoid')(x)    # pass x node to Dense hidden layer\n","out_node = Dense(10,  activation='softmax')(x)    # define output node as Dense layer that receive x node\n","\n","# initialize the model\n","model = Model(in_node, out_node, name='my_model_3')\n","\n","model.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qJa4iGcppv5U"},"source":["---\n","## 5 - Sequential API (Current)\n","The fourth way is a new way, and the current standard, of building a Sequential model. \n","\n","Similar to the first and second ways, but we can directly register the layers in the list when initializing the Sequential object as follows"]},{"cell_type":"code","metadata":{"id":"DqindqSvpv5V"},"source":["# create model compact sequential\n","\n","model = Sequential([                    \n","    Flatten(input_shape=(32,32,3)),     # Flatten layer to receive image 32x32x3 and reshape it into 3072x1\n","    Dense(100, activation='sigmoid'),   # First affine layer (hidden layer) with 100 neurons and sigmoid activation  \n","    Dense(10,  activation='softmax')    # Second affine layer (output layer) with 10 neuron and softmax activation\n","], name='my_model_4')\n","\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R8NYlKARqkxE"},"source":["The four models defined above are the same model. You can see it from the summaries that all model has $308,310$ total parameters (weights)"]},{"cell_type":"markdown","metadata":{"id":"3iqPeXbfdz0G"},"source":["---\n","## 6 - Plot Model\n","\n","Plot model is a utility function to converts a Keras model to dot format and save to a file. This enables us to visualize the model more easily, especially for non-linear models."]},{"cell_type":"code","metadata":{"id":"VF4cEoDbHDqC"},"source":["from tensorflow.keras.utils import plot_model\n","\n","plot_model(model, \n","           to_file=model.name+'.png', \n","           show_shapes=True, \n","           show_layer_names=False,\n","           rankdir='LR',\n","           dpi=70\n","          )\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y-kMHkC_wTnP"},"source":["---\n","---\n","# [Part 2] Activation and Optimizer "]},{"cell_type":"markdown","metadata":{"id":"5W3SaXjUc4NN"},"source":["---\n","## 1 - Activation Functions\n","\n","Activation functions are a core ingredient in deep neural networks. In fact they are what allows us to make use of multiple layers in a neural network. There are a number of different activation functions, each of which are more or less useful under different circumstances. The four activation functions that you are most likely to encounter are, arguably, [ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU), [Tanh](https://www.tensorflow.org/api_docs/python/tf/keras/activations/tanh), [Sigmoid](https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid), and [Softmax](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Softmax). \n","\n","More of activation functions can be seen at [keras activations](https://keras.io/api/layers/activations/) or [tf.keras activations](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Activation)"]},{"cell_type":"markdown","metadata":{"id":"V4SUoegchsDz"},"source":["---\n","## 2 - Loss Functions\n","\n","To optimize the model, we need to specify a loss function for our classifier. This tells us how good our model's predictions are compared to the actual labels (the targets), with a lower loss meaning better predictions. There are also various types of **loss functions** for various cases such as:\n","* `categorical crossentropy` &nbsp; for multi-class classifications\n","* `binary crossentropy` &nbsp; for binary classification\n","* `mean squared error` &nbsp; for regression\n","* and many others\n","\n","<br>\n","\n","The standard loss function to use with a multi-class classifier is the **cross-entropy loss** also known as the \"negative log likelihood\" for a classifier.\n","\n","For a a classification problem with $C$ classes, the cross-entropy loss is defined as\n","\n","$$Loss = -\\frac{1}{N}\\sum_{i=1}^N \\sum_{c=1}^C log( p(y|X_i)_c) \\mathbb{1}[y_i=c]$$\n","\n","\n","\n","More of loss functions can be seen at [keras losses](https://keras.io/api/losses/) or [tf.keras losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses)"]},{"cell_type":"markdown","metadata":{"id":"fwaWC62ajf2m"},"source":["---\n","## 3 - Optimizer Functions\n","\n","After determining the loss function, we can choose the optimization function that we will use to train the model. The optimizer also responsible for controlling the learning rate.\n","\n","There are various types of optimization functions such as:\n","* `sgd` &nbsp;for standard&nbsp; `stochastic gradient descent`, including &nbsp;`nesterov`\n","* `rmsprop` &nbsp;which is a further development of 'sgd'\n","* `adam` &nbsp;as the current standard optimization function\n","* and many others\n","\n","<br>\n","Here is an illustration showing how a few of these methods perform on a toy problem: \n","\n","<table>\n","  <tr><td  align=\"center\">\n","    <img src=\"https://cs231n.github.io/assets/nn3/opt1.gif\" width=\"70%\" \n","         alt=\"Optimization algorithms visualized over time in 3D space.\">\n","  </td></tr>\n","  <tr><td align=\"center\">\n","    <b>Figure:</b> Optimization algorithms visualized over time in 3D space.<br/>(Source: <a href=\"http://cs231n.github.io/neural-networks-3/\">Stanford class CS231n</a>, MIT License, Image credit: <a href=\"https://twitter.com/alecrad\">Alec Radford</a>)\n","  </td></tr>\n","</table>\n","\n","\n","More of optimizer functions can be seen at [keras optimizers](https://keras.io/api/optimizers/) or [tf.keras optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)"]},{"cell_type":"markdown","metadata":{"id":"sipVd5-6id7R"},"source":["---\n","---\n","# [Part 3] Preparing Data with TensorFlow\n","At the moment, our training data consists of two large tensors. The images are stored in a tensor of shape $[40000, 32, 32, 3]$, consisting of all the $32 \\times 32 \\times 3$ images matrices stacked together. The labels are stored in a 1D vector of shape $[40000]$. \n","\n","We wish to train a model using **mini-batch stochastic gradient descent**. In order to do so, we need to shuffle the data and split it into smaller (mini-)batches. We also convert the data from numpy arrays to TensorFlow Tensors.\n","\n","In order to do this batching (and shuffling) we will use the Tensorflow [Dataset API](https://www.tensorflow.org/api_docs/python/tf/data/Dataset), which is a set of simple reusable components that allow you to build efficient data pipelines. "]},{"cell_type":"markdown","metadata":{"id":"COaHTen8XvJo"},"source":["---\n","## 1 - Define Batch Dataset\n","\n","We start by defining the `batch_size` hyperparameter of our model. \n","> This hyperparameter controls the sizes of the mini-batches (chunks) of data that we use to train the model. The value you use will affect the memory usage, speed of convergence and potentially also the performance of the model. It also interacts with the learning rate used in gradient descent.  \n","\n","Then, we  group the image and label tensors together into a tuple and then split them into individual entries using [from_tensor_slices()](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices) function.\n","\n","The next thing we do is add a shuffle component and put the batch component to return a random batch of slices from the dataset. The output of this pipeline will be tuples of tensors containing images and label. The images will be of shape `(batch_size, 32, 32, 3)` and the labels of shape `(batch_size, )`"]},{"cell_type":"code","metadata":{"id":"b2-LgxEDidWV"},"source":["# define the batch size\n","batch_size = 128\n","\n","train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","train_ds = train_ds.shuffle(buffer_size=batch_size * 10)\n","train_ds = train_ds.batch(batch_size)\n","\n","image_shape = X_train.shape[1:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ig6GaenZalBE"},"source":["We do the same for the validation dataset, except we don't need to shuffle this time."]},{"cell_type":"code","metadata":{"id":"w77zK-kplCV-"},"source":["val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n","val_ds = val_ds.batch(batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cHN9ka7dG6bN"},"source":["---\n","---\n","# [Part 4] Tensorflow Training Function\n","\n","In graph mode, TensorFlow builds up a \"computation graph\" which captures all operations of the model and their dependencies. For training, the gradient can then be computed by traversing backwards from every node through its dependents and applying the \"chain rule\" of differentiation.\n","\n","However, in Eager mode, we don't have the concept of the computation graph anymore. Operations are performed imperatively (in the order in which they were executed). \n"]},{"cell_type":"markdown","metadata":{"id":"c8Pcv9G0Qjzc"},"source":["---\n","## 1 - Three-layer Neural Net\n","\n","In this section we'll build a classifier. Here you will complete the implementation of Three-layer Neural Net with the following architecture:\n","\n","<pre>\n","|              |              |         |\n","| <font color='red'>dense</font> - <font color=''>relu</font> | <font color='red'>dense</font> - <font color=''>relu</font> |  <font color='brown'>dense</font>  |\n","|              |              |         |\n","|       1      |      2       |    3    |\n","</pre>"]},{"cell_type":"markdown","metadata":{"id":"6SUahghIck4j"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","Define your classification model. \n","\n","You can define the model using Sequential or Functional API. You can also experiment by trying to change the layer type, activation functions, and number of neurons. However, for this pipeline, **do not** add activation function to the output layer."]},{"cell_type":"code","metadata":{"id":"jxM2gPBdlV-R"},"source":["model = Sequential([\n","                             \n","    Flatten(input_shape=(32,32,3)),  \n","\n","    ??,   # add a dense layer with 256 neurons and relu activation\n","    ??,   # add a dense layer with 128 neurons and relu activation\n","\n","    # Create an \"output layer\" with 10 neurons, \n","    # do not add activation to this output layer\n","    Dense(10),\n","\n","], name='my_model')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K7gcJ0E0qY9g"},"source":["Now display the architecture summary"]},{"cell_type":"code","metadata":{"id":"QWgc6mRbwlLl"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GHPgxrGhkRlA"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_? (Flatten)          (None, 3072)              0         \n","_________________________________________________________________\n","dense_? (Dense)              (None, 256)               786688    \n","_________________________________________________________________\n","dense_? (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_? (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 820,874\n","Trainable params: 820,874\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"rigkXhbUqhKg"},"source":["let's also plot the model design"]},{"cell_type":"code","metadata":{"id":"rDxsEQWCw5yG"},"source":["plot_model(model, \n","           to_file=model.name+'.png', \n","           show_shapes=True, \n","           show_layer_names=False,\n","           rankdir='LR',\n","           dpi=70\n","          )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aegx3nGCNjTq"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src=\"https://i.ibb.co/tK9yMJY/3layernet.png\" width=\"80%\">"]},{"cell_type":"markdown","metadata":{"id":"NPFnNas5T-52"},"source":["---\n","## 2 - Define Optimizer and Loss\n","\n","Here we use the **Adam optimizer** to train our neural networks. Adam is a variant of stochastic gradient descent which often performs well in practice. "]},{"cell_type":"markdown","metadata":{"id":"PNbzxfW2ynsT"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","Define  the oprimizer\n","\n","use ```tf.keras.optimizers.Adam()```."]},{"cell_type":"code","metadata":{"id":"qvzD08cj0wF1"},"source":["# Instantiate an optimizer to train the model.\n","optimizer = ??\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N5Q6_1YNyXWd"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","Define  the loss\n","\n","use ```tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)```."]},{"cell_type":"code","metadata":{"id":"ab9tXVH4htTy"},"source":["# Instantiate a loss function.\n","loss_fn = ??\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RFuTZPYfVDxX"},"source":["---\n","## 3 - Define Metrics\n","\n","Select metrics to measure the loss and the accuracy of the model. \n","These metrics accumulate the values over epochs and then print the overall result."]},{"cell_type":"code","metadata":{"id":"AebIUnG80xke"},"source":["from tensorflow.keras import metrics\n","\n","train_loss     = metrics.Mean(name='train_loss')\n","val_loss       = metrics.Mean(name='val_loss')\n","\n","train_accuracy = metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","val_accuracy   = metrics.SparseCategoricalAccuracy(name='val_accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ksS-p-a-VnrC"},"source":["---\n","## 4 - Train Step Function\n","\n","\n","The default runtime in TensorFlow 2.0 is eager execution. TensorFlow uses a mechanism called the **\"GradientTape\"** for computing gradients in Eager mode. \n","\n","Basically, the gradient tape records the order of all operations as they are executed, and can then be \"run backwards\" (traversed from last to first operation) for computing the gradients.\n","\n","This is great for debugging, but graph compilation has a definite performance advantage. \n","\n","Decribing your computation as a static graph enables the framework to apply global performance optimizations.\n"]},{"cell_type":"markdown","metadata":{"id":"Krin326Rj27-"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","Define a function to train the model using `tf.GradientTape`. This opens a GradientTape to record the operations run during the forward pass, which enables auto-differentiation. Inside the function we run the forward pass of the layer, and update the parameters using the recorded gradients of the trainable variables.\n"]},{"cell_type":"code","metadata":{"id":"XGmew_G90tqA"},"source":["@tf.function\n","def train_step(x, y):\n","\n","    # Initialise a GradientTape to track the operations\n","    with tf.GradientTape() as tape:\n","\n","        # Compute the logits (un-normalised scores) of the current batch of examples\n","        # using the neural network architecture we defined earlier\n","        # call model() function with input x and set training=True\n","        logits = ??\n","\n","        # Compute the loss value for this minibatch.\n","        # call loss_fn() function with input y and logits\n","        loss_value = ??\n","\n","    # Use the gradient tape to automatically retrieve\n","    # the gradients of the trainable variables with respect to the loss.\n","    gradients = tape.gradient(loss_value, model.trainable_weights)\n","\n","    # Run one step of gradient descent by updating\n","    # the value of the variables to minimize the loss.\n","    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n","\n","    # Update train metrics\n","    train_loss(loss_value)\n","    train_accuracy.update_state(y, logits)\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zFegUL2ZWejk"},"source":["---\n","## 5 - Test Step Function\n","\n","Define a function to evaluate the model. This function will run a validation loop at the end of each epoch."]},{"cell_type":"markdown","metadata":{"id":"UxN9swef0e27"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","complete the function\n"]},{"cell_type":"code","metadata":{"id":"N5p4OKH-0tnS"},"source":["@tf.function\n","def test_step(x, y):\n","\n","    # call model() with input x and set training=False\n","    logits = ??\n","\n","    # call loss_fn() function with input y and logits\n","    loss_value = ??\n","\n","    # Update val metrics\n","    val_loss(loss_value)\n","    val_accuracy.update_state(y, logits)\n","\n","    return logits, loss_value, val_accuracy.result()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P6da4wNnXAGw"},"source":["---\n","## 6 - Training Loop\n","\n","Define the training loop as follow:\n","* Define a `for` loop that iterates over epochs. For each epoch:\n","    * open a `for` loop that iterates over the training dataset, in batches.\n","      <br>for each train batch, call the `train_step()` function\n","    * open another `for` loop that iterates over the validation dataset, in batches.\n","      <br>for each validation batch, call the `test_step()` function\n"]},{"cell_type":"markdown","metadata":{"id":"xmDeyUAj0lVI"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","complete the function<br>\n","and train the network for 20 epochs"]},{"cell_type":"code","metadata":{"id":"WJCxE44olhnr"},"source":["# The number of epochs to run\n","num_epochs = 20  \n","\n","# Lists to store the loss and accuracy of every epoch\n","history = {}\n","history['loss']     = []\n","history['val_loss'] = []\n","history['acc']      = []\n","history['val_acc']  = []\n","\n","for epoch in range(num_epochs):\n","\n","    # Loop over our data pipeline\n","    for x_batch_train, y_batch_train in train_ds:\n","        # call train_step() function with input x_batch_train and y_batch_train\n","        ??\n","        \n","    # Run a validation loop at the end of each epoch.\n","    for x_batch_val, y_batch_val in val_ds:\n","        # call test_step() function with input x_batch_val and y_batch_val\n","        ??\n","    \n","    # add current loss and accuracy to history\n","    history['loss'].append(train_loss.result())\n","    history['val_loss'].append(val_loss.result())\n","\n","    history['acc'].append(train_accuracy.result())\n","    history['val_acc'].append(val_accuracy.result())\n","\n","    # print current loss and accuracy\n","    template = 'Epoch {:03d}, Loss: {:.4f}, Train Acc: {:.2%}, Val Acc: {:.2%}'\n","    print(template.format(epoch+1,\n","                          train_loss.result(), \n","                          train_accuracy.result(),\n","                          val_accuracy.result()))\n","    \n","\n","    # Reset training metrics at the end of each epoch\n","    train_accuracy.reset_states()\n","    val_accuracy.reset_states()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o_lvvWE7L-ej"},"source":["**EXPECTED OUTPUT**:\n","\n","<pre>The loss should start from ~1.7 and end around 0.9 with validation accuracy around 49%"]},{"cell_type":"markdown","metadata":{"id":"vWg1Ojmcl4rU"},"source":["The code block shows a typical training loop. There's actually an easier way to do this using Tensorflow and Keras, which we'll see later."]},{"cell_type":"markdown","metadata":{"id":"Yc8w-6vLXXBy"},"source":["---\n","## 7 - Visualize Training History\n","Plot the loss and accuracy during training"]},{"cell_type":"code","metadata":{"id":"B4q0inm0lhkv"},"source":["plt.rcParams['figure.figsize'] = [14, 3.5]\n","plt.subplots_adjust(wspace=0.2)\n","\n","plt.subplot(121)\n","# Plot training & validation accuracy values\n","plt.plot(history['acc'])\n","plt.plot(history['val_acc'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Val'])\n","\n","plt.subplot(122)\n","# Plot training loss values\n","plt.plot(history['loss'])\n","plt.plot(history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Val'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F2zhBIRWMSLz"},"source":["**EXPECTED OUTPUT**:\n","\n","<pre>You should see overfitting occured"]},{"cell_type":"markdown","metadata":{"id":"p-0TIyW8p1e5"},"source":["You should see that if we only use ordinary Artificial Neural Networks, overfitting occurs during training.\n","\n","You can improve this using more advanced architecture such as Convolutional Neural Network. \n","\n","You can also improve the model by adding more advanced optimization scheme such as adding Dropout Layer, Batch Normalization Layer, Regularizers, and so on.\n","\n","> For Dropout, see [Tensorflow documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) and [research paper](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) \n","\n","> For Batch Normalization, see [Tensorflow documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) and [research paper](http://proceedings.mlr.press/v37/ioffe15.pdf)"]},{"cell_type":"markdown","metadata":{"id":"FPKXANTwmaih"},"source":["---\n","## 8 - Evaluate Model\n","\n","Now let's test the model to the unseen dataset.\n","\n","First, convert testing dataset and its targets into tensor"]},{"cell_type":"code","metadata":{"id":"elV2XGeGnBRJ"},"source":["tf_X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n","tf_y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tKUzSXMwxr-7"},"source":["Then call the test_step function, and get the output tuple containing logits, loss, and accuracy\n","\n","we should get accuracy around `48%`"]},{"cell_type":"code","metadata":{"id":"JBtjSaU5nnq7"},"source":["test_logits, test_loss, test_accuracy = test_step(tf_X_test, tf_y_test)\n","\n","# get the predicted class\n","y_pred = tf.argmax(test_logits, axis=1, output_type=tf.int32)\n","\n","print('Completed testing on', tf_X_test.shape[0], 'examples...')\n","print('Loss: {:.3f}, Accuracy: {:.3%}'.format(test_loss, test_accuracy))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7udTUjE1MfwN"},"source":["**EXPECTED OUTPUT**:\n","\n","<pre>You should see testing accuracy around 48%"]},{"cell_type":"markdown","metadata":{"id":"jizSM5bzxYFV"},"source":["---\n","## 9 - View Result\n","Now to visualize some of the model's predictions:"]},{"cell_type":"code","metadata":{"id":"d2Vzno7PnyZb"},"source":["fig, ax = plt.subplots(2,10,figsize=(22,6))\n","fig.subplots_adjust(hspace=0.1, wspace=0.1)\n","label = y_test.ravel()\n","for j in range(0,2):\n","    for i in range(0, 10):\n","\n","        img_index = np.random.randint(0, 10000)\n","        ax[j,i].imshow(X_test_ori[img_index])\n","\n","        actual_label    = int(y_test[img_index])\n","        predicted_label = int(y_pred[img_index])\n","\n","        color = 'red'\n","        if actual_label == predicted_label:\n","            color = 'green'\n","\n","        ax[j,i].set_title(\"Actual: {} ({})\\n Predicted: {} ({})\".format(\n","            actual_label, class_names[actual_label], predicted_label, class_names[predicted_label]\n","            ), color=color)\n","        ax[j,i].axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aICA4RnfrAlb"},"source":["Run the cell above again to see another set of examples"]},{"cell_type":"markdown","metadata":{"id":"WWD1cqo7zgEM"},"source":["---\n","---\n","# [Part 5] Keras API Training Function"]},{"cell_type":"markdown","metadata":{"id":"UG6MM3yR76rE"},"source":["---\n","## 1 - One-Hot Matrix\n","\n","Up until now, we're using the `sparse categorical cross-entropy` loss since our targets are integers (index of the labels). Depending on your dataset, you might find dataset with one-hot encoded tagets.\n","\n","One-hot representations are usually good for categorical classes (multi-class problems) where no such ordinal relationship exists. In this case, a one-hot encoding can be applied to label representation as it has clear interpretation and its values are separated each is in different dimension.\n","\n","It is more intuitive if you implement the softmax loss from scratch. However, using one-hot representation may slow down the training when you have hundreds of classes to classify.\n","\n","For that, the first step that we have to do is convert the target into what is known as one-hot matrix. It change the target label into a sparse matrix with size of class number, with one in the index of the label and zeros in everywhere else. \n","\n","With Keras, we can use **to_categorical** functions from **tf.keras.utils** module. And when we're using one-hot representations as target, we can use `categorical cross-entropy` for the loss."]},{"cell_type":"markdown","metadata":{"id":"GtDQA9Yv8BuV"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","Change target vector **y_train**, **y_val**, and **y_test** each into a One-Hot Matrix using **to_categorical** method"]},{"cell_type":"code","metadata":{"id":"qpSpt2Tr76rH"},"source":["from tensorflow.keras.utils import to_categorical\n","\n","y_train_hot = to_categorical(y_train, 10)\n","y_val_hot   = ??\n","y_test_hot  = ??\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OMhv3sF18Buh"},"source":["Check your implementation"]},{"cell_type":"code","metadata":{"id":"H40YyfrG8Buj"},"source":["print('y_train_hot.shape =',y_train_hot.shape)\n","print('y_val_hot.shape   =',y_val_hot.shape)\n","print('y_test_hot.shape  =',y_test_hot.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"696lyg-L8Bur"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n"," y_train_hot.shape = (40000, 10)\n"," y_val_hot.shape   = (10000, 10)\n"," y_test_hot.shape  = (10000, 10)"]},{"cell_type":"markdown","metadata":{"id":"hw2Gwr4x76rR"},"source":["example of 10 first one-hot label from training data"]},{"cell_type":"code","metadata":{"id":"5cLe5HLi76rS"},"source":["print('  |     |  class:\\ni |  y  |  0 1 2 3 4 5 6 7 8 9\\n---------------------------------')\n","for i in range(10):\n","    print(i, '|', y_train[i], '|', y_train_hot[i,:].astype('int'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UvqtigwJ8lrH"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","  |   |  class:\n","i | y |  0 1 2 3 4 5 6 7 8 9\n","-------------------------------\n","0 | 6 | [0 0 0 0 0 0 1 0 0 0]\n","1 | 9 | [0 0 0 0 0 0 0 0 0 1]\n","2 | 9 | [0 0 0 0 0 0 0 0 0 1]\n","3 | 4 | [0 0 0 0 1 0 0 0 0 0]\n","4 | 1 | [0 1 0 0 0 0 0 0 0 0]\n","5 | 1 | [0 1 0 0 0 0 0 0 0 0]\n","6 | 2 | [0 0 1 0 0 0 0 0 0 0]\n","7 | 7 | [0 0 0 0 0 0 0 1 0 0]\n","8 | 8 | [0 0 0 0 0 0 0 0 1 0]\n","9 | 3 | [0 0 0 1 0 0 0 0 0 0]"]},{"cell_type":"markdown","metadata":{"id":"GykTPRsYT8Xd"},"source":["---\n","## 2 - Three-layer Neural Net\n","\n","Same as before, we define the classifier model of Three-layer Neural Net with the following architecture:\n","\n","<pre>\n","|              |              |                 |\n","| <font color='red'>dense</font> - <font color=''>relu</font> | <font color='red'>dense</font> - <font color=''>relu</font> | <font color='brown'>dense</font> - <font color=''>softmax</font> |\n","|              |              |                 |\n","|       1      |      2       |        3        |\n","</pre>\n","<br>\n","\n","\n","You can define the model using Sequential or Functional API. You can also experiment by trying to change the layer type, activation functions, and number of neurons. \n","\n","For this model, use `softmax` activation for the output layer."]},{"cell_type":"markdown","metadata":{"id":"jd2deUHh8vMx"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","Define your classification model. \n"]},{"cell_type":"code","metadata":{"id":"MxneSJ-A00bJ"},"source":["model = Sequential([\n","                             \n","    Flatten(input_shape=(32,32,3)),  \n","\n","    ??,   # add a dense layer with 256 neurons and relu activation\n","    ??,   # add a dense layer with 128 neurons and relu activation\n","    ??    # add a dense layer with 10 neurons and softmax activation\n","\n","], name='my_model')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d9xtgVaMUrfK"},"source":["Show the model summary"]},{"cell_type":"code","metadata":{"id":"8e9ozXZDLeMi"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L7A5vwNGLeM1"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_? (Flatten)          (None, 3072)              0         \n","_________________________________________________________________\n","dense_? (Dense)              (None, 256)               786688    \n","_________________________________________________________________\n","dense_? (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_? (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 820,874\n","Trainable params: 820,874\n","Non-trainable params: 0\n","_________________________________________________________________"]},{"cell_type":"markdown","metadata":{"id":"nYQkr87yM_6z"},"source":["let's also plot the model design"]},{"cell_type":"code","metadata":{"id":"7GzVDuUZLeM3"},"source":["plot_model(model, \n","           to_file=model.name+'.png', \n","           show_shapes=True, \n","           show_layer_names=False,\n","           rankdir='LR',\n","           dpi=70\n","          )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HGmnlYkELeNA"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src=\"https://i.ibb.co/tK9yMJY/3layernet.png\" width=\"80%\">"]},{"cell_type":"markdown","metadata":{"id":"ATlROUvI76rq"},"source":["---\n","## 3 - Compile Model\n","\n","When using the Keras API, to register loss functions and its optimization function, we use `.compile()` method. Conveniently, we can choose the loss, optimizer, and metrics using their string identifier."]},{"cell_type":"markdown","metadata":{"id":"h4rGAHDqNtH6"},"source":["#### <font color='red'>**EXERCISE:** </font>\n","compile your model using \n","* `'categorical_crossentropy'` loss, \n","* `'adam'` optimizer, and \n","* `['accuracy']` metrics\n","\n"]},{"cell_type":"code","metadata":{"id":"vU9pjwrN76rr"},"source":["# Compile model\n","model.??\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iaBCxATWVyMV"},"source":["To see the string identifier for loss functions, see [keras losses](https://keras.io/api/losses/) or [tf.keras losses](https://www.tensorflow.org/api_docs/python/tf/keras/losses)\n","\n","To see the string identifier for optimizers, see [keras optimizers](https://keras.io/api/optimizers/) or [tf.keras optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)"]},{"cell_type":"markdown","metadata":{"id":"j501RM3c76rw"},"source":["---\n","## 4 - Train Model\n","\n","Now we can train the model by calling the &nbsp; `.fit()` &nbsp; method.\n","\n","Run the training process for  20 epochs with batch size=128"]},{"cell_type":"code","metadata":{"id":"axpl5Za176rx"},"source":["num_epochs = 20\n","batch_size = 128\n","\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n","\n","history = model.fit(X_train, y_train_hot, \n","                    validation_data=(X_val, y_val_hot),\n","                    epochs=num_epochs, \n","                    batch_size=batch_size, \n","                    callbacks = [tensorboard_callback],\n","                    verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lBIe5ockO0vC"},"source":["**EXPECTED OUTPUT**:\n","\n","<pre>You should get similar result from before\n","The loss should start from ~1.7 and end around 0.5 with validation accuracy around 49%"]},{"cell_type":"markdown","metadata":{"id":"VmtqwUK_76r2"},"source":["you can further train the model simply by re-run the cell "]},{"cell_type":"markdown","metadata":{"id":"oMMVmvCu76r3"},"source":["---\n","## 5 - Visualize Training History\n","\n","Visualize the train-validation accuracy"]},{"cell_type":"code","metadata":{"id":"X94mNmsa76r4"},"source":["plt.rcParams['figure.figsize'] = [14, 3.5]\n","plt.subplots_adjust(wspace=0.2)\n","\n","plt.subplot(121)\n","# Plot training & validation accuracy values\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'])\n","\n","plt.subplot(122)\n","# Plot training & validation loss values\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p8J1alDQPEtM"},"source":["**EXPECTED OUTPUT**:\n","\n","<pre>You should see overfitting occured"]},{"cell_type":"markdown","metadata":{"id":"oVwhXzLieo-q"},"source":["We can also visualize the training history to Tensorboard"]},{"cell_type":"code","metadata":{"id":"vQYBrVlme09T"},"source":["%tensorboard --logdir logs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6qZuy8Vg76sB"},"source":["---\n","## 6 - Evaluate Model\n","Next, let's evaluate the accuracy of the models that have been trained\n","\n","we should get accuracy around `48%`"]},{"cell_type":"code","metadata":{"id":"N6kuoBNR76sB"},"source":["scores = model.evaluate(X_test, y_test_hot, verbose=1)\n","print(\"\\nModel Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vnCN6_Fp6E57"},"source":["---\n","## 7 - View Result\n","Now to visualize some of the model's predictions:"]},{"cell_type":"code","metadata":{"id":"OlalGMe16168"},"source":["y_pred = model.predict(X_test, verbose=0)\n","y_pred = np.argmax(y_pred, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x83E9GAi6E5_"},"source":["fig, ax = plt.subplots(2,10,figsize=(22,6))\n","fig.subplots_adjust(hspace=0.1, wspace=0.1)\n","\n","for j in range(0,2):\n","    for i in range(0, 10):\n","\n","        img_index = np.random.randint(0, 10000)\n","        ax[j,i].imshow(X_test_ori[img_index])\n","\n","        actual_label    = int(y_test[img_index])\n","        predicted_label = int(y_pred[img_index])\n","\n","        color = 'red'\n","        if actual_label == predicted_label:\n","            color = 'green'\n","\n","        ax[j,i].set_title(\"Actual: {} ({})\\n Predicted: {} ({})\".format(\n","            actual_label, class_names[actual_label], predicted_label, class_names[predicted_label]\n","            ), color=color)\n","        ax[j,i].axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0sAzqchYPRga"},"source":["Run the cell above again to see another set of examples"]},{"cell_type":"markdown","metadata":{"id":"tgo-d6OeBBBd"},"source":["---\n","## 8 - Save Model\n","\n","Now as an addition, we can save our model for later use by using `.save()` function. This will save both the architecture code and the weight matrices.\n","\n","The stored model is ready to use when loaded."]},{"cell_type":"code","metadata":{"id":"GukmHPbZvXja"},"source":["model.save('my_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k9SC6RTyPq8t"},"source":["Alternatively, you can opt to save just the weight matrices by using `.save_weights()` function. This way the saved file is smaller and more compact, but you need the exact matched model arcitecture to load it.\n","\n","This is typically used when you are deploying a system that already has an earlier version of the model embedded, but then you want to update the weights without actually changing the architecture. For example after you trained it further with new additional dataset to improve the accuracy."]},{"cell_type":"code","metadata":{"id":"PXNmkQdXvhV_"},"source":["model.save_weights('my_weights.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E-IRHHBt48r8"},"source":["---\n","---\n","# [Part 6] Keras Three-Layer ConvNet\n","\n","For this part, let's try to improve the classification performance by changing the model to a 3-layer Convolutional Neural Net\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8EAjJVOV62wH"},"source":["---\n","## 1 - Define Model\n","\n","Define a three-layer convnet with the same architecture from Part 1.\n","\n","You can use any model building style that fits to your taste\n","\n","A three-layer convolutional network with the following architecture:\n","\n","<pre>\n","|                       |                       |         |                 |\n","| <font color='red'>32 @5x5 Conv2D</font> - <font color=''>relu</font> | <font color='red'>16 @3x3 Conv2D</font> - <font color=''>relu</font> | Flatten | <font color='brown'>Dense</font> - <font color=''>softmax</font> |\n","|                       |                       |         |                 |\n","|            1          |           2           |         |        3        |\n","</pre>\n","<br>\n","\n","For the **Convolution Layer**, use the [**tensorflow.keras.layers.Conv2D**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)"]},{"cell_type":"markdown","metadata":{"id":"rzTxlipd6z4k"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","    define model:\n","    * 32 5x5 Conv2D layer with relu activation, padding valid, and input_shape=(32,32,3)\n","    * 16 3x3 Conv2D layer with relu activation and padding valid\n","    * Flatten layer\n","    * Dense layer with 10 neurons and softmax activation\n","\n"]},{"cell_type":"code","metadata":{"id":"Bp22uBi3yNsk"},"source":["from tensorflow.keras.layers import Conv2D\n","\n","myConv = Sequential([\n","    ??\n","    ??\n","    ??\n","    ??\n","])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7AoPsCVfRfav"},"source":["Show the model summary"]},{"cell_type":"code","metadata":{"id":"6ThyvOLULkrP"},"source":["myConv.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_uABzxgrLkra"},"source":["**Expected Output**:\n","<pre>\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_? (Conv2D)            (None, 28, 28, 32)        2432      \n","_________________________________________________________________\n","conv2d_? (Conv2D)            (None, 26, 26, 16)        4624      \n","_________________________________________________________________\n","flatten_? (Flatten)          (None, 10816)             0         \n","_________________________________________________________________\n","dense_? (Dense)              (None, 10)                108170    \n","=================================================================\n","Total params: 115,226\n","Trainable params: 115,226\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"LNxPBXxpRnSL"},"source":["let's also plot the model design"]},{"cell_type":"code","metadata":{"id":"LWGzrbj9Lkrc"},"source":["plot_model(myConv, \n","           to_file=model.name+'.png', \n","           show_shapes=True, \n","           show_layer_names=False,\n","           rankdir='LR',\n","           dpi=70\n","          )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yZgYy1NeRwbU"},"source":["**EXPECTED OUTPUT**:\n","\n","<img src=\"https://i.ibb.co/F8JWX3R/3layerconv.png\" width=\"90%\">"]},{"cell_type":"markdown","metadata":{"id":"aMgsfDzx86hd"},"source":["---\n","## 2 - Compile Model\n","\n","Here we have to compile the model by registering a loss function and its optimization function. You should know that `adam` optimizer is better and converge faster than straight `sgd`, <br>but for the sake of this example, here we use the `sgd` optimizer\n"]},{"cell_type":"code","metadata":{"id":"fas8HCS186ho"},"source":["# Compile model\n","myConv.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ceVXKQw--AX4"},"source":["---\n","## 3 - Model Checkpoint Callback\n","\n","When using Keras, we can add several callback functions to the &nbsp; `.fit()` &nbsp; training function. \n","\n","A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. \n","\n","One of the very useful callback functions is **ModelCheckpoint**.\n","\n","You know that when we train neural networks, training accuracy and validation accuracy should always increase with epoch iteration. But at some point, while training accuracy continues to increase, validation accuracy may go down. Which indicates that the network has **overfit** the data. \n","\n","Obviously, the model that we want to use is not the model at the end of training epoch, but the one just before the validation accuracy drops.\n","\n","We can use the **ModelCheckpoint** to periodically save the model only when validation accuracy is increased"]},{"cell_type":"code","metadata":{"id":"J7U1u2eOBB8u"},"source":["import os\n","os.mkdir('./model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LbdKCAjIAxkB"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","filepath = './model/my_model.h5'\n","\n","myCheckpoint = ModelCheckpoint(filepath, \n","                               monitor='val_accuracy',\n","                               save_best_only=True,\n","                              )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YYeyP2awCGz_"},"source":["---\n","## 4 - Early Stopping Callback\n","\n","Another useful callback function is **EarlyStopping**\n","\n","With this, we can monitor the training, and when the loss or accuracy is no longer improving for several epochs, we can terminate the training session and investigate what happened. \n","\n","After that, we can think of what we can do to improve training accuracy, then continue the training.\n","\n","For this example, we'll monitor the validation loss, and when the loss is not decreasing after 5 epochs, we terminate the training.\n","\n","Other callback functions can be seen at [tf.keras.callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks)\n"]},{"cell_type":"code","metadata":{"id":"xU_HHXL3DpmB"},"source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","myStopping = EarlyStopping(monitor='val_loss',\n","                          patience=5\n","                          )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U2JoUp-2In5T"},"source":["---\n","## 5 - Live Training Plot Callback\n","\n","For this part, let's add a custom callback function to perform live training plot between training and validation accuracy\n","\n","---\n","\n","<font color='red'>**NOTE**</font>: For some reason, as of June 2020, the tensorflow is removing some model parameter in 2.2.0 version. Which interferes with this callback example. So I kind of *quick-fixed* this so the callback just works. This will be further updated after there's further fix and clarification from Tensorflow\n","<br> see [Issues](https://github.com/tensorflow/tensorflow/issues/40515)"]},{"cell_type":"code","metadata":{"id":"o0ClR0iuIn5T"},"source":["from IPython.display import clear_output\n","\n","\n","def translate_metric(x):\n","    translations = {'acc': \"Accuracy\", 'loss': \"Log-loss (cost function)\"}\n","    if x in translations:\n","        return translations[x]\n","    else:\n","        return x\n","\n","class PlotLosses(tf.keras.callbacks.Callback):\n","    def __init__(self, figsize=None):\n","        super(PlotLosses, self).__init__()\n","        self.figsize = figsize\n","\n","    def on_train_begin(self, logs={}):\n","        \n","        #=======================================\n","        # quick-fix to solve missing param\n","        # print(self.params)\n","        self.params['metrics'] = ['loss']\n","        self.params['do_validation'] = ['true']\n","        #=======================================\n","\n","        self.base_metrics = [metric for metric in self.params['metrics'] if not metric.startswith('val_')]\n","        self.logs = []\n","        \n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        self.logs.append(logs)\n","\n","        clear_output(wait=True)\n","        plt.figure(figsize=self.figsize)\n","        \n","        for metric_id, metric in enumerate(self.base_metrics):\n","            plt.subplot(1, len(self.base_metrics), metric_id + 1)\n","            \n","            plt.plot(range(1, len(self.logs) + 1),\n","                     [log[metric] for log in self.logs],\n","                     label=\"training\")\n","            if self.params['do_validation']:\n","                plt.plot(range(1, len(self.logs) + 1),\n","                         [log['val_' + metric] for log in self.logs],\n","                         label=\"validation\")\n","            plt.title(translate_metric(metric))\n","            plt.xlabel('epoch')\n","            plt.legend(loc='center right')\n","        \n","        plt.tight_layout()\n","        plt.show();\n","        \n","myTrainPlot = PlotLosses(figsize=(10, 4))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0x4A8MFY86hz"},"source":["---\n","## 6 - Train Model\n","\n","Now we can train the model by calling the &nbsp; `fit` &nbsp; function\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DZGeEp2DOaV3"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","    Train a three-layer ConvNet for 30 epochs with batch size=100\n","    "]},{"cell_type":"code","metadata":{"id":"gLXVILtZ86h1"},"source":["num_epochs = 30\n","batch_size = 100\n","\n","history = myConv.fit(X_train, y_train_hot, \n","                     validation_data=(X_val, y_val_hot),\n","                     epochs=num_epochs, \n","                     batch_size=batch_size, \n","                     callbacks=[myTrainPlot, myCheckpoint, myStopping],\n","                     verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4sDZ6RCK86h6"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","the training should lasts in about 23 epochs before early stopping callback terminate the iteration,\n","the training loss should start around 1.8 and end around 0.7\n","while validation loss start around 1.6 then plateau around 1.1\n"]},{"cell_type":"markdown","metadata":{"id":"7hHvxzOF9jlq"},"source":["---\n","## 7 - Evaluate Model\n","Next, let's evaluate the accuracy of the models that have been trained\n","\n","First, load the best model from checkpoint"]},{"cell_type":"code","metadata":{"id":"L26NQQx8NKLg"},"source":["from tensorflow.keras.models import load_model\n","\n","myModel = load_model('./model/my_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"92FsWJQsNZzn"},"source":["Evaluate the model using &nbsp; `X_test` &nbsp; and &nbsp; `y_test_hot`"]},{"cell_type":"code","metadata":{"id":"0EPBwyyB9jl1"},"source":["scores = myModel.evaluate(X_test, y_test_hot, verbose=1)\n","\n","print(\"\\nModel Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"coc1tJzANl6e"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","you should get around 62% of testing accuracy"]},{"cell_type":"markdown","metadata":{"id":"AzjAfyGhVkPK"},"source":["---\n","## 8 - Test Model on New Image\n","\n","For this part, you have to test your model on new image\n","\n","First of all, search for five images on the Internet, then list the URLs to the code below.\n","\n","The five images must belong to the 10 CIFAR-10 classes that the model recognizes."]},{"cell_type":"markdown","metadata":{"id":"pnU03-WEVkPW"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","    define five image urls\n","    one image has been given for an example, you can change it"]},{"cell_type":"code","metadata":{"id":"CkFlqQoIF0YD"},"source":["!wget -q -O 'data_test_0.jpg' 'https://ichef.bbci.co.uk/news/912/cpsprodpb/160B4/production/_103229209_horsea.png'\n","!wget -q -O 'data_test_1.jpg' '??'\n","!wget -q -O 'data_test_2.jpg' '??'\n","!wget -q -O 'data_test_3.jpg' '??'\n","!wget -q -O 'data_test_4.jpg' '??'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j5wH83YDXj0a"},"source":["Run and Recognize the images"]},{"cell_type":"code","metadata":{"id":"OBaJnd2gF6X_"},"source":["import cv2 as cv\n","from PIL import Image\n","class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","\n","for i in range(5):\n","    # load and open the image\n","    new_img = Image.open('data_test_'+str(i)+'.jpg')\n","    new_img = np.array(new_img)\n","\n","    # resize into (32,32,3)\n","    new_img2 = cv.resize(new_img, (32,32), interpolation=cv.INTER_AREA)\n","    plt.imshow(new_img2)\n","    plt.axis('off')\n","    plt.show()\n","\n","    # preprocess the image using X_train mean and std\n","    new_img2 = (new_img2 - mean_pixel) / std_pixel\n","\n","    # predict the class\n","    pred = myModel.predict(new_img2)\n","    class_id = np.argmax(pred)\n","    print('predicted id   :',class_id)\n","    print('predicted class:', class_names[class_id])\n","    print('--------------------------------\\n\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5JECsUGsN94_"},"source":["---\n","---\n","# [Part 7] CIFAR-10 Open-ended Challenge\n","\n","In this section you can experiment with whatever ConvNet architecture you'd like on CIFAR-10.\n","\n","You should experiment with **architectures**, **hyperparameters**, **loss functions**, **regularization**, or anything else you can think of to train a model \n","\n","You should achieve <font color='blue' size='5'><b>at least 75% accuracy</b></font> on the **validation** set <font color='red' size='4'><b>within 10-20 epochs</b></font>. \n"]},{"cell_type":"markdown","metadata":{"id":"qbYFGiXWOPX4"},"source":["---\n","## Some things you can try:\n","- **Filter size**: Above we used 5x5 and 3x3; is this optimal?\n","\n","- **Number of filters**: Above we used 16 and 32 filters. Would more or fewer do better?\n","\n","- **Pooling**: We didn't use any pooling above. Would this improve the model?\n","\n","- **Normalization**: Would your model be improved with batch normalization, layer normalization, group normalization, or some other normalization strategy?\n","\n","- **Network architecture**: The ConvNet above has only three layers of trainable parameters. Would a deeper model do better?\n","\n","- **Global average pooling**: Instead of flattening after the final convolutional layer, would global average pooling do better? This strategy is used for example in Google's Inception network and in Residual Networks.\n","\n","- **Regularization**: Would some kind of regularization improve performance? Maybe weight decay or dropout?\n","\n","- **Optimization**: You've seen various advanced optimization function. Maybe changing the optimization using Adam or RMSProp will increase the accuracy?\n","\n","<br><center>\n","<font color='red' size='4'><b>--- You must design YOUR OWN Architecture --- <br>\n","--- And train it from scratch --- </b></font>"]},{"cell_type":"markdown","metadata":{"id":"0eYZkoAQO-S2"},"source":["---\n","## Tips for training\n","For each network architecture that you try, you should tune the learning rate and other hyperparameters. \n","\n","When doing this there are a couple important things to keep in mind:\n","\n","- If the parameters are working well, you should see improvement within a few hundred iterations\n","\n","- Remember the coarse-to-fine approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.\n","\n","- Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n","\n","- You should use the validation set for hyperparameter search, and save your test set for evaluating your architecture on the best parameters as selected by the validation set."]},{"cell_type":"markdown","metadata":{"id":"CM0a9PvRPhqa"},"source":["<center>\n","<h2><font color='blue'>--- Go Wild, Have Fun, and Happy Training!  --- </font></h2>"]},{"cell_type":"markdown","metadata":{"id":"AW4Ees_zVLBJ"},"source":["---\n","## 1 - Define Model"]},{"cell_type":"markdown","metadata":{"id":"rq_8xfRAQIKO"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","    Design your Convolutional Neural Network Architecture\n","\n","    "]},{"cell_type":"code","metadata":{"id":"euoKYCFcQNOf"},"source":["from tensorflow.keras.layers import *\n","\n","myModel = ??\n","\n","\n","myModel.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jJ9XUD5iVP26"},"source":["---\n","## 2 - Train Model"]},{"cell_type":"markdown","metadata":{"id":"OwRct_FtVP3A"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","    Compile the model\n","    Train the model\n","    "]},{"cell_type":"code","metadata":{"id":"lQCmkzyXSAeg"},"source":["# Compile model\n","myModel.compile(??)\n","\n","num_epochs = ??\n","batch_size = ??\n","\n","history = myModel.fit(??)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"czp7YYjSsGt0"},"source":["# Save model if needed\n","myModel.save(??)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y8bwtzimVUfs"},"source":["---\n","## 3 - Evaluate Model"]},{"cell_type":"markdown","metadata":{"id":"SOzUKWj5Q_La"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","    evaluate your model on test set\n","    "]},{"cell_type":"code","metadata":{"id":"QZMNJP7hQ-G5"},"source":["myModel = load_model(??)\n","\n","train_scores = myModel.evaluate(X_train, y_train_hot, verbose=1)\n","val_scores   = myModel.evaluate(X_val, y_val_hot, verbose=1)\n","test_scores  = myModel.evaluate(X_test, y_test_hot, verbose=1)\n","\n","print(\"Training Accuracy  : %.2f%%\" % (train_scores[1]*100))\n","print(\"Validation Accuracy: %.2f%%\" % (val_scores[1]*100))\n","print(\"Testing Accuracy  :  %.2f%%\" % (test_scores[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Q2Lgw7gSwqD"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","try to get above 80% of accuracy for train, val, and test set"]},{"cell_type":"markdown","metadata":{"id":"V7SIMIWzYIq9"},"source":["---\n","## 4 - Test Model on New Image\n","\n","Test your model on new image"]},{"cell_type":"markdown","metadata":{"id":"fkTntuHaYIrI"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","\n","    define five image urls\n","    one image has been given for an example, you can change it"]},{"cell_type":"code","metadata":{"id":"bcYaoCy0YIrP"},"source":["!wget -q -O 'data_test_0.jpg' 'https://ichef.bbci.co.uk/news/912/cpsprodpb/160B4/production/_103229209_horsea.png'\n","!wget -q -O 'data_test_1.jpg' '??'\n","!wget -q -O 'data_test_2.jpg' '??'\n","!wget -q -O 'data_test_3.jpg' '??'\n","!wget -q -O 'data_test_4.jpg' '??'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DJrPxToeYIrb"},"source":["Run and Recognize the images"]},{"cell_type":"code","metadata":{"id":"0pYhcYJeYIrd"},"source":["import cv2 as cv\n","from PIL import Image\n","class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","\n","for i in range(5):\n","    # load and open the image\n","    new_img = Image.open('data_test_'+str(i)+'.jpg')\n","    new_img = np.array(new_img)\n","\n","    # resize into (32,32,3)\n","    new_img2 = cv.resize(new_img, (32,32), interpolation=cv.INTER_AREA)\n","    plt.imshow(new_img2)\n","    plt.axis('off')\n","    plt.show()\n","\n","    # preprocess the image using X_train mean and std\n","    new_img2 = (new_img2 - mean_pixel) / std_pixel\n","\n","    # predict the class\n","    pred = myModel.predict(new_img2)\n","    class_id = np.argmax(pred)\n","    print('predicted id   :',class_id)\n","    print('predicted class:', class_names[class_id])\n","    print('--------------------------------\\n\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aQqQ_gcO92ub"},"source":["\n","---\n","\n","# Congratulation, You've Completed Exercise 4\n","\n","<p>Copyright &copy;  <a href=https://www.linkedin.com/in/andityaarifianto/>2020 - ADF</a> </p>"]},{"cell_type":"markdown","metadata":{"id":"7_Hkr9kg9Do-"},"source":["![footer](https://i.ibb.co/yX0jfMS/footer2020.png)"]}]}