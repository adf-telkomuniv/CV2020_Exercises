{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CV2020 - 09 - Keras Model.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"f_ChrQTZyAZU"},"source":["![title](https://i.ibb.co/f2W87Fg/logo2020.png)\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"oUkeuLWzoHoN"},"source":["<table  class=\"tfo-notebook-buttons\" align=\"left\"><tr><td>\n","    \n","<a href=\"https://colab.research.google.com/github/adf-telkomuniv/CV2020_Exercises/blob/main/CV2020 - 09 - Keras Model.ipynb\" source=\"blank\" ><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>\n","</td><td>\n","<a href=\"https://github.com/adf-telkomuniv/CV2020_Exercises/blob/main/CV2020 - 09 - Keras Model.ipynb\" source=\"blank\" ><img src=\"https://i.ibb.co/6NxqGSF/pinpng-com-github-logo-png-small.png\"></a>\n","    \n","</td></tr></table>"]},{"cell_type":"markdown","metadata":{"id":"ZnlKAepF9JBf"},"source":["\n","\n","# Task 09 - Keras Model\n","\n","\n","In this assignment you will practice in using and freezing the available pretrained model in Keras and using it for Transfer Learning later\n","\n","The goals of this assignment are as follows:\n","* load empty VGG model\n","* load pretrained VGG model\n","* modifying VGG architectures\n","* freezing VGG layers"]},{"cell_type":"markdown","metadata":{"id":"SF71bN55cZzi"},"source":["Write down your Name and Student ID"]},{"cell_type":"code","metadata":{"id":"S5yg44U8cZzk"},"source":["## --- start your code here ----\n","\n","NIM = ??\n","Nama = ??\n","\n","## --- end your code here ----"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6VAE_sE-Bgk1"},"source":["---\n","---\n","#[Part 0] Import Libraries and Load Data"]},{"cell_type":"markdown","metadata":{"id":"DvPSXMEIaFm1"},"source":["---\n","## 1 - Import Libraries\n","Import required libraries"]},{"cell_type":"code","metadata":{"id":"4KOPbytzogWG"},"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import Model\n","from tensorflow.keras.models import Sequential\n","\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.layers import GlobalAveragePooling2D\n","\n","%matplotlib inline\n","np.set_printoptions(precision=7)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9-dF2DZMZs8W"},"source":["---\n","## 2 - Helper Functions\n","\n","Helper function to display the model's parameter\n","\n","similar to &nbsp;`model.summary()` method"]},{"cell_type":"code","metadata":{"id":"97UcRtaaZvKu"},"source":["def print_params(model):\n","  \n","  def count_params(weights):\n","      \"\"\"Count the total number of scalars composing the weights.\n","      # Arguments\n","          weights: An iterable containing the weights on which to compute params\n","      # Returns\n","          The total number of scalars composing the weights\n","      \"\"\"\n","      weight_ids = set()\n","      total = 0\n","      for w in weights:\n","          if id(w) not in weight_ids:\n","              weight_ids.add(id(w))\n","              total += int(K.count_params(w))\n","      return total\n","  \n","  trainable_count = count_params(model.trainable_weights)\n","  non_trainable_count = count_params(model.non_trainable_weights)\n","\n","  print('Total params: {:,}'.format(trainable_count + non_trainable_count))\n","  print('Trainable params: {:,}'.format(trainable_count))\n","  print('Non-trainable params: {:,}'.format(non_trainable_count))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehyWu_xFCBpK"},"source":["---\n","---\n","# [Part 1] Using VGG16 model from Keras\n","\n","Here we will demonstrate various ways to use the VGG model from Keras\n","\n","The use of the model will be similar for other models provided by Keras"]},{"cell_type":"markdown","metadata":{"id":"X2_s8Xyf3S3h"},"source":["---\n","## 0 - Import model\n","\n","First, import the &nbsp;**`keras.application`**&nbsp; module to use the predefined model\n","\n","The format is similar for other models:\n","    \n","``` python\n","    from tensorflow.keras.application.model_name import ModelName\n","```\n","\n","here, we'll use &nbsp;**`vgg16`**&nbsp;"]},{"cell_type":"code","metadata":{"id":"itx5V0pmve0_"},"source":["from tensorflow.keras.applications.vgg16 import VGG16"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NZiscLqs3YL7"},"source":["---\n","### Loading VGG Model Formats"]},{"cell_type":"markdown","metadata":{"id":"jKUX-Hpati1l"},"source":["The basic function for using the VGG16 architecture that has been defined from the Keras library is\n","\n","```python\n","    model = VGG16( weights=??, include_top=??, pooling_name=??, input_shape=(??) )\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nG8zJ9bYwdg4"},"source":["\n","There are several arguments we can enter when instantiating a model object\n","\n","<br>\n","\n","<table width=80%>\n","  <tr><td width=35%><font size=3><pre>weights = None</pre></font></td><td><font size=3> instantiates VGG16 with random weights</font></td></tr>\n","  <tr><td><font size=3><pre>weights = 'imagenet'</pre></font></td><td><font size=3>(default) - instantiates VGG16 with pre-trained weight <br>from ImageNet dataset</font></td></tr>\n","\n","  <tr><td width=35%><font size=3><pre>include_top = True</pre></font></td><td><font size=3>(default) - fully instantiates VGG16 <br>from the Convolution layer to the FC layer</font> </td></tr>\n","  <tr><td><font size=3><pre>include_top = False</pre></font></td><td><font size=3>instantiates VGG16 only the Convolution layer, <br>without the last 3 FC layers</font></td></tr>\n","</table>\n","\n","<br>\n","<br>\n","\n","\n","These arguments only applicable if &nbsp;&nbsp;<font color='red'>**`include_top = False`**</font>\n","<table width=80%>\n","  <tr><td width=35%><font size=3><pre>input_shape = ( ?, ?, ? )</pre></font></td><td width=2*><font size=3>instantiates VGG16 with a custom input size</font></td></tr>\n","  <tr><td><font size=3><pre>pooling_name = 'avg'\n","pooling_name = 'max'\n","pooling_name = None</pre></font></td><td><font size=3> instantiates VGG16 <br>with <b>Global Pooling Layer</b> output</font></td></tr>\n","</table>\n","<br>\n","<br>\n","\n","This argument only applicable if&nbsp;&nbsp; <font color='red'>**`include_top = True`**</font>&nbsp;&nbsp; and&nbsp;&nbsp; <font color='red'>**`weights = None`**</font>\n","<table width=80%>\n","  <tr><td width=35%><font size=3><pre>classes = ?</pre></font></td><td><font size=3> instantiates whole VGG16 with custom class output</font></td></tr>\n","</table>\n","<br>\n","<br>\n"]},{"cell_type":"markdown","metadata":{"id":"eYLVtDV_HXT9"},"source":["---\n","## 1 - Complete, Random\n","Load **full VGG16** with **random initialized** weights\n","<pre><b>* 16 layers (<font color='brown'>13 Conv</font> + <font color='green'>3 FC</font>)<br>* Random Initialized<br><br>* Input  ( None, 224, 224, 3 )<br>* Output ( None, 1000, )"]},{"cell_type":"markdown","metadata":{"id":"PKTnzE8cNdDJ"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>call VGG16() function with <b>weights=None</b> alone\n","or with <b>weights=None</b> and <b>include_top=True</b>"]},{"cell_type":"code","metadata":{"id":"xP8doh3BPQFM"},"source":["model = ??\n","\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ozGzjnABcZ0u"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n"," input_? (InputLayer)         [(None, 224, 224, 3)]     0         \n"," ...\n"," predictions (Dense)          (None, 1000)              4097000   \n"," =================================================================\n"," Total params: 138,357,544\n"," Trainable params: 138,357,544\n"," Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"U0tMDxylDfSe"},"source":["---\n","### Test New Image\n","\n","The model is initialized with random weights, so if we try to test and predict an image, it'll classify the image into random class\n","\n","Let's try it\n","\n","We'll use the built in function to load and process the image, as well decode the prediction to retrive the predicted class"]},{"cell_type":"code","metadata":{"id":"Up-N_yCACSrh"},"source":["from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iZoJbBlxlmjh"},"source":["Let's download an image, you can change it url"]},{"cell_type":"code","metadata":{"id":"sd9yVtaADfSt"},"source":["!wget -q -O 'new_image.jpg' 'https://i.pinimg.com/736x/95/d6/5c/95d65c7de6ddcad403aaf57c69ed7cd5.jpg'\n","\n","img = image.load_img('new_image.jpg', target_size=(224, 224))\n","plt.imshow(img)\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TmRbg1OklrGi"},"source":["next we convert the image into numpy array, then preprocess the input (mean centering from vgg16)"]},{"cell_type":"code","metadata":{"id":"rKZMvgUMDfS0"},"source":["x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3sIYlIf-lzlQ"},"source":["lastly, we predict the image and show the top three predictions\n","\n","you'll see that the prediction is wrong"]},{"cell_type":"code","metadata":{"id":"FFxQTHBIDfS6"},"source":["preds = model.predict(x)\n","\n","# decode the results into a list of tuples (class, description, probability)\n","# (one such list for each sample in the batch)\n","print('Predicted:', decode_predictions(preds, top=3)[0])\n","print('Correct Answer: Malamute')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gmZumPUPPle2"},"source":["---\n","## 2 - Complete, Random, Custom Output\n","Load **Full VGG16** with **random initialized** weights and output **10 class**\n","\n","<pre><b>* 16 layers (<font color='brown'>13 Conv</font> + <font color='green'>3 FC</font>)<br>* Random Initialized<br><br>* Input  ( None, 224, 224, 3 )<br>* <font color='blue'>Output ( None, 10, )</font>"]},{"cell_type":"markdown","metadata":{"id":"UDezjr6T6kKM"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>call VGG16() function with <b>include_top=True</b>, <b>weights=None</b>, and <b>classes=10</b>"]},{"cell_type":"code","metadata":{"id":"POvCYCc-PQCM"},"source":["model = ??\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ghKf1NR6ywC"},"source":["**EXPECTED OUTPUT**:\n","<pre> input_? (InputLayer)         [(None, 224, 224, 3)]     0         \n"," ...\n"," predictions (Dense)          (None, 10)                40970     \n"," =================================================================\n"," Total params: 134,301,514\n"," Trainable params: 134,301,514\n"," Non-trainable params: 0\n"]},{"cell_type":"markdown","metadata":{"id":"Hg3O6T7zSAwu"},"source":["---\n","## 3 - No Top, Random\n","\n","Load VGG16 **without FC** layers with **random initialized** weights\n","\n","<pre><b><font color='blue'>13 Conv layers</font>\n","Random Initialized\n","\n","<font color='red'>Input  ( None, None, None, 3 )</font>        (<i>input size will have to be defined before using</i>)\n","<font color='red'>Output ( None, None, None, 512 )</font>      (<i>according to input</i>)"]},{"cell_type":"markdown","metadata":{"id":"k20N9BKz7Hcy"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>call VGG16() function with <b>include_top=False</b> and <b>weights=None</b>"]},{"cell_type":"code","metadata":{"id":"pR-sqBvzSWbw"},"source":["model = ??\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_FRo0TJ37PX9"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","input_? (InputLayer)         [(None, None, None, 3)]   0         \n","...\n","block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n"]},{"cell_type":"markdown","metadata":{"id":"RTo4fPGCSbc3"},"source":["---\n","## 4 - No Top, Random, Custom Input\n","Load VGG16 **without FC** layers with **random initialized** weights and **custom input** size\n","<pre><b><font color='blue'>13 Conv layers</font>\n","Random Initialized\n","\n","<font color='blue'>Input  ( None, 32, 32,   3 )</font> \n","<font color='red'>Output ( None,  1,  1, 512 )</font>      (<i>according to input</i>)"]},{"cell_type":"markdown","metadata":{"id":"VwsaR2h27b1I"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>call VGG16() function with <b>include_top=False</b>,<b> weights=None</b>, and<b> input_shape=(32,32,3)</b>"]},{"cell_type":"code","metadata":{"id":"qWN12dEjSbc5"},"source":["model = ??\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cu-FHpD07gkC"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","input_? (InputLayer)         [(None, 32, 32, 3)]       0         \n","...\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"AtXU2pwwRIN0"},"source":["---\n","## 5 - Complete, ImageNet\n","Load **full VGG16** with **pretrained weights** from ImageNet\n","<pre><b>16 layers (13 Conv + 3 FC)\n","<font color='blue'>ImageNet Pretrained</font>\n","\n","Input  ( None,  224, 224, 3)\n","Output ( None, 1000, )"]},{"cell_type":"markdown","metadata":{"id":"qYX50SOT7dzo"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>call VGG16() function with <b>include_top=True</b> and<b> weights='imagenet'</b>"]},{"cell_type":"code","metadata":{"id":"oDWQ5-13RGGc"},"source":["# model size ~530MB\n","model = ??\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kWpREQRp7l0s"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Downloading data from ...\n","553467904/553467096 [==============================] \n","\n","input_? (InputLayer)         [(None, 224, 224, 3)]     0         \n","...\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"yi3WZNU5CL6_"},"source":["---\n","### Test New Image\n","\n","the current model is initialized using vgg weights that have been trained in ImageNet reaching $94\\%$ top-5 accuracy\n","\n","now if we try to test and predict an image, it should produce the correct class (or at least close to it)"]},{"cell_type":"code","metadata":{"id":"Ht9epPnrCGKK"},"source":["!wget -q -O 'new_image.jpg' 'https://i.pinimg.com/736x/95/d6/5c/95d65c7de6ddcad403aaf57c69ed7cd5.jpg'\n","\n","img = image.load_img('new_image.jpg', target_size=(224, 224))\n","plt.imshow(img)\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z4VcnA0gCun3"},"source":["x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cx0rgOSLC26P"},"source":["preds = model.predict(x)\n","\n","# decode the results into a list of tuples (class, description, probability)\n","# (one such list for each sample in the batch)\n","print('Predicted:', decode_predictions(preds, top=3)[0])\n","print('Correct Answer: Malamute')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tCANRSs6DLGr"},"source":["---\n","### Test Another Image\n","\n","Let's try another image that is really close to the previous image"]},{"cell_type":"code","metadata":{"id":"A8tDibtjDHuV"},"source":["!wget -q -O 'new_image.jpg' 'https://cdn.shopify.com/s/files/1/0994/0236/files/siberian-husky_4217efb5-9130-4bdc-aa80-b274821bd05d_large.jpg?v=1518819764'\n","\n","img = image.load_img('new_image.jpg', target_size=(224, 224))\n","plt.imshow(img)\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m7OEwk4WDHum"},"source":["x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UmZjUeosDHuu"},"source":["preds = model.predict(x)\n","\n","# decode the results into a list of tuples (class, description, probability)\n","# (one such list for each sample in the batch)\n","print('Predicted:', decode_predictions(preds, top=3)[0])\n","print('Correct Answer: Siberian Husky')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Md_R0NxHTmuW"},"source":["---\n","## 6 - No Top, ImageNet\n","Load VGG16 **without FC** layers with **pretrained weights** from ImageNet\n","\n","<pre><b><font color='blue'>13 Conv layers</font>\n","<font color='blue'>ImageNet Pretrained</font>\n","\n","<font color='red'>Input  ( None, None, None, 3 )</font>        (<i>input size will have to be defined before using</i>)\n","<font color='red'>Output ( None, None, None, 512 )</font>      (<i>according to input</i>)"]},{"cell_type":"markdown","metadata":{"id":"8Pj1AlxT7eET"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>call VGG16() function with <b>include_top=False</b> and<b> weights='imagenet'</b>"]},{"cell_type":"code","metadata":{"id":"GsS53LW2Tmue"},"source":["# model size ~57MB\n","model = ??\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SyPR5UMD7lcD"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Downloading data from ...\n","58892288/58889256 [==============================]\n","\n","input_? (InputLayer)         [(None, None, None, 3)]   0         \n","...\n","block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n"]},{"cell_type":"markdown","metadata":{"id":"fdgMw3eHRzr-"},"source":["---\n","## 7 - No Top, ImageNet, Custom Input\n","Load VGG16 **without FC** layers with **pretrained weights** from ImageNet and **custom input** size\n","<pre><b><font color='blue'>13 Conv layers</font>\n","<font color='blue'>ImageNet Pretrained</font>\n","\n","<font color='blue'>Input  ( None, 32, 32,   3 )</font> \n","<font color='red'>Output ( None,  1,  1, 512 )</font>      (<i>according to input</i>)"]},{"cell_type":"markdown","metadata":{"id":"Ag_hYKsA7ed_"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>call VGG16() function with <b>include_top=False</b>,<b> weights='imagenet'</b>, and<b> input_shape=(32, 32, 3)</b> "]},{"cell_type":"code","metadata":{"id":"JQa4dDgsR0pE"},"source":["model = ??\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AGxJSKLd7kwL"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","input_?  (InputLayer)        [(None, 32, 32, 3)]       0         \n","...\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"Dm4TCFL8bFOx"},"source":["---\n","## 8 - No Top, ImageNet, Global Pooling\n","Load VGG16 **without FC** layers with **pretrained weights** from ImageNet and add **Global Average Pooling** to the top\n","<pre><b><font color='blue'>13 Conv layers + Global Avg Pooling</font>\n","<font color='blue'>ImageNet Pretrained</font>\n","\n","<font color='red'>Input  ( None, None, None, 3 )</font>     (<i>input size will have to be defined before using</i>)\n","<font color='blue'>Output ( None, 512 )</font>"]},{"cell_type":"markdown","metadata":{"id":"C_QJ0R137etT"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>call VGG16() function with <b>include_top=False</b>,<b> weights='imagenet'</b>, and<b> pooling='avg'</b> "]},{"cell_type":"code","metadata":{"id":"RUmNamdIR0mu"},"source":["model = ??\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tg2pwXrH7kGg"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","input_?  (InputLayer)        [(None, None, None, 3)]   0         \n","...\n","global_average_pooling2d (Gl (None, 512)               0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"gaRSS3QdbWoX"},"source":["---\n","## 9 - No Top, ImageNet, Global Pooling, Custom Input\n","Load VGG16 **without FC** layers with **pretrained weights** from ImageNet, **custom input** size and add **Global Average Pooling** to the top\n","<pre><b><font color='blue'>13 Conv layers + Global Avg Pooling</font>\n","<font color='blue'>ImageNet Pretrained</font>\n","\n","<font color='blue'>Input  ( None, 32, 32, 3 )</font> \n","<font color='blue'>Output ( None, 512 )</font> "]},{"cell_type":"markdown","metadata":{"id":"VavHqPon7fBx"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>call VGG16() function with <b>include_top=False</b>,<b> weights='imagenet'</b>,<b> input_shape=(32, 32, 3)</b>, and<b> pooling='avg'</b>"]},{"cell_type":"code","metadata":{"id":"9zQQJL__R0jl"},"source":["model = ??\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PF98hbMQ7kU_"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","input_?  (InputLayer)        [(None, 32, 32, 3)]       0         \n","...\n","global_average_pooling2d_? ( (None, 512)               0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"O_qjy3jQ_Y92"},"source":["---\n","---\n","# [Part 2] Modifying Full VGG16's Head\n","Here we will demonstrate various ways to modify the classification head from VGG16 architecture\n","\n","The modification procedures will be similar for other models provided by Keras\n","\n","\n","The model inside Keras can be built and modified in two forms:   &nbsp;&nbsp;`Sequential` &nbsp;&nbsp;and&nbsp;&nbsp;` Functional`\n","<br>\n","* For the &nbsp;&nbsp;`Sequential` &nbsp;&nbsp;model, we can immediately delete the beginning or end of the layer by calling the&nbsp;&nbsp;` pop(id)`&nbsp;&nbsp;method.\n","<br>\n","* For the &nbsp;&nbsp;`Functional`&nbsp;&nbsp; model, modifying inputs and adding layers at the beginning or end can use the&nbsp;&nbsp;` Functional API`&nbsp;&nbsp;format. \n"]},{"cell_type":"markdown","metadata":{"id":"FTZ8LE5TdAej"},"source":["---\n","## 1 - Load Full VGG16\n","\n","First, let's load the full VGG16 model\n","\n"]},{"cell_type":"code","metadata":{"id":"w33VAB_sa86I"},"source":["model = VGG16(include_top=True, weights='imagenet')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JSUC8mFNjF7m"},"source":["---\n","## 2 - List Layer Names\n","To see the entire name of the model, we can see by calling layer.name"]},{"cell_type":"code","metadata":{"id":"YGM6O7Hja83U"},"source":["for i, layer in enumerate(model.layers):\n","    print(i, layer.name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vC2rBQBNpXu2"},"source":["---\n","## 3 - Using Sequential Model\n","\n","First, let's see how to change the classification head using Sequential Model"]},{"cell_type":"markdown","metadata":{"id":"n61bPrRlpdgl"},"source":["---\n","### a. Prepare new Sequential Model\n","\n","To modify the architecture, first we create a new empty model\n","\n","we name the model &nbsp; `'myModel_full_1'`"]},{"cell_type":"code","metadata":{"id":"5HF2gwI52dMk"},"source":["myModel_F1 = Sequential(name='myModel_full_1')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"awOkGsVq2X0e"},"source":["---\n","### b. Add Full VGG16 into Sequential Model\n","\n","Now we copy and add all layers from vgg architecture into our model"]},{"cell_type":"code","metadata":{"id":"CyQImPfUpgdG"},"source":["for layer in model.layers:\n","  myModel_F1.add(layer)\n","  \n","myModel_F1.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DhkC0UfVqH8V"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Model: \"myModel_full_1\"\n","\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","...\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"odA84uMfqVu5"},"source":["you can see that the model is exact copy of vgg16\n","\n","(the input layer is not shown)"]},{"cell_type":"code","metadata":{"id":"nFdPtn0Epqy-"},"source":["for i, layer in enumerate(myModel_F1.layers):\n","    print(i, layer.name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1fjoduxYFGVk"},"source":["---\n","### c. Test New Image\n","\n","Just to make sure, let's test it"]},{"cell_type":"code","metadata":{"id":"3yWyQyQBFDAf"},"source":["!wget -q -O 'new_image.jpg' 'https://i.pinimg.com/736x/95/d6/5c/95d65c7de6ddcad403aaf57c69ed7cd5.jpg'\n","\n","img = image.load_img('new_image.jpg', target_size=(224, 224))\n","plt.imshow(img)\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1tmXqFjpFDAu"},"source":["x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mk1lC0tnFDA0"},"source":["preds = myModel_F1.predict(x)\n","\n","# decode the results into a list of tuples (class, description, probability)\n","# (one such list for each sample in the batch)\n","print('Predicted:', decode_predictions(preds, top=3)[0])\n","print('Correct Answer: Malamute')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DvgmehyqjzZo"},"source":["---\n","### d. Remove Top Layers\n","To delete the top layers, we can use the &nbsp;`pop()`&nbsp; function\n","\n","for example, to get the same results as we instantiating the VGG16 model with the &nbsp;`include_top = False`&nbsp; argument, we must remove the **top 4 layers**&nbsp;\n","(`flatten, fc1, fc2 and prediction`)\n","\n"]},{"cell_type":"code","metadata":{"id":"I_AyzR5gjRVu"},"source":["x = myModel_F1.pop()\n","x = myModel_F1.pop()\n","x = myModel_F1.pop()\n","x = myModel_F1.pop()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MsRYQx69D2k-"},"source":["Now let's list the remaining layers"]},{"cell_type":"code","metadata":{"id":"MSfSisdPD2R6"},"source":["for i, layer in enumerate(myModel_F1.layers):\n","    print(i, layer.name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xp0RoDlp3OtT"},"source":["---\n","### e. Add new Classifier Head\n","\n","Recent popular architecture always use Global Average Pooling after the last conv/pool layer, so let's do that\n","\n","Add a **Global Average Pool** layer and a couple of **Dense** layers with **10 class** output classification\n","\n","You can add naming to the layer as shown in the prediction layer"]},{"cell_type":"code","metadata":{"id":"d5QvJH7c3U_C"},"source":["myModel_F1.add(GlobalAveragePooling2D())\n","myModel_F1.add(Dense(1024, activation='relu'))\n","myModel_F1.add(Dense(10, activation='softmax', name='prediction_full_1'))\n","\n","myModel_F1.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6AAdmwdlrxa6"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Model: \"myModel_full_1\"\n","\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","...\n","\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","global_average_pooling2d_? ( (None, 512)               0         \n","dense (Dense)                (None, 1024)              525312    \n","prediction_full_1 (Dense)    (None, 10)                10250     \n","=================================================================\n","Total params: 15,250,250\n","Trainable params: 15,250,250\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"BYWSKDlobBN9"},"source":["---\n","## 4 - Using Functional API\n","\n","Now we'll see how to do it using Functional API"]},{"cell_type":"markdown","metadata":{"id":"9HoiqynMbKHE"},"source":["---\n","### a. Select output layer\n","\n","When using Functional API, we can simply select which layer we want to cut\n","\n","For VGG16, we can see that the last block ('`block5_pool`') is at layer $17$\n","\n","So we select that layer output as follow"]},{"cell_type":"code","metadata":{"id":"uMiY7IDan5PE"},"source":["x = model.layers[17].output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0WXBqjXGcSze"},"source":["---\n","### b. Add new Classifier Head\n","\n","Now to add a **Global Average Pool** layer and a couple of **Dense** layers with **10 class** output classification\n"]},{"cell_type":"code","metadata":{"id":"uI0kVLhSn5NG"},"source":["x = GlobalAveragePooling2D()(x)\n","\n","x = Dense(1024, activation='relu')(x)\n","\n","prediction = Dense(10, activation='softmax', name='prediction_full_2')(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jEaPYSyGcoLg"},"source":["---\n","### c. Instantiate Model\n","\n","Lastly, we instantiate new Model from input vgg16 model to our `'prediction'` branch\n","\n","Let's name it &nbsp;`'myModel_full_2'`"]},{"cell_type":"code","metadata":{"id":"v2AtBFktn5Jp"},"source":["myModel_F2 = Model(inputs=model.input, outputs=prediction, name='myModel_full_2')\n","myModel_F2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XUDCZwfphktI"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Model: \"myModel_full_2\"\n","\n","input_?  (InputLayer)        [(None, 224, 224, 3)]     0 \n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","...\n","\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","global_average_pooling2d_? ( (None, 512)               0         \n","dense (Dense)                (None, 1024)              525312    \n","prediction_full_2 (Dense)    (None, 10)                10250     \n","=================================================================\n","Total params: 15,250,250\n","Trainable params: 15,250,250\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"MNSAYA0Mx5ON"},"source":["---\n","---\n","# [Part 3] Modifying VGG16 for CIFAR-10\n","You've seen two ways to modify a Keras model using &nbsp;`Sequential`&nbsp; and &nbsp;`Functional API`\n","\n","Using &nbsp;`Sequential`&nbsp; model is slightly longer than using &nbsp;`Functional API`\n","\n","Now we've modified the output class, yes, but the input size is still $224\\times224$\n","\n","If we want to use Transfer Learning to train our own dataset with different input size, like CIFAR-10, we need to change the input shape as well\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DPSVALL7OzAg"},"source":["---\n","## 1 - Load VGG16 CNN body (no top)\n","\n","For that, let's start by loading VGG16 body (without classification head). \n","\n","To simplify things, let's also set the custom input and output pooling"]},{"cell_type":"markdown","metadata":{"id":"p_PCng8ffCAF"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>call VGG16() function with <b>include_top=False</b>, <b>input_shape=(32, 32, 3)</b>, and<b> pooling='avg'</b>"]},{"cell_type":"code","metadata":{"id":"CcG2uyQcOzAk"},"source":["model = ??"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0-rQ9kcWdMun"},"source":["---\n","## 2 - Using Sequential Model\n","\n","Like before, we'll try to modify the model first using Sequential Model"]},{"cell_type":"markdown","metadata":{"id":"3U2bldsVdW04"},"source":["---\n","### a. Prepare new Sequential Model\n","\n","Create a new empty model, and name the model &nbsp; `'myModel_cifar_1'`"]},{"cell_type":"markdown","metadata":{"id":"vrQSd5w5fQZ7"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>Create new Sequential model with <b>name='myModel_cifar_1'</b>"]},{"cell_type":"code","metadata":{"id":"HhDvEOqFdb9K"},"source":["myModel_C1 = ??"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0hCg7pmYdiK6"},"source":["---\n","### b. Add VGG16 body into Sequential Model\n","\n","Now copy and add all layers from vgg architecture into our model"]},{"cell_type":"markdown","metadata":{"id":"fL1m5iJmfihw"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>insert all layer from <b>model</b> into <b>myModel_C1</b>"]},{"cell_type":"code","metadata":{"id":"O05jgBENdiLB"},"source":["for layer in model.layers:\n","  ??\n","  \n","myModel_C1.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V_aWQeF1f1PV"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Model: \"myModel_cifar_1\"\n","\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","...\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","global_average_pooling2d_? ( (None, 512)               0         \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"569HBw61dy6I"},"source":["---\n","### c. Add new Classifier Head\n","\n","Now to add a couple of **Dense** layers with $1024$ neuron and $10$ class output classification respectively\n","\n","You **don't** have to add a **Global Average Pool** layer since we've already load VGG16 with pooling head\n","\n","Name the classification head as &nbsp;**`'prediction_cifar_1'`**"]},{"cell_type":"markdown","metadata":{"id":"VJG4t4htf855"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>add Dense 1024 with relu activation, \n","and Dense 10 with softmax activation, set name='prediction_cifar_1'"]},{"cell_type":"code","metadata":{"id":"D4G-tjbZdy6P"},"source":["??\n","??\n","\n","myModel_C1.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iuQLaL5cf66C"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Model: \"myModel_cifar_1\"\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","...\n","global_average_pooling2d_? ( (None, 512)               0         \n","dense_? (Dense)              (None, 1024)              525312    \n","prediction_cifar_1 (Dense)   (None, 10)                10250     \n","=================================================================\n","Total params: 15,250,250\n","Trainable params: 15,250,250\n","Non-trainable params: 0\n","_________________________________________________________________"]},{"cell_type":"markdown","metadata":{"id":"kWLLuM-venWy"},"source":["---\n","## 3 - Using Functional API\n","\n","Now let's try the same exact modification, but now using Functional API"]},{"cell_type":"markdown","metadata":{"id":"YHUxidh1etPs"},"source":["---\n","### a. Select output layer\n","\n","First, select the output layer\n","\n","Since we're already loding VGG16 using global pooling and without classification head, we can simply set &nbsp;**`x`**&nbsp; to the model output"]},{"cell_type":"markdown","metadata":{"id":"d9ATnMU2gJ55"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>set <b>x = model.output</b>"]},{"cell_type":"code","metadata":{"id":"6XahOlx5etPz"},"source":["x = ??\n","\n","print(x.name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I0AS-r3-gVsj"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","global_average_pooling2d_?/Identity:0"]},{"cell_type":"markdown","metadata":{"id":"72nX5qtOetP9"},"source":["---\n","### b. Add new Classifier Head\n","\n","Then add a couple of **Dense** layers with $1024$ neuron and $10$ class output classification respectively\n","\n","Again, you **don't** have to add a **Global Average Pool** layer since we've already load VGG16 with pooling head\n","\n","Name the classification head as &nbsp;**`'prediction_cifar_2'`**"]},{"cell_type":"markdown","metadata":{"id":"oj94DxxPgc4O"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>set x = Dense 1024 with relu activation that receive input from x, then\n","set prediction = Dense 10 with softmax activation that receive input from x, set name='prediction_cifar_2'"]},{"cell_type":"code","metadata":{"id":"S4AjiI66etP_"},"source":["x = ??\n","\n","prediction = Dense(10, activation='softmax', name='prediction_cifar_2')(x)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wbRSvHVXetQF"},"source":["---\n","### c. Instantiate Model\n","\n","Lastly, we instantiate the new model from input vgg16 model to our new classification head\n","\n","set the model name as  ` 'myModel_cifar_2'`"]},{"cell_type":"markdown","metadata":{"id":"SajrcDo5g33e"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>instantiate Model with <b>inputs = model.input</b> and <b>outputs = prediction</b>,\n","set with <b>name='myModel_cifar_2'"]},{"cell_type":"code","metadata":{"id":"j8kkFZg3etQH"},"source":["myModel_C2 = ??\n","\n","myModel_C2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nhm8P1oMj7nw"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Model: \"myModel_cifar_2\"\n","input_?  (InputLayer)        [(None, 32, 32, 3)]       0   \n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","...\n","global_average_pooling2d_? ( (None, 512)               0         \n","dense_? (Dense)              (None, 1024)              525312    \n","prediction_cifar_2 (Dense)   (None, 10)                10250     \n","=================================================================\n","Total params: 15,250,250\n","Trainable params: 15,250,250\n","Non-trainable params: 0\n","_________________________________________________________________"]},{"cell_type":"markdown","metadata":{"id":"QkyVG2uF4GBV"},"source":["---\n","---\n","# [Part 4] Modifying Mini VGG16 for CIFAR-10\n","As mentioned in previous exercise, using full VGG16 for CIFAR-10 sized dataset leads to an output pool shape of $1\\times1\\times512$\n","\n","which is too small (no spatial size)\n","\n","Therefore, we might want to cut the vgg body, and only take the first half or so\n","\n","So let's do that"]},{"cell_type":"markdown","metadata":{"id":"bG7Lf_YIONoU"},"source":["---\n","## 1 - Load VGG16 CNN body (no top)\n","\n","Again, let's load the VGG16 body without classification head.\n","\n","Don't forget to set the custom input and output pooling"]},{"cell_type":"markdown","metadata":{"id":"ghXllgtMhRY_"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>call VGG16() function with <b>include_top=False</b>, <b>input_shape=(32, 32, 3)</b>, and<b> pooling='avg'</b>"]},{"cell_type":"code","metadata":{"id":"hG9cIC8jhRZC"},"source":["model = ??"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R3E2g1h3hoNS"},"source":["---\n","## 2 - List Layer Names\n","First, let's look at the layers naming"]},{"cell_type":"code","metadata":{"id":"Bog2nxyqhoNa"},"source":["for i, layer in enumerate(model.layers):\n","    print(i, layer.name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fZHKf9z9soiU"},"source":["For this mini version of vgg for cifar-10, let's cut the model up to &nbsp;**`'block4_conv3'`** or layer $13$"]},{"cell_type":"markdown","metadata":{"id":"HkEidxz34GBu"},"source":["---\n","## 3 - Using Sequential Model\n","\n","Again, let's try it first using Sequential Model"]},{"cell_type":"markdown","metadata":{"id":"WtRiWlWws9oL"},"source":["---\n","### a. Prepare new Sequential Model\n","\n","Create a new empty model, and name the model &nbsp; `'myModel_mini_1'`"]},{"cell_type":"markdown","metadata":{"id":"N0cX52YlhZN-"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>Create new Sequential model with <b>name='myModel_mini_1'</b>"]},{"cell_type":"code","metadata":{"id":"iFJ5amby4GBz"},"source":["myModel_M1 = ??\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5FebDGSmtEA_"},"source":["---\n","### b. Add several VGG16 layers into Sequential Model\n","\n","Now copy and add layers from vgg architecture into our model.\n","\n","You can either:\n","\n","    a. copy and add all layers from model, then pop it back until the desired layer, or\n","    b. copy and add layers up to 'block4_conv3' or layer 13"]},{"cell_type":"markdown","metadata":{"id":"AVbbDUeehzS0"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>insert layers from <b>model</b> into <b>myModel_M1</b> up to <b>'block4_conv3'</b> or <b>layer 13</b>"]},{"cell_type":"code","metadata":{"id":"wYbJ4YRT4GB5"},"source":["for layer in ??:\n","  ??\n","  \n","myModel_M1.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nx5qhAD3iCXO"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Model: \"myModel_mini_1\"\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","...\n","block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","=================================================================\n","Total params: 7,635,264\n","Trainable params: 7,635,264\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"6_ZkSYMyuYIR"},"source":["---\n","### c. Add new Classifier Head\n","\n","Now to add a **Global Average Pool** layer and a couple of **Dense** layers with $1024$ neuron and $10$ class output classification respectively\n","\n","Name the classification head as &nbsp;**`'prediction_mini_1'`**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iiRsf5J6iJbE"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>add Global Average Pooling 2D,\n","add Dense 1024 with relu activation, \n","and add Dense 10 with softmax activation, set name='prediction_mini_1'"]},{"cell_type":"code","metadata":{"id":"cRx9n20Q4GB_"},"source":["??\n","??\n","??\n","\n","myModel_M1.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sgr3VH0piPWt"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Model: \"myModel_mini_1\"\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","...\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","global_average_pooling2d_? ( (None, 512)               0         \n","dense_? (Dense)              (None, 1024)              525312    \n","prediction_mini_1 (Dense)    (None, 10)                10250     \n","=================================================================\n","Total params: 8,170,826\n","Trainable params: 8,170,826\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"Ux45Z3OR4GCE"},"source":["---\n","## 4 - Using Functional API\n","\n","Now do the same using Functional API"]},{"cell_type":"markdown","metadata":{"id":"oXpRagBK4GCF"},"source":["---\n","### a. Select output layer\n","\n","To select an output layer from vgg, you can either:\n","\n","    a. select from the model.layer[] list as the example shown before, or\n","    b. use model.get_layer() function to select a layer by its name"]},{"cell_type":"markdown","metadata":{"id":"HSSY19DliadZ"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>set <b>x</b> to either <b>model.layer[13].output</b>\n","or <b>model.get_layer('block4_conv3').output</b> "]},{"cell_type":"code","metadata":{"id":"1ShmNw034GCH"},"source":["x = ??\n","\n","print(x.name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5L-praOUi-3-"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","block4_conv3_?/Identity:0"]},{"cell_type":"markdown","metadata":{"id":"jwZwEXDJ4GCK"},"source":["---\n","### b. Add new Classifier Head\n","\n","Then add a **Global Average Pool** layer and a couple of **Dense** layers with $1024$ neuron and $10$ class output classification respectively\n","\n","Name the classification head as &nbsp;**`'prediction_mini_2'`**"]},{"cell_type":"markdown","metadata":{"id":"oA5DMUMejLFE"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>set x = Global Average Pooling2D that receive input from x, then\n","set x = Dense 1024 with relu activation that receive input from x, and lastly\n","set prediction = Dense 10 with softmax activation that receive input from x, set name='prediction_mini_2'"]},{"cell_type":"code","metadata":{"id":"xLRXsR9I4GCL"},"source":["x = ??(x)\n","x = ??(x)\n","\n","prediction = Dense(10, activation='softmax', name='prediction_mini_2')(x)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G8bqw5dQ4GCQ"},"source":["---\n","### c. Instantiate Model\n","\n","Lastly, instantiate the new model from input vgg16 model to our new classification head\n","\n","set the model name as  ` 'myModel_mini_2'`"]},{"cell_type":"markdown","metadata":{"id":"TnOMmd_EjX-4"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>instantiate Model with <b>inputs = model.input</b> and <b>outputs = prediction</b>,\n","set with <b>name='myModel_mini_2'"]},{"cell_type":"code","metadata":{"id":"Xk5QZFWK4GCR"},"source":["myModel_M2 = ??\n","\n","myModel_M2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qY6dIPabjEa8"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Model: \"myModel_mini_2\"\n","input_?  (InputLayer)        [(None, 32, 32, 3)]       0         \n","...\n","block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n","global_average_pooling2d_? ( (None, 512)               0         \n","dense_? (Dense)              (None, 1024)              525312    \n","prediction_mini_2 (Dense)    (None, 10)                10250     \n","=================================================================\n","Total params: 8,170,826\n","Trainable params: 8,170,826\n","Non-trainable params: 0"]},{"cell_type":"markdown","metadata":{"id":"xvT7GDnk6M31"},"source":["---\n","# [Part 5] Freezing Model\n","\n","When training a model using Transfer Learning, we can use all designed layers or just train several layers and freeze the rest\n","\n","We can freeze layers by changing the boolean flag `trainable`. \n","\n","Frozen layers won't be updated during training"]},{"cell_type":"markdown","metadata":{"id":"IkG8jvo_PY_t"},"source":["---\n","## 1 - List Layer Names\n","We'll use our previously defined model for cifar-10 &nbsp;`myModel_C1`\n","\n","First, let's list the layer"]},{"cell_type":"code","metadata":{"id":"9J3l4A1sPY_0"},"source":["for i, layer in enumerate(myModel_C1.layers):\n","    print(i, layer.name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QRY7DdXnFws5"},"source":["You should see that there are 15 million parameters (weights) to train, and all parameters are trainable"]},{"cell_type":"code","metadata":{"id":"CqOhmpQhkFk5"},"source":["print_params(myModel_C1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bnqgrCtCj8vu"},"source":["---\n","## 2 - Freezing Conv Body\n","\n","For this example, let's try to freeze the CNN body, since it's already trained on ImageNet, and only train the classification head\n","\n","To do that, set the trainable of all layers up to layer $18$ to be `False`"]},{"cell_type":"code","metadata":{"id":"XM05fClEj_pw"},"source":["for layer in myModel_C1.layers[:19]:\n","    layer.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"33xcntGWGWro"},"source":["Now if we show the summary, you should see that there are $500$ thousands parameters to train, while the other $14$ million parameters are frozen."]},{"cell_type":"code","metadata":{"id":"dhJdu_otkKJh"},"source":["myModel_C1.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UbE74Z4KGunm"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Model: \"myModel_cifar_1\"\n","\n","block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n","...\n","block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n","global_average_pooling2d_? ( (None, 512)               0         \n","=================================================================\n","Total params: 15,250,250\n","Trainable params: 535,562\n","Non-trainable params: 14,714,688"]},{"cell_type":"markdown","metadata":{"id":"3feP1jcA7dDc"},"source":["---\n","## 3 - Freezing Several Layers\n","\n","In case of small dataset to train, you might want to freeze less layer and train more of them.\n","\n","For this exercise, let's freeze layers from &nbsp;**`myModel_C2`**&nbsp; up to <b>`'block4_pool'`</b> or layer <b>$14$</b>"]},{"cell_type":"markdown","metadata":{"id":"la5Xp87VjiyD"},"source":["---\n","#### <font color='red'>**EXERCISE:** </font>\n","<pre>freeze layer up to <b>'block4_pool'</b> or <b>layer 14</b>"]},{"cell_type":"code","metadata":{"id":"_iquGJ_xG_bx"},"source":["for layer in ??:\n","    layer.trainable = ??\n","    \n","for layer ??:\n","    ??"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2fhmF7E6HkKo"},"source":["Now if we show the summary, you should get $7$ million parameters to train, and another $7$ million parameters frozen."]},{"cell_type":"code","metadata":{"id":"AY8uIE4E7b84"},"source":["myModel_C2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n2ZcfxMvHyfu"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","Model: \"myModel_cifar_2\"\n","input_?  (InputLayer)        [(None, 32, 32, 3)]       0         \n","...\n","dense_? (Dense)              (None, 1024)              525312    \n","prediction_cifar_2 (Dense)   (None, 10)                10250     \n","=================================================================\n","Total params: 15,250,250\n","Trainable params: 7,614,986\n","Non-trainable params: 7,635,264"]},{"cell_type":"markdown","metadata":{"id":"SLXix0irH8Zd"},"source":["let's print the layer name and its trainable status"]},{"cell_type":"code","metadata":{"id":"VNxo7exAGGFo"},"source":["print('trainable : layer name')\n","print('-------------------------------')\n","for i, layer in enumerate(myModel_C2.layers):\n","    print(layer.trainable,'\\t  :', i, layer.name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JxcmRI70GhqI"},"source":["**EXPECTED OUTPUT**:\n","<pre>\n","trainable : layer name\n","-------------------------------\n","False     : 0 input_?\n","False     : 1 block1_conv1\n","False     : 2 block1_conv2\n","False     : 3 block1_pool\n","False     : 4 block2_conv1\n","False     : 5 block2_conv2\n","False     : 6 block2_pool\n","False     : 7 block3_conv1\n","False     : 8 block3_conv2\n","False     : 9 block3_conv3\n","False     : 10 block3_pool\n","False     : 11 block4_conv1\n","False     : 12 block4_conv2\n","False     : 13 block4_conv3\n","False     : 14 block4_pool\n","True      : 15 block5_conv1\n","True      : 16 block5_conv2\n","True      : 17 block5_conv3\n","True      : 18 block5_pool\n","True      : 19 global_average_pooling2d_?\n","True      : 20 dense_?\n","True      : 21 prediction_cifar_2"]},{"cell_type":"markdown","metadata":{"id":"aQqQ_gcO92ub"},"source":["\n","---\n","\n","# Congratulation, You've Completed Exercise 09\n","\n","<p>Copyright &copy;  <a href=https://www.linkedin.com/in/andityaarifianto/>2020 - ADF</a> </p>"]},{"cell_type":"markdown","metadata":{"id":"7_Hkr9kg9Do-"},"source":["![footer](https://i.ibb.co/yX0jfMS/footer2020.png)"]}]}